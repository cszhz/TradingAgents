#!/usr/bin/env python3
"""
Test Code for Adding Memories to TradingAgents System

This script provides comprehensive tests for the memory adding functionality,
including various scenarios, error conditions, and validation of stored data.
"""

import sys
import os
from pathlib import Path
import json
import time
from typing import List, Tuple, Dict, Any

# Add the parent directories to Python path
current_dir = Path(__file__).parent
strands_agents_dir = current_dir.parent
parent_dir = strands_agents_dir.parent
sys.path.insert(0, str(parent_dir))
sys.path.insert(0, str(strands_agents_dir))

from strands_agents.tools.memory import FinancialSituationMemory, add_financial_situation_memories
from strands_agents.default_config import DEFAULT_CONFIG
from strands_agents.model_utils import get_model
from strands_agents.agents.reflector import TradingReflector
import chromadb
from chromadb.config import Settings


class MemoryAddingTester:
    """Comprehensive tester for memory adding functionality."""
    
    def __init__(self):
        self.config = DEFAULT_CONFIG.copy()
        self.test_collection_prefix = "test_memory_"
        self.test_results = []
        
    def cleanup_test_collections(self):
        """Clean up test collections before and after testing."""
        try:
            client = chromadb.PersistentClient(path=self.config["chromadb_path"],settings=Settings(allow_reset=True))
            collections = client.list_collections()
            
            for collection in collections:
                if collection.name.startswith(self.test_collection_prefix):
                    try:
                        client.delete_collection(name=collection.name)
                        print(f"üßπ Cleaned up test collection: {collection.name}")
                    except Exception as e:
                        print(f"‚ö†Ô∏è  Failed to cleanup {collection.name}: {e}")
        except Exception as e:
            print(f"‚ö†Ô∏è  Cleanup error: {e}")
    
    def test_basic_memory_adding(self) -> bool:
        """Test basic memory adding functionality."""
        print("\n1Ô∏è‚É£ Testing Basic Memory Adding")
        print("-" * 40)
        
        try:
            collection_name = f"{self.test_collection_prefix}basic"
            memory = FinancialSituationMemory(collection_name, self.config)
            
            # Test data
            test_situations = [
                (
                    "NVDA technical analysis shows bullish breakout above $450 with high volume",
                    "Successful BUY decision resulted in +15% return. Technical breakout was validated."
                ),
                (
                    "AAPL earnings beat expectations but guidance was mixed",
                    "HOLD decision was appropriate. Stock moved sideways as expected."
                ),
                (
                    "TSLA showing bearish divergence with negative sentiment",
                    "SELL decision avoided -12% loss. Sentiment analysis proved predictive."
                )
            ]
            
            # Add memories
            memory.add_situations(test_situations)
            print(f"‚úÖ Added {len(test_situations)} memories successfully")
            
            # Verify memories were stored
            client = chromadb.PersistentClient(path=self.config["chromadb_path"],settings=Settings(allow_reset=True))
            collection = client.get_collection(name=collection_name)
            count = collection.count()
            
            if count == len(test_situations):
                print(f"‚úÖ Verified {count} memories stored in collection")
                
                # Test retrieval
                results = memory.get_memories("NVDA technical analysis", n_matches=2)
                if results:
                    print(f"‚úÖ Successfully retrieved {len(results)} matching memories")
                    print(f"   Top match similarity: {results[0].get('similarity_score', 0):.3f}")
                    return True
                else:
                    print("‚ùå Failed to retrieve memories")
                    return False
            else:
                print(f"‚ùå Expected {len(test_situations)} memories, found {count}")
                return False
                
        except Exception as e:
            print(f"‚ùå Basic memory adding test failed: {e}")
            return False
    
    def test_empty_and_invalid_data(self) -> bool:
        """Test handling of empty and invalid data."""
        print("\n2Ô∏è‚É£ Testing Empty and Invalid Data Handling")
        print("-" * 40)
        
        try:
            collection_name = f"{self.test_collection_prefix}invalid"
            memory = FinancialSituationMemory(collection_name, self.config)
            
            # Test empty list
            memory.add_situations([])
            print("‚úÖ Handled empty situations list")
            
            # Test invalid data types
            invalid_data_sets = [
                [("", "Valid recommendation")],  # Empty situation
                [("Valid situation", "")],       # Empty recommendation
                [(None, "Valid recommendation")], # None situation
                [("Valid situation", None)],     # None recommendation
                [("Valid", "Valid"), ("", "")],  # Mixed valid and invalid
            ]
            
            for i, invalid_data in enumerate(invalid_data_sets):
                try:
                    memory.add_situations(invalid_data)
                    print(f"‚úÖ Handled invalid data set {i+1}")
                except Exception as e:
                    print(f"‚ö†Ô∏è  Invalid data set {i+1} caused error: {e}")
            
            # Verify collection still works with valid data
            valid_data = [("Test situation", "Test recommendation")]
            memory.add_situations(valid_data)
            
            results = memory.get_memories("Test", n_matches=1)
            if results:
                print("‚úÖ Collection still functional after invalid data tests")
                return True
            else:
                print("‚ùå Collection not functional after invalid data tests")
                return False
                
        except Exception as e:
            print(f"‚ùå Invalid data test failed: {e}")
            return False
    
    def test_large_batch_adding(self) -> bool:
        """Test adding large batches of memories."""
        print("\n3Ô∏è‚É£ Testing Large Batch Adding")
        print("-" * 40)
        
        try:
            collection_name = f"{self.test_collection_prefix}large_batch"
            memory = FinancialSituationMemory(collection_name, self.config)
            
            # Generate large batch of test data
            large_batch = []
            for i in range(50):
                situation = f"Trading scenario {i}: Market analysis shows {'bullish' if i % 2 == 0 else 'bearish'} signals for stock XYZ with volume at {100 + i}% of average."
                recommendation = f"Decision {i}: {'BUY' if i % 2 == 0 else 'SELL'} recommendation resulted in {5 + (i % 10)}% {'gain' if i % 3 != 0 else 'loss'}. Key lesson: {['Technical analysis', 'Sentiment analysis', 'Fundamental analysis'][i % 3]} was the primary factor."
                large_batch.append((situation, recommendation))
            
            start_time = time.time()
            memory.add_situations(large_batch)
            end_time = time.time()
            
            print(f"‚úÖ Added {len(large_batch)} memories in {end_time - start_time:.2f} seconds")
            
            # Verify count
            client = chromadb.PersistentClient(path=self.config["chromadb_path"],settings=Settings(allow_reset=True))
            collection = client.get_collection(name=collection_name)
            count = collection.count()
            
            if count == len(large_batch):
                print(f"‚úÖ Verified all {count} memories stored correctly")
                
                # Test search performance
                start_time = time.time()
                results = memory.get_memories("bullish signals", n_matches=10)
                end_time = time.time()
                
                print(f"‚úÖ Search completed in {end_time - start_time:.2f} seconds, found {len(results)} results")
                return True
            else:
                print(f"‚ùå Expected {len(large_batch)} memories, found {count}")
                return False
                
        except Exception as e:
            print(f"‚ùå Large batch test failed: {e}")
            return False
    
    def test_concurrent_adding(self) -> bool:
        """Test concurrent memory adding from multiple instances."""
        print("\n4Ô∏è‚É£ Testing Concurrent Memory Adding")
        print("-" * 40)
        
        try:
            collection_name = f"{self.test_collection_prefix}concurrent"
            
            # Create multiple memory instances
            memories = []
            for i in range(3):
                memory = FinancialSituationMemory(collection_name, self.config)
                memories.append(memory)
            
            # Add different data from each instance
            for i, memory in enumerate(memories):
                test_data = [
                    (f"Concurrent test situation {i}-1", f"Recommendation from instance {i}-1"),
                    (f"Concurrent test situation {i}-2", f"Recommendation from instance {i}-2"),
                ]
                memory.add_situations(test_data)
                print(f"‚úÖ Instance {i+1} added {len(test_data)} memories")
            
            # Verify total count
            client = chromadb.PersistentClient(path=self.config["chromadb_path"],settings=Settings(allow_reset=True))
            collection = client.get_collection(name=collection_name)
            total_count = collection.count()
            expected_count = len(memories) * 2  # 2 memories per instance
            
            if total_count == expected_count:
                print(f"‚úÖ Total memories from all instances: {total_count}")
                
                # Test that all instances can read the data
                for i, memory in enumerate(memories):
                    results = memory.get_memories("Concurrent test", n_matches=5)
                    print(f"‚úÖ Instance {i+1} can read {len(results)} memories")
                
                return True
            else:
                print(f"‚ùå Expected {expected_count} total memories, found {total_count}")
                return False
                
        except Exception as e:
            print(f"‚ùå Concurrent adding test failed: {e}")
            return False
    
    def test_memory_persistence(self) -> bool:
        """Test that memories persist across instance recreation."""
        print("\n5Ô∏è‚É£ Testing Memory Persistence")
        print("-" * 40)
        
        try:
            collection_name = f"{self.test_collection_prefix}persistence"
            
            # Create first instance and add data
            memory1 = FinancialSituationMemory(collection_name, self.config)
            test_data = [
                ("Persistence test situation 1", "This should persist across instances"),
                ("Persistence test situation 2", "This should also persist"),
            ]
            memory1.add_situations(test_data)
            print(f"‚úÖ First instance added {len(test_data)} memories")
            
            # Delete the instance
            del memory1
            
            # Create second instance and verify data exists
            memory2 = FinancialSituationMemory(collection_name, self.config)
            results = memory2.get_memories("Persistence test", n_matches=5)
            
            if len(results) == len(test_data):
                print(f"‚úÖ Second instance found {len(results)} persisted memories")
                
                # Add more data with second instance
                additional_data = [("Additional persistence test", "Added by second instance")]
                memory2.add_situations(additional_data)
                
                # Verify total count
                client = chromadb.Client(Settings(allow_reset=True))
                collection = client.get_collection(name=collection_name)
                total_count = collection.count()
                expected_total = len(test_data) + len(additional_data)
                
                if total_count == expected_total:
                    print(f"‚úÖ Total persisted memories: {total_count}")
                    return True
                else:
                    print(f"‚ùå Expected {expected_total} total memories, found {total_count}")
                    return False
            else:
                print(f"‚ùå Expected {len(test_data)} persisted memories, found {len(results)}")
                return False
                
        except Exception as e:
            print(f"‚ùå Persistence test failed: {e}")
            return False
    
    def test_tool_function_adding(self) -> bool:
        """Test adding memories through the tool function."""
        print("\n6Ô∏è‚É£ Testing Tool Function Memory Adding")
        print("-" * 40)
        
        try:
            # Create mock agent
            class MockAgent:
                def __init__(self, memory_name, config):
                    self.state_data = {
                        "memory_name": memory_name,
                        "config": config
                    }
                
                class State:
                    def __init__(self, data):
                        self.data = data
                    
                    def get(self, key):
                        return self.data.get(key)
                
                @property
                def state(self):
                    return self.State(self.state_data)
            
            collection_name = f"{self.test_collection_prefix}tool_function"
            agent = MockAgent(collection_name, self.config)
            
            # Test data
            test_situations = [
                ("Tool function test situation 1", "Tool function recommendation 1"),
                ("Tool function test situation 2", "Tool function recommendation 2"),
            ]
            
            # Add memories using tool function
            add_financial_situation_memories(test_situations, agent)
            print(f"‚úÖ Tool function added {len(test_situations)} memories")
            
            # Verify memories were stored
            memory = FinancialSituationMemory(collection_name, self.config)
            results = memory.get_memories("Tool function test", n_matches=5)
            
            if len(results) == len(test_situations):
                print(f"‚úÖ Verified {len(results)} memories stored via tool function")
                return True
            else:
                print(f"‚ùå Expected {len(test_situations)} memories, found {len(results)}")
                return False
                
        except Exception as e:
            print(f"‚ùå Tool function test failed: {e}")
            return False
    
    def test_reflection_system_integration(self) -> bool:
        """Test memory adding through the reflection system."""
        print("\n7Ô∏è‚É£ Testing Reflection System Integration")
        print("-" * 40)
        
        try:
            # Get model for reflection system
            llm = get_model(provider='bedrock')
            reflector = TradingReflector(llm, self.config)
            
            # Sample trading state
            trading_state = {
                "market_report": "Test market analysis showing bullish momentum",
                "sentiment_report": "Positive sentiment across platforms",
                "news_report": "Company announced strong earnings",
                "fundamentals_report": "Revenue growth and expanding margins",
                "trader_investment_plan": "FINAL TRANSACTION PROPOSAL: **BUY**",
                "investment_debate_state": {
                    "bull_history": "Bull case: Strong technical and fundamental signals",
                    "bear_history": "Bear case: Valuation concerns remain",
                    "judge_decision": "Bullish consensus based on multiple factors"
                },
                "risk_debate_state": {
                    "judge_decision": "Approved BUY with 2% position limit"
                }
            }
            
            returns_outcome = "Trade Result: +10% return over 2 weeks. Strategy executed well."
            
            # Generate reflections (this should add memories)
            print("Generating reflections...")
            reflections = reflector.reflect_on_all_components(trading_state, returns_outcome)
            
            print(f"‚úÖ Generated reflections for {len(reflections)} components")
            
            # Verify memories were created in standard collections
            standard_collections = ["bull_memory", "bear_memory", "trader_memory", "invest_judge_memory", "risk_manager_memory"]
            memories_found = 0
            
            for collection_name in standard_collections:
                try:
                    memory = FinancialSituationMemory(collection_name, self.config)
                    results = memory.get_memories("Test market analysis", n_matches=1)
                    if results:
                        memories_found += 1
                        print(f"‚úÖ Found reflection memory in {collection_name}")
                except Exception as e:
                    print(f"‚ö†Ô∏è  Could not check {collection_name}: {e}")
            
            if memories_found > 0:
                print(f"‚úÖ Reflection system successfully added memories to {memories_found} collections")
                return True
            else:
                print("‚ùå No memories found from reflection system")
                return False
                
        except Exception as e:
            print(f"‚ùå Reflection system integration test failed: {e}")
            return False
    
    def test_embedding_generation(self) -> bool:
        """Test that embeddings are generated correctly for added memories."""
        print("\n8Ô∏è‚É£ Testing Embedding Generation")
        print("-" * 40)
        
        try:
            collection_name = f"{self.test_collection_prefix}embeddings"
            memory = FinancialSituationMemory(collection_name, self.config)
            
            # Test data with different content
            test_situations = [
                ("Technical analysis shows bullish patterns", "Technical analysis recommendation"),
                ("Fundamental analysis reveals strong metrics", "Fundamental analysis recommendation"),
                ("Sentiment analysis indicates positive mood", "Sentiment analysis recommendation"),
            ]
            
            memory.add_situations(test_situations)
            print(f"‚úÖ Added {len(test_situations)} memories with embeddings")
            
            # Verify embeddings exist and are different
            client = chromadb.PersistentClient(path=self.config["chromadb_path"],settings=Settings(allow_reset=True))
            collection = client.get_collection(name=collection_name)
            data = collection.get(include=["embeddings", "documents"])
            
            embeddings = data.get("embeddings", [])
            if len(embeddings) == len(test_situations):
                print(f"‚úÖ Generated {len(embeddings)} embeddings")
                
                # Check embedding dimensions
                if embeddings and len(embeddings[0]) > 0:
                    print(f"‚úÖ Embedding dimensions: {len(embeddings[0])}")
                    
                    # Test that embeddings are different (not all zeros)
                    non_zero_embeddings = 0
                    for embedding in embeddings:
                        if any(val != 0.0 for val in embedding):
                            non_zero_embeddings += 1
                    
                    if non_zero_embeddings == len(embeddings):
                        print(f"‚úÖ All {non_zero_embeddings} embeddings contain non-zero values")
                        
                        # Test semantic search works
                        results = memory.get_memories("technical patterns", n_matches=1)
                        if results and results[0].get("similarity_score", 0) > 0:
                            print(f"‚úÖ Semantic search working, top similarity: {results[0]['similarity_score']:.3f}")
                            return True
                        else:
                            print("‚ùå Semantic search not working properly")
                            return False
                    else:
                        print(f"‚ùå Only {non_zero_embeddings} embeddings have non-zero values")
                        return False
                else:
                    print("‚ùå Embeddings are empty or malformed")
                    return False
            else:
                print(f"‚ùå Expected {len(test_situations)} embeddings, found {len(embeddings)}")
                return False
                
        except Exception as e:
            print(f"‚ùå Embedding generation test failed: {e}")
            return False
    
    def run_all_tests(self) -> Dict[str, bool]:
        """Run all memory adding tests."""
        print("üß™ TradingAgents Memory Adding Tests")
        print("=" * 60)
        
        # Cleanup before testing
        self.cleanup_test_collections()
        
        # Define all tests
        tests = [
            ("Basic Memory Adding", self.test_basic_memory_adding),
            # ("Empty and Invalid Data", self.test_empty_and_invalid_data),
            # ("Large Batch Adding", self.test_large_batch_adding),
            # ("Concurrent Adding", self.test_concurrent_adding),
            # ("Memory Persistence", self.test_memory_persistence),
            # ("Tool Function Adding", self.test_tool_function_adding),
            # ("Reflection System Integration", self.test_reflection_system_integration),
            # ("Embedding Generation", self.test_embedding_generation),
        ]
        
        results = {}
        passed = 0
        
        # Run each test
        for test_name, test_func in tests:
            try:
                result = test_func()
                results[test_name] = result
                if result:
                    passed += 1
            except Exception as e:
                print(f"‚ùå {test_name} failed with exception: {e}")
                results[test_name] = False
        
        # Cleanup after testing
        # self.cleanup_test_collections()
        
        # Print summary
        print("\n" + "=" * 60)
        print("üìä TEST RESULTS SUMMARY")
        print("=" * 60)
        
        for test_name, result in results.items():
            status = "‚úÖ PASS" if result else "‚ùå FAIL"
            print(f"{status} {test_name}")
        
        print(f"\nOverall: {passed}/{len(tests)} tests passed")
        
        if passed == len(tests):
            print("üéâ All memory adding tests passed!")
        elif passed > len(tests) * 0.7:
            print("‚ö†Ô∏è  Most tests passed, system is mostly functional")
        else:
            print("‚ùå Many tests failed, system needs attention")
        
        return results


def test_specific_scenarios():
    """Test specific trading scenarios for memory adding."""
    print("\nüéØ Testing Specific Trading Scenarios")
    print("=" * 50)
    
    try:
        memory = FinancialSituationMemory("test_trading_scenarios", DEFAULT_CONFIG.copy())
        
        # Real-world trading scenarios
        trading_scenarios = [
            (
                "NVDA Q3 2024: Stock at $450, RSI 65, MACD bullish crossover, volume 2x average. AI chip demand strong, data center revenue up 200% YoY. Positive sentiment 85% bullish.",
                "BUY decision executed at $450. Result: +18% return to $531 in 2 weeks. Key factors: Technical breakout confirmed, AI narrative strong, volume supported move. Lesson: High-conviction technical + fundamental + sentiment alignment = strong performance."
            ),
            (
                "TSLA March 2024: Stock at $220, bearish divergence (price up, RSI down), production issues reported, CEO distraction concerns, 70% bearish sentiment, competition increasing.",
                "SELL decision executed at $220. Result: Avoided -15% loss, stock fell to $187. Key factors: Multiple bearish signals aligned, sentiment predictive. Lesson: When technical, fundamental, and sentiment all negative, act decisively."
            ),
            (
                "AAPL September 2024: Mixed signals - above 50-day MA but below 200-day MA, iPhone 15 sales uncertain, China weakness, services growth slowing, neutral sentiment 52% bullish.",
                "HOLD decision maintained. Result: +4% return over 1 month, stock moved sideways as expected. Key factors: Uncertainty warranted caution. Lesson: When signals are mixed, conservative approach often best."
            ),
            (
                "SPY October 2024: Market at resistance, VIX elevated at 25, Fed meeting approaching, earnings season mixed, geopolitical tensions, technical indicators diverging.",
                "Risk management: Reduced position sizes by 50%, increased cash allocation. Result: Portfolio protected during 8% market decline. Lesson: Risk management more important than individual stock picks during uncertain periods."
            ),
            (
                "AMZN AWS Focus: Stock at $180, AWS growth accelerating 35% YoY, retail margins improving, but consumer spending concerns, mixed analyst ratings $140-200 targets.",
                "Moderate BUY decision with 1.5% position. Result: +12% return over 6 weeks as AWS strength drove results. Lesson: Diversified business models provide stability, focus on strongest growth drivers."
            )
        ]
        
        # Add scenarios
        memory.add_situations(trading_scenarios)
        print(f"‚úÖ Added {len(trading_scenarios)} real trading scenarios")
        
        # Test searches for different aspects
        search_tests = [
            ("NVDA technical analysis", "Technical analysis scenarios"),
            ("risk management position", "Risk management scenarios"),
            ("earnings results", "Earnings-related scenarios"),
            ("sentiment analysis", "Sentiment-driven scenarios"),
            ("AWS growth", "Specific company scenarios"),
        ]
        
        for query, description in search_tests:
            results = memory.get_memories(query, n_matches=2)
            print(f"üîç {description}: Found {len(results)} matches for '{query}'")
            if results:
                top_similarity = results[0].get("similarity_score", 0)
                print(f"   Top match similarity: {top_similarity:.3f}")
        
        return True
        
    except Exception as e:
        print(f"‚ùå Specific scenarios test failed: {e}")
        return False


def main():
    """Main test execution function."""
    print("üöÄ TradingAgents Memory Adding Test Suite")
    print("=" * 60)
    
    # Run comprehensive tests
    tester = MemoryAddingTester()
    results = tester.run_all_tests()
    
    # Run specific scenario tests
    scenario_result = test_specific_scenarios()
    
    # Final summary
    print("\n" + "=" * 60)
    print("üèÅ FINAL TEST SUMMARY")
    print("=" * 60)
    
    total_tests = len(results) + 1  # +1 for scenario test
    passed_tests = sum(results.values()) + (1 if scenario_result else 0)
    
    print(f"Total Tests Run: {total_tests}")
    print(f"Tests Passed: {passed_tests}")
    print(f"Success Rate: {(passed_tests/total_tests)*100:.1f}%")
    
    if passed_tests == total_tests:
        print("\nüéâ ALL TESTS PASSED! Memory adding functionality is working perfectly.")
        print("\nKey capabilities verified:")
        print("‚úÖ Basic memory storage and retrieval")
        print("‚úÖ Error handling for invalid data")
        print("‚úÖ Large batch processing")
        print("‚úÖ Concurrent access support")
        print("‚úÖ Data persistence across instances")
        print("‚úÖ Tool function integration")
        print("‚úÖ Reflection system integration")
        print("‚úÖ Embedding generation and semantic search")
        print("‚úÖ Real-world trading scenario handling")
    elif passed_tests > total_tests * 0.8:
        print("\n‚ö†Ô∏è  MOST TESTS PASSED - System is largely functional with minor issues.")
    else:
        print("\n‚ùå MULTIPLE TEST FAILURES - System needs attention before production use.")
    
    print(f"\nFor detailed analysis, check the individual test results above.")
    return passed_tests == total_tests


if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1)
