{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a262470d-15cb-4a69-8059-8d8baefcabad",
   "metadata": {},
   "source": [
    "# Building Multi-Agent Investment Firms with Strands SDK\n",
    "\n",
    "## Introduction\n",
    "\n",
    "Welcome to **Challenge 2** of the AWS re:Invent Jam! In this challenge, you'll build a sophisticated multi-agent investment analysis system using the Strands Agents SDK. This system mirrors the collaborative dynamics of real-world investment firms, where different specialists work together to make informed trading decisions.\n",
    "\n",
    "### What You'll Build\n",
    "\n",
    "You'll create an AI-powered investment research team consisting of:\n",
    "- **Bull Researcher**: An optimistic analyst focused on growth opportunities and positive market factors\n",
    "- **Bear Researcher**: A cautious analyst specializing in risk identification and market threats\n",
    "- **Research Manager**: A senior decision-maker who synthesizes insights from both perspectives\n",
    "\n",
    "### The Challenge Scenario\n",
    "\n",
    "Imagine you're building the AI backbone for a modern investment firm. Your system needs to:\n",
    "1. **Analyze Market Data**: Process financial information and news to understand market conditions\n",
    "2. **Generate Diverse Perspectives**: Create both bullish and bearish investment cases\n",
    "3. **Facilitate Structured Debates**: Allow agents to challenge and refine each other's arguments\n",
    "4. **Synthesize Final Decisions**: Combine multiple viewpoints into actionable investment recommendations\n",
    "\n",
    "### Technical Learning Objectives\n",
    "\n",
    "By completing this challenge, you will:\n",
    "- **Master Agent Design**: Learn to create specialized AI agents with distinct roles and expertise\n",
    "- **Implement Multi-Agent Coordination**: Use the Strands Swarm framework for structured agent interactions\n",
    "- **Build Collaborative AI Systems**: Demonstrate how multiple AI agents can work together effectively\n",
    "- **Apply AI to Finance**: Create practical applications for investment analysis and decision-making\n",
    "\n",
    "Let's begin building your multi-agent investment analysis system!\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ad4111d0-c7a1-4d8d-9c00-5feff20ef0ac",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Task 2 - Multi-Agent Investment Analysis System\n",
    "\n",
    "### Objective\n",
    "- **Primary Goal**: Master the fundamentals of Strands Agent API and build a sophisticated multi-agent investment analysis system\n",
    "- **Specific Tasks**: \n",
    "  - Create Bull Researcher and Bear Researcher agents with distinct analytical perspectives\n",
    "  - Implement collaborative dialogue and debate mechanisms between agents\n",
    "  - Generate comprehensive market analysis reports and investment recommendations\n",
    "  - Learn to utilize the Swarm multi-agent coordination framework effectively\n",
    "\n",
    "### System Architecture\n",
    "This system simulates the operational model of real-world investment firms, featuring these core components:\n",
    "1. **Bull Researcher**: Focuses on identifying investment opportunities and positive market factors\n",
    "2. **Bear Researcher**: Specializes in risk identification and negative market indicators  \n",
    "3. **Research Manager**: Coordinates debates and synthesizes final investment decisions\n",
    "4. **Multi-Agent Dialogue System**: Manages interactions and collaboration between agents\n",
    "\n",
    "### Learning Outcomes\n",
    "By completing this challenge, you will:\n",
    "- Understand how to design and implement specialized AI agents with distinct roles\n",
    "- Learn to orchestrate complex multi-agent conversations and debates\n",
    "- Master the Strands SDK for building production-ready agent systems\n",
    "- Gain insights into collaborative AI decision-making processes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b05c2834-d7b8-4600-8e1e-3cfdf489a5ee",
   "metadata": {},
   "source": [
    "## 1. Install Required Dependencies\n",
    "\n",
    "### Installation Overview\n",
    "This section installs all necessary packages for building our multi-agent investment analysis system. The dependencies are organized into several categories:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "682675cb-d9a0-4947-8ad4-4511e77fb3af",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting strands>=0.1.0 (from -r requirements.txt (line 2))\n",
      "  Downloading Strands-0.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.1 kB)\n",
      "Collecting strands-agents>=1.5.0 (from -r requirements.txt (line 3))\n",
      "  Downloading strands_agents-1.7.1-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting strands-agents-tools>=0.2.4 (from -r requirements.txt (line 4))\n",
      "  Downloading strands_agents_tools-0.2.6-py3-none-any.whl.metadata (43 kB)\n",
      "Collecting langchain>=0.1.0 (from -r requirements.txt (line 5))\n",
      "  Downloading langchain-0.3.27-py3-none-any.whl.metadata (7.8 kB)\n",
      "Collecting openai>=1.0.0 (from -r requirements.txt (line 6))\n",
      "  Downloading openai-1.107.0-py3-none-any.whl.metadata (29 kB)\n",
      "Collecting anthropic>=0.20.0 (from -r requirements.txt (line 7))\n",
      "  Downloading anthropic-0.66.0-py3-none-any.whl.metadata (27 kB)\n",
      "Requirement already satisfied: boto3>=1.34.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from -r requirements.txt (line 8)) (1.40.21)\n",
      "Requirement already satisfied: botocore>=1.34.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from -r requirements.txt (line 9)) (1.40.21)\n",
      "Requirement already satisfied: pandas>=2.0.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from -r requirements.txt (line 12)) (2.3.2)\n",
      "Requirement already satisfied: numpy>=1.24.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from -r requirements.txt (line 13)) (1.26.4)\n",
      "Collecting yfinance>=0.2.0 (from -r requirements.txt (line 14))\n",
      "  Downloading yfinance-0.2.65-py2.py3-none-any.whl.metadata (5.8 kB)\n",
      "Collecting stockstats>=0.6.0 (from -r requirements.txt (line 15))\n",
      "  Downloading stockstats-0.6.5-py2.py3-none-any.whl.metadata (39 kB)\n",
      "Requirement already satisfied: requests>=2.31.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from -r requirements.txt (line 18)) (2.32.5)\n",
      "Requirement already satisfied: beautifulsoup4>=4.12.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from -r requirements.txt (line 19)) (4.13.5)\n",
      "Collecting finnhub-python>=2.4.0 (from -r requirements.txt (line 20))\n",
      "  Downloading finnhub_python-2.4.24-py3-none-any.whl.metadata (9.2 kB)\n",
      "Collecting praw>=7.7.0 (from -r requirements.txt (line 21))\n",
      "  Downloading praw-7.8.1-py3-none-any.whl.metadata (9.4 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from -r requirements.txt (line 24)) (2.9.0.post0)\n",
      "Collecting python-dotenv>=1.0.0 (from -r requirements.txt (line 27))\n",
      "  Downloading python_dotenv-1.1.1-py3-none-any.whl.metadata (24 kB)\n",
      "Requirement already satisfied: pydantic>=2.0.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from -r requirements.txt (line 28)) (2.9.2)\n",
      "Requirement already satisfied: typer>=0.9.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from -r requirements.txt (line 31)) (0.16.1)\n",
      "Requirement already satisfied: rich>=13.0.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from -r requirements.txt (line 32)) (14.1.0)\n",
      "Collecting questionary>=2.0.0 (from -r requirements.txt (line 33))\n",
      "  Downloading questionary-2.1.1-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting chromadb>=0.4.0 (from -r requirements.txt (line 36))\n",
      "  Downloading chromadb-1.0.20-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.3 kB)\n",
      "Collecting asyncio-mqtt>=0.13.0 (from -r requirements.txt (line 39))\n",
      "  Downloading asyncio_mqtt-0.16.2-py3-none-any.whl.metadata (17 kB)\n",
      "Requirement already satisfied: pytest>=7.0.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from -r requirements.txt (line 42)) (8.4.1)\n",
      "Collecting pytest-asyncio>=0.21.0 (from -r requirements.txt (line 43))\n",
      "  Downloading pytest_asyncio-1.1.0-py3-none-any.whl.metadata (4.1 kB)\n",
      "Requirement already satisfied: tqdm>=4.65.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from -r requirements.txt (line 46)) (4.67.1)\n",
      "Collecting lxml>=4.9.0 (from -r requirements.txt (line 47))\n",
      "  Downloading lxml-6.0.1-cp310-cp310-manylinux_2_26_x86_64.manylinux_2_28_x86_64.whl.metadata (3.8 kB)\n",
      "Collecting docstring-parser<1.0,>=0.15 (from strands-agents>=1.5.0->-r requirements.txt (line 3))\n",
      "  Downloading docstring_parser-0.17.0-py3-none-any.whl.metadata (3.5 kB)\n",
      "Collecting mcp<2.0.0,>=1.11.0 (from strands-agents>=1.5.0->-r requirements.txt (line 3))\n",
      "  Downloading mcp-1.13.1-py3-none-any.whl.metadata (74 kB)\n",
      "Collecting opentelemetry-api<2.0.0,>=1.30.0 (from strands-agents>=1.5.0->-r requirements.txt (line 3))\n",
      "  Downloading opentelemetry_api-1.36.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting opentelemetry-instrumentation-threading<1.00b0,>=0.51b0 (from strands-agents>=1.5.0->-r requirements.txt (line 3))\n",
      "  Downloading opentelemetry_instrumentation_threading-0.57b0-py3-none-any.whl.metadata (2.1 kB)\n",
      "Collecting opentelemetry-sdk<2.0.0,>=1.30.0 (from strands-agents>=1.5.0->-r requirements.txt (line 3))\n",
      "  Downloading opentelemetry_sdk-1.36.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: typing-extensions<5.0.0,>=4.13.2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from strands-agents>=1.5.0->-r requirements.txt (line 3)) (4.15.0)\n",
      "Requirement already satisfied: watchdog<7.0.0,>=6.0.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from strands-agents>=1.5.0->-r requirements.txt (line 3)) (6.0.0)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from boto3>=1.34.0->-r requirements.txt (line 8)) (1.0.1)\n",
      "Requirement already satisfied: s3transfer<0.14.0,>=0.13.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from boto3>=1.34.0->-r requirements.txt (line 8)) (0.13.1)\n",
      "Requirement already satisfied: urllib3!=2.2.0,<3,>=1.25.4 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from botocore>=1.34.0->-r requirements.txt (line 9)) (2.5.0)\n",
      "Requirement already satisfied: six>=1.5 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from python-dateutil>=2.8.0->-r requirements.txt (line 24)) (1.17.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from pydantic>=2.0.0->-r requirements.txt (line 28)) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.4 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from pydantic>=2.0.0->-r requirements.txt (line 28)) (2.23.4)\n",
      "Requirement already satisfied: anyio>=4.5 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from mcp<2.0.0,>=1.11.0->strands-agents>=1.5.0->-r requirements.txt (line 3)) (4.10.0)\n",
      "Collecting httpx-sse>=0.4 (from mcp<2.0.0,>=1.11.0->strands-agents>=1.5.0->-r requirements.txt (line 3))\n",
      "  Downloading httpx_sse-0.4.1-py3-none-any.whl.metadata (9.4 kB)\n",
      "Collecting httpx>=0.27.1 (from mcp<2.0.0,>=1.11.0->strands-agents>=1.5.0->-r requirements.txt (line 3))\n",
      "  Using cached httpx-0.28.1-py3-none-any.whl.metadata (7.1 kB)\n",
      "Requirement already satisfied: jsonschema>=4.20.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from mcp<2.0.0,>=1.11.0->strands-agents>=1.5.0->-r requirements.txt (line 3)) (4.25.1)\n",
      "Collecting pydantic-settings>=2.5.2 (from mcp<2.0.0,>=1.11.0->strands-agents>=1.5.0->-r requirements.txt (line 3))\n",
      "  Downloading pydantic_settings-2.10.1-py3-none-any.whl.metadata (3.4 kB)\n",
      "Collecting pydantic>=2.0.0 (from -r requirements.txt (line 28))\n",
      "  Using cached pydantic-2.11.7-py3-none-any.whl.metadata (67 kB)\n",
      "Collecting python-multipart>=0.0.9 (from mcp<2.0.0,>=1.11.0->strands-agents>=1.5.0->-r requirements.txt (line 3))\n",
      "  Downloading python_multipart-0.0.20-py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting sse-starlette>=1.6.1 (from mcp<2.0.0,>=1.11.0->strands-agents>=1.5.0->-r requirements.txt (line 3))\n",
      "  Downloading sse_starlette-3.0.2-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: starlette>=0.27 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from mcp<2.0.0,>=1.11.0->strands-agents>=1.5.0->-r requirements.txt (line 3)) (0.47.3)\n",
      "Requirement already satisfied: uvicorn>=0.31.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from mcp<2.0.0,>=1.11.0->strands-agents>=1.5.0->-r requirements.txt (line 3)) (0.35.0)\n",
      "Collecting pydantic-core==2.33.2 (from pydantic>=2.0.0->-r requirements.txt (line 28))\n",
      "  Using cached pydantic_core-2.33.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
      "Collecting typing-inspection>=0.4.0 (from pydantic>=2.0.0->-r requirements.txt (line 28))\n",
      "  Using cached typing_inspection-0.4.1-py3-none-any.whl.metadata (2.6 kB)\n",
      "Requirement already satisfied: importlib-metadata<8.8.0,>=6.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from opentelemetry-api<2.0.0,>=1.30.0->strands-agents>=1.5.0->-r requirements.txt (line 3)) (6.11.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from importlib-metadata<8.8.0,>=6.0->opentelemetry-api<2.0.0,>=1.30.0->strands-agents>=1.5.0->-r requirements.txt (line 3)) (3.23.0)\n",
      "Collecting opentelemetry-instrumentation==0.57b0 (from opentelemetry-instrumentation-threading<1.00b0,>=0.51b0->strands-agents>=1.5.0->-r requirements.txt (line 3))\n",
      "  Downloading opentelemetry_instrumentation-0.57b0-py3-none-any.whl.metadata (6.7 kB)\n",
      "Requirement already satisfied: wrapt<2.0.0,>=1.0.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from opentelemetry-instrumentation-threading<1.00b0,>=0.51b0->strands-agents>=1.5.0->-r requirements.txt (line 3)) (1.17.3)\n",
      "Collecting opentelemetry-semantic-conventions==0.57b0 (from opentelemetry-instrumentation==0.57b0->opentelemetry-instrumentation-threading<1.00b0,>=0.51b0->strands-agents>=1.5.0->-r requirements.txt (line 3))\n",
      "  Downloading opentelemetry_semantic_conventions-0.57b0-py3-none-any.whl.metadata (2.4 kB)\n",
      "Requirement already satisfied: packaging>=18.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from opentelemetry-instrumentation==0.57b0->opentelemetry-instrumentation-threading<1.00b0,>=0.51b0->strands-agents>=1.5.0->-r requirements.txt (line 3)) (24.2)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from strands-agents-tools>=0.2.4->-r requirements.txt (line 4)) (3.12.15)\n",
      "Collecting aws-requests-auth<0.5.0,>=0.4.3 (from strands-agents-tools>=0.2.4->-r requirements.txt (line 4))\n",
      "  Downloading aws_requests_auth-0.4.3-py2.py3-none-any.whl.metadata (567 bytes)\n",
      "Requirement already satisfied: dill<0.5.0,>=0.4.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from strands-agents-tools>=0.2.4->-r requirements.txt (line 4)) (0.4.0)\n",
      "Collecting markdownify<2.0.0,>=1.0.0 (from strands-agents-tools>=0.2.4->-r requirements.txt (line 4))\n",
      "  Downloading markdownify-1.2.0-py3-none-any.whl.metadata (9.9 kB)\n",
      "Requirement already satisfied: pillow<12.0.0,>=11.2.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from strands-agents-tools>=0.2.4->-r requirements.txt (line 4)) (11.3.0)\n",
      "Requirement already satisfied: prompt-toolkit<4.0.0,>=3.0.51 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from strands-agents-tools>=0.2.4->-r requirements.txt (line 4)) (3.0.51)\n",
      "Requirement already satisfied: pyjwt<3.0.0,>=2.10.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from strands-agents-tools>=0.2.4->-r requirements.txt (line 4)) (2.10.1)\n",
      "Collecting readabilipy<1.0.0,>=0.2.0 (from strands-agents-tools>=0.2.4->-r requirements.txt (line 4))\n",
      "  Downloading readabilipy-0.3.0-py3-none-any.whl.metadata (8.9 kB)\n",
      "Collecting slack-bolt<2.0.0,>=1.23.0 (from strands-agents-tools>=0.2.4->-r requirements.txt (line 4))\n",
      "  Downloading slack_bolt-1.24.0-py2.py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: sympy<2.0.0,>=1.12.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from strands-agents-tools>=0.2.4->-r requirements.txt (line 4)) (1.14.0)\n",
      "Requirement already satisfied: tenacity<10.0.0,>=9.1.2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from strands-agents-tools>=0.2.4->-r requirements.txt (line 4)) (9.1.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from requests>=2.31.0->-r requirements.txt (line 18)) (3.4.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from requests>=2.31.0->-r requirements.txt (line 18)) (3.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from requests>=2.31.0->-r requirements.txt (line 18)) (2025.8.3)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from rich>=13.0.0->-r requirements.txt (line 32)) (4.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from rich>=13.0.0->-r requirements.txt (line 32)) (2.19.2)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.0->strands-agents-tools>=0.2.4->-r requirements.txt (line 4)) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.0->strands-agents-tools>=0.2.4->-r requirements.txt (line 4)) (1.4.0)\n",
      "Requirement already satisfied: async-timeout<6.0,>=4.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.0->strands-agents-tools>=0.2.4->-r requirements.txt (line 4)) (5.0.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.0->strands-agents-tools>=0.2.4->-r requirements.txt (line 4)) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.0->strands-agents-tools>=0.2.4->-r requirements.txt (line 4)) (1.7.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.0->strands-agents-tools>=0.2.4->-r requirements.txt (line 4)) (6.6.3)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.0->strands-agents-tools>=0.2.4->-r requirements.txt (line 4)) (0.3.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.0->strands-agents-tools>=0.2.4->-r requirements.txt (line 4)) (1.20.1)\n",
      "Requirement already satisfied: soupsieve>1.2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from beautifulsoup4>=4.12.0->-r requirements.txt (line 19)) (2.7)\n",
      "Requirement already satisfied: wcwidth in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from prompt-toolkit<4.0.0,>=3.0.51->strands-agents-tools>=0.2.4->-r requirements.txt (line 4)) (0.2.13)\n",
      "Collecting html5lib (from readabilipy<1.0.0,>=0.2.0->strands-agents-tools>=0.2.4->-r requirements.txt (line 4))\n",
      "  Downloading html5lib-1.1-py2.py3-none-any.whl.metadata (16 kB)\n",
      "Requirement already satisfied: regex in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from readabilipy<1.0.0,>=0.2.0->strands-agents-tools>=0.2.4->-r requirements.txt (line 4)) (2025.7.34)\n",
      "Collecting slack_sdk<4,>=3.35.0 (from slack-bolt<2.0.0,>=1.23.0->strands-agents-tools>=0.2.4->-r requirements.txt (line 4))\n",
      "  Downloading slack_sdk-3.36.0-py2.py3-none-any.whl.metadata (15 kB)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from sympy<2.0.0,>=1.12.0->strands-agents-tools>=0.2.4->-r requirements.txt (line 4)) (1.3.0)\n",
      "Collecting langchain-core<1.0.0,>=0.3.72 (from langchain>=0.1.0->-r requirements.txt (line 5))\n",
      "  Downloading langchain_core-0.3.75-py3-none-any.whl.metadata (5.7 kB)\n",
      "Collecting langchain-text-splitters<1.0.0,>=0.3.9 (from langchain>=0.1.0->-r requirements.txt (line 5))\n",
      "  Downloading langchain_text_splitters-0.3.11-py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting langsmith>=0.1.17 (from langchain>=0.1.0->-r requirements.txt (line 5))\n",
      "  Downloading langsmith-0.4.27-py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from langchain>=0.1.0->-r requirements.txt (line 5)) (2.0.43)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from langchain>=0.1.0->-r requirements.txt (line 5)) (6.0.2)\n",
      "Collecting async-timeout<6.0,>=4.0 (from aiohttp<4.0.0,>=3.8.0->strands-agents-tools>=0.2.4->-r requirements.txt (line 4))\n",
      "  Downloading async_timeout-4.0.3-py3-none-any.whl.metadata (4.2 kB)\n",
      "Collecting jsonpatch<2.0,>=1.33 (from langchain-core<1.0.0,>=0.3.72->langchain>=0.1.0->-r requirements.txt (line 5))\n",
      "  Downloading jsonpatch-1.33-py2.py3-none-any.whl.metadata (3.0 kB)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.72->langchain>=0.1.0->-r requirements.txt (line 5)) (3.0.0)\n",
      "Requirement already satisfied: greenlet>=1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from SQLAlchemy<3,>=1.4->langchain>=0.1.0->-r requirements.txt (line 5)) (3.2.4)\n",
      "Collecting distro<2,>=1.7.0 (from openai>=1.0.0->-r requirements.txt (line 6))\n",
      "  Downloading distro-1.9.0-py3-none-any.whl.metadata (6.8 kB)\n",
      "Collecting jiter<1,>=0.4.0 (from openai>=1.0.0->-r requirements.txt (line 6))\n",
      "  Downloading jiter-0.10.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.2 kB)\n",
      "Requirement already satisfied: sniffio in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from openai>=1.0.0->-r requirements.txt (line 6)) (1.3.1)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from anyio>=4.5->mcp<2.0.0,>=1.11.0->strands-agents>=1.5.0->-r requirements.txt (line 3)) (1.3.0)\n",
      "Collecting httpcore==1.* (from httpx>=0.27.1->mcp<2.0.0,>=1.11.0->strands-agents>=1.5.0->-r requirements.txt (line 3))\n",
      "  Using cached httpcore-1.0.9-py3-none-any.whl.metadata (21 kB)\n",
      "Requirement already satisfied: h11>=0.16 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from httpcore==1.*->httpx>=0.27.1->mcp<2.0.0,>=1.11.0->strands-agents>=1.5.0->-r requirements.txt (line 3)) (0.16.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from pandas>=2.0.0->-r requirements.txt (line 12)) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from pandas>=2.0.0->-r requirements.txt (line 12)) (2025.2)\n",
      "Collecting multitasking>=0.0.7 (from yfinance>=0.2.0->-r requirements.txt (line 14))\n",
      "  Downloading multitasking-0.0.12.tar.gz (19 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: platformdirs>=2.0.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from yfinance>=0.2.0->-r requirements.txt (line 14)) (4.4.0)\n",
      "Collecting frozendict>=2.3.4 (from yfinance>=0.2.0->-r requirements.txt (line 14))\n",
      "  Downloading frozendict-2.4.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (23 kB)\n",
      "Collecting peewee>=3.16.2 (from yfinance>=0.2.0->-r requirements.txt (line 14))\n",
      "  Downloading peewee-3.18.2.tar.gz (949 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m949.2/949.2 kB\u001b[0m \u001b[31m45.7 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting curl_cffi>=0.7 (from yfinance>=0.2.0->-r requirements.txt (line 14))\n",
      "  Downloading curl_cffi-0.13.0-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (13 kB)\n",
      "Requirement already satisfied: protobuf>=3.19.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from yfinance>=0.2.0->-r requirements.txt (line 14)) (6.31.1)\n",
      "Collecting websockets>=13.0 (from yfinance>=0.2.0->-r requirements.txt (line 14))\n",
      "  Downloading websockets-15.0.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
      "Collecting prawcore<3,>=2.4 (from praw>=7.7.0->-r requirements.txt (line 21))\n",
      "  Downloading prawcore-2.4.0-py3-none-any.whl.metadata (5.0 kB)\n",
      "Collecting update_checker>=0.18 (from praw>=7.7.0->-r requirements.txt (line 21))\n",
      "  Downloading update_checker-0.18.0-py3-none-any.whl.metadata (2.3 kB)\n",
      "Requirement already satisfied: websocket-client>=0.54.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from praw>=7.7.0->-r requirements.txt (line 21)) (1.8.0)\n",
      "Requirement already satisfied: click>=8.0.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from typer>=0.9.0->-r requirements.txt (line 31)) (8.2.1)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from typer>=0.9.0->-r requirements.txt (line 31)) (1.5.4)\n",
      "Collecting build>=1.0.3 (from chromadb>=0.4.0->-r requirements.txt (line 36))\n",
      "  Downloading build-1.3.0-py3-none-any.whl.metadata (5.6 kB)\n",
      "Collecting pybase64>=1.4.1 (from chromadb>=0.4.0->-r requirements.txt (line 36))\n",
      "  Downloading pybase64-1.4.2-cp310-cp310-manylinux1_x86_64.manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_5_x86_64.whl.metadata (8.7 kB)\n",
      "Collecting posthog<6.0.0,>=2.4.0 (from chromadb>=0.4.0->-r requirements.txt (line 36))\n",
      "  Downloading posthog-5.4.0-py3-none-any.whl.metadata (5.7 kB)\n",
      "Collecting onnxruntime>=1.14.1 (from chromadb>=0.4.0->-r requirements.txt (line 36))\n",
      "  Downloading onnxruntime-1.16.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.3 kB)\n",
      "Collecting opentelemetry-exporter-otlp-proto-grpc>=1.2.0 (from chromadb>=0.4.0->-r requirements.txt (line 36))\n",
      "  Downloading opentelemetry_exporter_otlp_proto_grpc-1.36.0-py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting tokenizers>=0.13.2 (from chromadb>=0.4.0->-r requirements.txt (line 36))\n",
      "  Downloading tokenizers-0.22.0-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
      "Collecting pypika>=0.48.9 (from chromadb>=0.4.0->-r requirements.txt (line 36))\n",
      "  Downloading PyPika-0.48.9.tar.gz (67 kB)\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: overrides>=7.3.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from chromadb>=0.4.0->-r requirements.txt (line 36)) (7.7.0)\n",
      "Requirement already satisfied: importlib-resources in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from chromadb>=0.4.0->-r requirements.txt (line 36)) (6.5.2)\n",
      "Collecting grpcio>=1.58.0 (from chromadb>=0.4.0->-r requirements.txt (line 36))\n",
      "  Downloading grpcio-1.74.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\n",
      "Requirement already satisfied: bcrypt>=4.0.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from chromadb>=0.4.0->-r requirements.txt (line 36)) (4.3.0)\n",
      "Collecting kubernetes>=28.1.0 (from chromadb>=0.4.0->-r requirements.txt (line 36))\n",
      "  Downloading kubernetes-33.1.0-py2.py3-none-any.whl.metadata (1.7 kB)\n",
      "Collecting mmh3>=4.0.1 (from chromadb>=0.4.0->-r requirements.txt (line 36))\n",
      "  Downloading mmh3-5.2.0-cp310-cp310-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl.metadata (14 kB)\n",
      "Collecting orjson>=3.9.12 (from chromadb>=0.4.0->-r requirements.txt (line 36))\n",
      "  Downloading orjson-3.11.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (41 kB)\n",
      "Collecting backoff>=1.10.0 (from posthog<6.0.0,>=2.4.0->chromadb>=0.4.0->-r requirements.txt (line 36))\n",
      "  Downloading backoff-2.2.1-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting paho-mqtt>=1.6.0 (from asyncio-mqtt>=0.13.0->-r requirements.txt (line 39))\n",
      "  Downloading paho_mqtt-2.1.0-py3-none-any.whl.metadata (23 kB)\n",
      "Requirement already satisfied: iniconfig>=1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from pytest>=7.0.0->-r requirements.txt (line 42)) (2.0.0)\n",
      "Requirement already satisfied: pluggy<2,>=1.5 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from pytest>=7.0.0->-r requirements.txt (line 42)) (1.6.0)\n",
      "Requirement already satisfied: tomli>=1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from pytest>=7.0.0->-r requirements.txt (line 42)) (2.2.1)\n",
      "Collecting backports-asyncio-runner<2,>=1.1 (from pytest-asyncio>=0.21.0->-r requirements.txt (line 43))\n",
      "  Downloading backports_asyncio_runner-1.2.0-py3-none-any.whl.metadata (7.5 kB)\n",
      "Collecting pyproject_hooks (from build>=1.0.3->chromadb>=0.4.0->-r requirements.txt (line 36))\n",
      "  Downloading pyproject_hooks-1.2.0-py3-none-any.whl.metadata (1.3 kB)\n",
      "Requirement already satisfied: cffi>=1.12.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from curl_cffi>=0.7->yfinance>=0.2.0->-r requirements.txt (line 14)) (1.17.1)\n",
      "Requirement already satisfied: pycparser in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from cffi>=1.12.0->curl_cffi>=0.7->yfinance>=0.2.0->-r requirements.txt (line 14)) (2.22)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from jsonschema>=4.20.0->mcp<2.0.0,>=1.11.0->strands-agents>=1.5.0->-r requirements.txt (line 3)) (2025.4.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from jsonschema>=4.20.0->mcp<2.0.0,>=1.11.0->strands-agents>=1.5.0->-r requirements.txt (line 3)) (0.36.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from jsonschema>=4.20.0->mcp<2.0.0,>=1.11.0->strands-agents>=1.5.0->-r requirements.txt (line 3)) (0.27.0)\n",
      "Collecting google-auth>=1.0.1 (from kubernetes>=28.1.0->chromadb>=0.4.0->-r requirements.txt (line 36))\n",
      "  Downloading google_auth-2.40.3-py2.py3-none-any.whl.metadata (6.2 kB)\n",
      "Collecting requests-oauthlib (from kubernetes>=28.1.0->chromadb>=0.4.0->-r requirements.txt (line 36))\n",
      "  Downloading requests_oauthlib-2.0.0-py2.py3-none-any.whl.metadata (11 kB)\n",
      "Collecting oauthlib>=3.2.2 (from kubernetes>=28.1.0->chromadb>=0.4.0->-r requirements.txt (line 36))\n",
      "  Downloading oauthlib-3.3.1-py3-none-any.whl.metadata (7.9 kB)\n",
      "Collecting durationpy>=0.7 (from kubernetes>=28.1.0->chromadb>=0.4.0->-r requirements.txt (line 36))\n",
      "  Downloading durationpy-0.10-py3-none-any.whl.metadata (340 bytes)\n",
      "Collecting cachetools<6.0,>=2.0.0 (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb>=0.4.0->-r requirements.txt (line 36))\n",
      "  Downloading cachetools-5.5.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting pyasn1-modules>=0.2.1 (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb>=0.4.0->-r requirements.txt (line 36))\n",
      "  Downloading pyasn1_modules-0.4.2-py3-none-any.whl.metadata (3.5 kB)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb>=0.4.0->-r requirements.txt (line 36)) (4.7.2)\n",
      "Requirement already satisfied: pyasn1>=0.1.3 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from rsa<5,>=3.1.4->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb>=0.4.0->-r requirements.txt (line 36)) (0.6.1)\n",
      "Collecting requests-toolbelt>=1.0.0 (from langsmith>=0.1.17->langchain>=0.1.0->-r requirements.txt (line 5))\n",
      "  Downloading requests_toolbelt-1.0.0-py2.py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: zstandard>=0.23.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from langsmith>=0.1.17->langchain>=0.1.0->-r requirements.txt (line 5)) (0.23.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich>=13.0.0->-r requirements.txt (line 32)) (0.1.2)\n",
      "Collecting coloredlogs (from onnxruntime>=1.14.1->chromadb>=0.4.0->-r requirements.txt (line 36))\n",
      "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n",
      "Collecting flatbuffers (from onnxruntime>=1.14.1->chromadb>=0.4.0->-r requirements.txt (line 36))\n",
      "  Downloading flatbuffers-25.2.10-py2.py3-none-any.whl.metadata (875 bytes)\n",
      "Collecting googleapis-common-protos~=1.57 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb>=0.4.0->-r requirements.txt (line 36))\n",
      "  Downloading googleapis_common_protos-1.70.0-py3-none-any.whl.metadata (9.3 kB)\n",
      "Collecting opentelemetry-exporter-otlp-proto-common==1.36.0 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb>=0.4.0->-r requirements.txt (line 36))\n",
      "  Downloading opentelemetry_exporter_otlp_proto_common-1.36.0-py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting opentelemetry-proto==1.36.0 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb>=0.4.0->-r requirements.txt (line 36))\n",
      "  Downloading opentelemetry_proto-1.36.0-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting huggingface-hub<1.0,>=0.16.4 (from tokenizers>=0.13.2->chromadb>=0.4.0->-r requirements.txt (line 36))\n",
      "  Downloading huggingface_hub-0.34.4-py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: filelock in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb>=0.4.0->-r requirements.txt (line 36)) (3.16.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb>=0.4.0->-r requirements.txt (line 36)) (2025.7.0)\n",
      "Collecting hf-xet<2.0.0,>=1.1.3 (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb>=0.4.0->-r requirements.txt (line 36))\n",
      "  Downloading hf_xet-1.1.9-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.7 kB)\n",
      "Collecting httptools>=0.6.3 (from uvicorn[standard]>=0.18.3->chromadb>=0.4.0->-r requirements.txt (line 36))\n",
      "  Downloading httptools-0.6.4-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.6 kB)\n",
      "Collecting uvloop>=0.15.1 (from uvicorn[standard]>=0.18.3->chromadb>=0.4.0->-r requirements.txt (line 36))\n",
      "  Downloading uvloop-0.21.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
      "Collecting watchfiles>=0.13 (from uvicorn[standard]>=0.18.3->chromadb>=0.4.0->-r requirements.txt (line 36))\n",
      "  Downloading watchfiles-1.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
      "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime>=1.14.1->chromadb>=0.4.0->-r requirements.txt (line 36))\n",
      "  Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n",
      "Requirement already satisfied: webencodings in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from html5lib->readabilipy<1.0.0,>=0.2.0->strands-agents-tools>=0.2.4->-r requirements.txt (line 4)) (0.5.1)\n",
      "Downloading Strands-0.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (635 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m635.6/635.6 kB\u001b[0m \u001b[31m44.9 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading strands_agents-1.7.1-py3-none-any.whl (192 kB)\n",
      "Downloading docstring_parser-0.17.0-py3-none-any.whl (36 kB)\n",
      "Downloading mcp-1.13.1-py3-none-any.whl (161 kB)\n",
      "Using cached pydantic-2.11.7-py3-none-any.whl (444 kB)\n",
      "Using cached pydantic_core-2.33.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.0 MB)\n",
      "Downloading opentelemetry_api-1.36.0-py3-none-any.whl (65 kB)\n",
      "Downloading opentelemetry_instrumentation_threading-0.57b0-py3-none-any.whl (9.3 kB)\n",
      "Downloading opentelemetry_instrumentation-0.57b0-py3-none-any.whl (32 kB)\n",
      "Downloading opentelemetry_semantic_conventions-0.57b0-py3-none-any.whl (201 kB)\n",
      "Downloading opentelemetry_sdk-1.36.0-py3-none-any.whl (119 kB)\n",
      "Downloading strands_agents_tools-0.2.6-py3-none-any.whl (283 kB)\n",
      "Downloading aws_requests_auth-0.4.3-py2.py3-none-any.whl (6.8 kB)\n",
      "Downloading markdownify-1.2.0-py3-none-any.whl (15 kB)\n",
      "Downloading readabilipy-0.3.0-py3-none-any.whl (22 kB)\n",
      "Downloading slack_bolt-1.24.0-py2.py3-none-any.whl (230 kB)\n",
      "Downloading slack_sdk-3.36.0-py2.py3-none-any.whl (293 kB)\n",
      "Downloading langchain-0.3.27-py3-none-any.whl (1.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m56.3 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading async_timeout-4.0.3-py3-none-any.whl (5.7 kB)\n",
      "Downloading langchain_core-0.3.75-py3-none-any.whl (443 kB)\n",
      "Downloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
      "Downloading langchain_text_splitters-0.3.11-py3-none-any.whl (33 kB)\n",
      "Downloading openai-1.107.0-py3-none-any.whl (950 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m951.0/951.0 kB\u001b[0m \u001b[31m76.4 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading distro-1.9.0-py3-none-any.whl (20 kB)\n",
      "Using cached httpx-0.28.1-py3-none-any.whl (73 kB)\n",
      "Using cached httpcore-1.0.9-py3-none-any.whl (78 kB)\n",
      "Downloading jiter-0.10.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (352 kB)\n",
      "Downloading anthropic-0.66.0-py3-none-any.whl (308 kB)\n",
      "Downloading yfinance-0.2.65-py2.py3-none-any.whl (119 kB)\n",
      "Downloading stockstats-0.6.5-py2.py3-none-any.whl (31 kB)\n",
      "Downloading finnhub_python-2.4.24-py3-none-any.whl (11 kB)\n",
      "Downloading praw-7.8.1-py3-none-any.whl (189 kB)\n",
      "Downloading prawcore-2.4.0-py3-none-any.whl (17 kB)\n",
      "Downloading python_dotenv-1.1.1-py3-none-any.whl (20 kB)\n",
      "Downloading questionary-2.1.1-py3-none-any.whl (36 kB)\n",
      "Downloading chromadb-1.0.20-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (19.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.8/19.8 MB\u001b[0m \u001b[31m213.4 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading posthog-5.4.0-py3-none-any.whl (105 kB)\n",
      "Downloading asyncio_mqtt-0.16.2-py3-none-any.whl (17 kB)\n",
      "Downloading pytest_asyncio-1.1.0-py3-none-any.whl (15 kB)\n",
      "Downloading backports_asyncio_runner-1.2.0-py3-none-any.whl (12 kB)\n",
      "Downloading lxml-6.0.1-cp310-cp310-manylinux_2_26_x86_64.manylinux_2_28_x86_64.whl (5.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.3/5.3 MB\u001b[0m \u001b[31m177.3 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading backoff-2.2.1-py3-none-any.whl (15 kB)\n",
      "Downloading build-1.3.0-py3-none-any.whl (23 kB)\n",
      "Downloading curl_cffi-0.13.0-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (8.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.3/8.3 MB\u001b[0m \u001b[31m238.9 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading frozendict-2.4.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (117 kB)\n",
      "Downloading grpcio-1.74.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.2/6.2 MB\u001b[0m \u001b[31m158.8 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading httpx_sse-0.4.1-py3-none-any.whl (8.1 kB)\n",
      "Downloading kubernetes-33.1.0-py2.py3-none-any.whl (1.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m98.5 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading durationpy-0.10-py3-none-any.whl (3.9 kB)\n",
      "Downloading google_auth-2.40.3-py2.py3-none-any.whl (216 kB)\n",
      "Downloading cachetools-5.5.2-py3-none-any.whl (10 kB)\n",
      "Downloading langsmith-0.4.27-py3-none-any.whl (384 kB)\n",
      "Downloading mmh3-5.2.0-cp310-cp310-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl (101 kB)\n",
      "Downloading oauthlib-3.3.1-py3-none-any.whl (160 kB)\n",
      "Downloading onnxruntime-1.16.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.4/6.4 MB\u001b[0m \u001b[31m160.1 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading opentelemetry_exporter_otlp_proto_grpc-1.36.0-py3-none-any.whl (18 kB)\n",
      "Downloading opentelemetry_exporter_otlp_proto_common-1.36.0-py3-none-any.whl (18 kB)\n",
      "Downloading opentelemetry_proto-1.36.0-py3-none-any.whl (72 kB)\n",
      "Downloading googleapis_common_protos-1.70.0-py3-none-any.whl (294 kB)\n",
      "Downloading orjson-3.11.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (132 kB)\n",
      "Downloading paho_mqtt-2.1.0-py3-none-any.whl (67 kB)\n",
      "Downloading pyasn1_modules-0.4.2-py3-none-any.whl (181 kB)\n",
      "Downloading pybase64-1.4.2-cp310-cp310-manylinux1_x86_64.manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_5_x86_64.whl (68 kB)\n",
      "Downloading pydantic_settings-2.10.1-py3-none-any.whl (45 kB)\n",
      "Downloading python_multipart-0.0.20-py3-none-any.whl (24 kB)\n",
      "Downloading requests_toolbelt-1.0.0-py2.py3-none-any.whl (54 kB)\n",
      "Downloading sse_starlette-3.0.2-py3-none-any.whl (11 kB)\n",
      "Downloading tokenizers-0.22.0-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m200.3 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading huggingface_hub-0.34.4-py3-none-any.whl (561 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m561.5/561.5 kB\u001b[0m \u001b[31m47.4 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading hf_xet-1.1.9-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.2/3.2 MB\u001b[0m \u001b[31m184.8 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached typing_inspection-0.4.1-py3-none-any.whl (14 kB)\n",
      "Downloading update_checker-0.18.0-py3-none-any.whl (7.0 kB)\n",
      "Downloading httptools-0.6.4-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (442 kB)\n",
      "Downloading uvloop-0.21.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.8/3.8 MB\u001b[0m \u001b[31m137.4 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading watchfiles-1.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (453 kB)\n",
      "Downloading websockets-15.0.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (181 kB)\n",
      "Downloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
      "Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
      "Downloading flatbuffers-25.2.10-py2.py3-none-any.whl (30 kB)\n",
      "Downloading html5lib-1.1-py2.py3-none-any.whl (112 kB)\n",
      "Downloading pyproject_hooks-1.2.0-py3-none-any.whl (10 kB)\n",
      "Downloading requests_oauthlib-2.0.0-py2.py3-none-any.whl (24 kB)\n",
      "Building wheels for collected packages: multitasking, peewee, pypika\n",
      "\u001b[33m  DEPRECATION: Building 'multitasking' using the legacy setup.py bdist_wheel mechanism, which will be removed in a future version. pip 25.3 will enforce this behaviour change. A possible replacement is to use the standardized build interface by setting the `--use-pep517` option, (possibly combined with `--no-build-isolation`), or adding a `pyproject.toml` file to the source tree of 'multitasking'. Discussion can be found at https://github.com/pypa/pip/issues/6334\u001b[0m\u001b[33m\n",
      "\u001b[0m  Building wheel for multitasking (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for multitasking: filename=multitasking-0.0.12-py3-none-any.whl size=15636 sha256=4f8bdb2136b2fa9fb3d7e7c76cb4e89cf0289c905f7bc8ad18af543a77c9a183\n",
      "  Stored in directory: /home/ec2-user/.cache/pip/wheels/e9/25/85/25d2e1cfc0ece64b930b16972f7e4cc3599c43b531f1eba06d\n",
      "  Building wheel for peewee (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for peewee: filename=peewee-3.18.2-cp310-cp310-linux_x86_64.whl size=302976 sha256=0d91a62266a8fae653098be8fcc55520f088babc032bdbfa02f1aa15508a4182\n",
      "  Stored in directory: /home/ec2-user/.cache/pip/wheels/29/22/6c/745744e946d21fdbad1d89887af15cf0659ea76d1a884417ca\n",
      "  Building wheel for pypika (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for pypika: filename=pypika-0.48.9-py2.py3-none-any.whl size=53803 sha256=0893713b058d2901ecf6000b1592b10ed2a362f3d67f3ba5952b5bf044558647\n",
      "  Stored in directory: /home/ec2-user/.cache/pip/wheels/e1/26/51/d0bffb3d2fd82256676d7ad3003faea3bd6dddc9577af665f4\n",
      "Successfully built multitasking peewee pypika\n",
      "Installing collected packages: pypika, peewee, multitasking, flatbuffers, durationpy, websockets, uvloop, typing-inspection, strands, slack_sdk, python-multipart, python-dotenv, pyproject_hooks, pydantic-core, pybase64, pyasn1-modules, paho-mqtt, orjson, opentelemetry-proto, oauthlib, mmh3, lxml, jsonpatch, jiter, humanfriendly, httpx-sse, httptools, httpcore, html5lib, hf-xet, grpcio, googleapis-common-protos, frozendict, docstring-parser, distro, cachetools, backports-asyncio-runner, backoff, async-timeout, update_checker, slack-bolt, requests-toolbelt, requests-oauthlib, readabilipy, questionary, pydantic, prawcore, posthog, opentelemetry-exporter-otlp-proto-common, opentelemetry-api, markdownify, huggingface-hub, google-auth, finnhub-python, curl_cffi, coloredlogs, build, aws-requests-auth, asyncio-mqtt, yfinance, watchfiles, tokenizers, stockstats, sse-starlette, pytest-asyncio, pydantic-settings, praw, opentelemetry-semantic-conventions, onnxruntime, kubernetes, httpx, opentelemetry-sdk, opentelemetry-instrumentation, openai, mcp, langsmith, anthropic, opentelemetry-instrumentation-threading, opentelemetry-exporter-otlp-proto-grpc, langchain-core, strands-agents, langchain-text-splitters, chromadb, strands-agents-tools, langchain\n",
      "\u001b[2K  Attempting uninstall: pydantic-core━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 9/85\u001b[0m [slack_sdk]\n",
      "\u001b[2K    Found existing installation: pydantic_core 2.23.4━━━━━━━━━\u001b[0m \u001b[32m 9/85\u001b[0m [slack_sdk]\n",
      "\u001b[2K    Uninstalling pydantic_core-2.23.4:━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 9/85\u001b[0m [slack_sdk]\n",
      "\u001b[2K      Successfully uninstalled pydantic_core-2.23.4━━━━━━━━━━━\u001b[0m \u001b[32m 9/85\u001b[0m [slack_sdk]\n",
      "\u001b[2K  Attempting uninstall: async-timeout\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m33/85\u001b[0m [docstring-parser]\n",
      "\u001b[2K    Found existing installation: async-timeout 5.0.1━━━━━━━━━━\u001b[0m \u001b[32m33/85\u001b[0m [docstring-parser]\n",
      "\u001b[2K    Uninstalling async-timeout-5.0.1:m━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m33/85\u001b[0m [docstring-parser]\n",
      "\u001b[2K      Successfully uninstalled async-timeout-5.0.1━━━━━━━━━━━━\u001b[0m \u001b[32m33/85\u001b[0m [docstring-parser]\n",
      "\u001b[2K  Attempting uninstall: pydantic\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44/85\u001b[0m [questionary]]\n",
      "\u001b[2K    Found existing installation: pydantic 2.9.2━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44/85\u001b[0m [questionary]\n",
      "\u001b[2K    Uninstalling pydantic-2.9.2:m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45/85\u001b[0m [pydantic]\n",
      "\u001b[2K      Successfully uninstalled pydantic-2.9.2━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45/85\u001b[0m [pydantic]\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85/85\u001b[0m [langchain]angchain]ents-tools]re]c-conventions]\n",
      "\u001b[1A\u001b[2K\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "safety-schemas 0.0.14 requires pydantic<2.10.0,>=2.6.0, but you have pydantic 2.11.7 which is incompatible.\n",
      "sparkmagic 0.21.0 requires pandas<2.0.0,>=0.17.1, but you have pandas 2.3.2 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed anthropic-0.66.0 async-timeout-4.0.3 asyncio-mqtt-0.16.2 aws-requests-auth-0.4.3 backoff-2.2.1 backports-asyncio-runner-1.2.0 build-1.3.0 cachetools-5.5.2 chromadb-1.0.20 coloredlogs-15.0.1 curl_cffi-0.13.0 distro-1.9.0 docstring-parser-0.17.0 durationpy-0.10 finnhub-python-2.4.24 flatbuffers-25.2.10 frozendict-2.4.6 google-auth-2.40.3 googleapis-common-protos-1.70.0 grpcio-1.74.0 hf-xet-1.1.9 html5lib-1.1 httpcore-1.0.9 httptools-0.6.4 httpx-0.28.1 httpx-sse-0.4.1 huggingface-hub-0.34.4 humanfriendly-10.0 jiter-0.10.0 jsonpatch-1.33 kubernetes-33.1.0 langchain-0.3.27 langchain-core-0.3.75 langchain-text-splitters-0.3.11 langsmith-0.4.27 lxml-6.0.1 markdownify-1.2.0 mcp-1.13.1 mmh3-5.2.0 multitasking-0.0.12 oauthlib-3.3.1 onnxruntime-1.16.3 openai-1.107.0 opentelemetry-api-1.36.0 opentelemetry-exporter-otlp-proto-common-1.36.0 opentelemetry-exporter-otlp-proto-grpc-1.36.0 opentelemetry-instrumentation-0.57b0 opentelemetry-instrumentation-threading-0.57b0 opentelemetry-proto-1.36.0 opentelemetry-sdk-1.36.0 opentelemetry-semantic-conventions-0.57b0 orjson-3.11.3 paho-mqtt-2.1.0 peewee-3.18.2 posthog-5.4.0 praw-7.8.1 prawcore-2.4.0 pyasn1-modules-0.4.2 pybase64-1.4.2 pydantic-2.11.7 pydantic-core-2.33.2 pydantic-settings-2.10.1 pypika-0.48.9 pyproject_hooks-1.2.0 pytest-asyncio-1.1.0 python-dotenv-1.1.1 python-multipart-0.0.20 questionary-2.1.1 readabilipy-0.3.0 requests-oauthlib-2.0.0 requests-toolbelt-1.0.0 slack-bolt-1.24.0 slack_sdk-3.36.0 sse-starlette-3.0.2 stockstats-0.6.5 strands-0.1.0 strands-agents-1.7.1 strands-agents-tools-0.2.6 tokenizers-0.22.0 typing-inspection-0.4.1 update_checker-0.18.0 uvloop-0.21.0 watchfiles-1.1.0 websockets-15.0.1 yfinance-0.2.65\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd6d541e-6cb4-48c6-8d4e-53acc0cb36a4",
   "metadata": {},
   "source": [
    "## 2. Prerequisites code  \n",
    "### 2.1 Import Utils functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8d52631e-9eb7-4eab-958a-ae9441b2589b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Import essential libraries for our multi-agent system\n",
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "from default_config import DEFAULT_CONFIG  # Configuration settings for the system\n",
    "import logging  # For debugging and monitoring agent interactions\n",
    "from dotenv import load_dotenv  # For loading environment variables (API keys, etc.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4032eff3-205e-489a-9793-564257d15a80",
   "metadata": {},
   "source": [
    "## 2. System Configuration and Setup\n",
    "\n",
    "### 2.1 Import Core Libraries\n",
    "First, we import the essential libraries needed for our multi-agent system:\n",
    "- **System utilities**: For path management and configuration\n",
    "- **Configuration management**: Default settings and environment variables\n",
    "- **Logging**: For debugging and monitoring agent interactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d19b09c1-e6db-4348-9c61-2c0b2a0d2dd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the Large Language Model for our agents\n",
    "# Amazon Nova Pro is optimized for complex reasoning and financial analysis\n",
    "NOVA_RPO_MODEL_ID = \"amazon.nova-pro-v1:0\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9fbed04-42a3-46d6-8a80-af4ead4b3e85",
   "metadata": {},
   "source": [
    "### 2.2 Configure Model Selection\n",
    "We define the Large Language Model (LLM) that will power our agents. Amazon Nova Pro is a state-of-the-art model optimized for complex reasoning tasks, making it ideal for financial analysis and multi-agent debates."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "model-setup-explanation",
   "metadata": {},
   "source": [
    "### 2.3 Initialize LLM Model Factory\n",
    "\n",
    "The `get_model()` function serves as our model factory, creating configured Amazon Bedrock model instances for our agents. Key features:\n",
    "\n",
    "**Configuration Options:**\n",
    "- **Model Selection**: Choose from various Amazon Bedrock models\n",
    "- **Thinking Mode**: Enable step-by-step reasoning for complex analysis\n",
    "- **Temperature Control**: Balance between consistency and creativity\n",
    "- **Token Limits**: Control response length and computational cost\n",
    "\n",
    "**Timeout and Retry Settings:**\n",
    "- **Read Timeout**: 30 minutes for complex financial analysis\n",
    "- **Connect Timeout**: 15 minutes for initial connection\n",
    "- **Adaptive Retries**: Automatic retry with exponential backoff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fd196741-fa95-4167-8900-e097dc48d907",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "from botocore.config import Config\n",
    "from strands.models import BedrockModel\n",
    "\n",
    "# AWS Boto3 client configuration with timeouts and retries\n",
    "boto_client_config = Config(\n",
    "    read_timeout=1800,      # 30 minutes read timeout\n",
    "    connect_timeout=900,    # 15 minutes connect timeout\n",
    "    retries=dict(max_attempts=3, mode=\"adaptive\"),\n",
    ")\n",
    "\n",
    "\n",
    "def get_model(model_id=NOVA_RPO_MODEL_ID, thinking=False,\n",
    "              temperature=0.7, max_tokens=10000):\n",
    "    \"\"\"\n",
    "    Create and return a Bedrock model instance.\n",
    "\n",
    "    Args:\n",
    "        model_id (str): The specific model ID to use\n",
    "        thinking (bool): Whether to enable thinking mode for supported models\n",
    "        temperature (float): Sampling temperature for response generation\n",
    "        max_tokens (int): Maximum tokens in the response\n",
    "\n",
    "    Returns:\n",
    "        BedrockModel instance\n",
    "    \"\"\"\n",
    "    session = boto3.Session()\n",
    "\n",
    "    # Configure thinking mode for supported models\n",
    "    additional_request_fields = {}\n",
    "    if thinking:\n",
    "        additional_request_fields = {\n",
    "            \"thinking\": {\n",
    "                \"type\": \"enabled\",\n",
    "                \"budget_tokens\": 4096,\n",
    "            }\n",
    "        }\n",
    "\n",
    "    return BedrockModel(\n",
    "        model_id=model_id,\n",
    "        boto_session=session,\n",
    "        max_tokens=max_tokens,\n",
    "        temperature=temperature,\n",
    "        boto_client_config=boto_client_config,\n",
    "        additional_request_fields=additional_request_fields,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "15ed67dc-8420-4655-b596-9a117a84749e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a model instance that will be shared by all our agents\n",
    "# This ensures consistent behavior across the multi-agent system\n",
    "llm = get_model(NOVA_RPO_MODEL_ID)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec585f6d-4ebc-4f08-9733-526f9bda03fc",
   "metadata": {},
   "source": [
    "## 3. Agent Definitions\n",
    "\n",
    "### 3.1 Bear Researcher Agent\n",
    "\n",
    "The Bear Researcher agent represents the cautious, risk-focused perspective in our investment analysis system. This agent is designed to:\n",
    "\n",
    "**Core Responsibilities:**\n",
    "- Identify and analyze potential investment risks and downsides\n",
    "- Challenge overly optimistic assumptions with data-driven counterarguments\n",
    "- Provide essential risk perspective to prevent overconfident investment decisions\n",
    "- Engage in constructive debates with bullish analysts\n",
    "\n",
    "**Analytical Framework:**\n",
    "The Bear Researcher employs a comprehensive risk assessment framework covering:\n",
    "- Financial and operational risks (debt levels, cash flow, margins)\n",
    "- Market and competitive threats (saturation, disruption, regulation)\n",
    "- Macroeconomic headwinds (recession, interest rates, inflation)\n",
    "- Valuation concerns (overvaluation, market bubbles, volatility)\n",
    "\n",
    "**Debate Strategy:**\n",
    "- Present arguments with analytical rigor and healthy skepticism\n",
    "- Use historical precedents and market cycles as supporting evidence\n",
    "- Directly challenge bullish assumptions with concrete data\n",
    "- Focus on downside protection and risk management"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aa5ce16b-f704-49f5-a74e-5691a69533be",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Bear Researcher Agent\n",
    "\"\"\"\n",
    "\n",
    "from strands import Agent\n",
    "\n",
    "def create_bear_researcher(llm, config):\n",
    "    \"\"\"\n",
    "    Create a Bear Researcher agent that advocates for cautious investment positions.\n",
    "    \n",
    "    Args:\n",
    "        llm: The language model to use for the agent\n",
    "        config (dict): Configuration settings for the agent\n",
    "        \n",
    "    Returns:\n",
    "        Agent: Configured Bear Researcher agent\n",
    "    \"\"\"\n",
    "    \n",
    "    system_message = (\n",
    "        \"\"\"You are a Bear Researcher specializing in risk analysis and investment caution. \n",
    "        Your role is to advocate against risky investments by presenting well-researched, \n",
    "        evidence-based arguments that emphasize potential downsides and market risks.\n",
    "\n",
    "        **Key Responsibilities:**\n",
    "        1. Build compelling cases against overvalued or risky investments\n",
    "        2. Counter bullish arguments with solid risk analysis and data\n",
    "        3. Engage in constructive debate with bull analysts\n",
    "        4. Learn from past investment decisions and market downturns\n",
    "\n",
    "        **Risk Assessment Framework:**\n",
    "\n",
    "        **Financial and Operational Risks:**\n",
    "        - Declining revenue trends and margin compression\n",
    "        - High debt levels and liquidity concerns\n",
    "        - Poor cash flow management and capital allocation\n",
    "        - Overvaluation relative to fundamentals\n",
    "        - Accounting irregularities or transparency issues\n",
    "\n",
    "        **Market and Competitive Threats:**\n",
    "        - Market saturation and limited growth opportunities\n",
    "        - Intense competition and pricing pressure\n",
    "        - Technological disruption and obsolescence risks\n",
    "        - Loss of market share to competitors\n",
    "        - Regulatory threats and compliance costs\n",
    "\n",
    "        **Macroeconomic Headwinds:**\n",
    "        - Economic recession or slowdown risks\n",
    "        - Interest rate sensitivity and credit tightening\n",
    "        - Inflation impact on costs and margins\n",
    "        - Currency fluctuation risks for international exposure\n",
    "        - Geopolitical tensions affecting operations\n",
    "\n",
    "        **Industry-Specific Challenges:**\n",
    "        - Cyclical downturns and seasonal volatility\n",
    "        - Supply chain disruptions and cost inflation\n",
    "        - Regulatory changes and policy shifts\n",
    "        - Environmental and social governance risks\n",
    "        - Technological shifts disrupting business models\n",
    "\n",
    "        **Valuation and Market Concerns:**\n",
    "        - Overvaluation relative to peers and historical metrics\n",
    "        - Excessive market optimism and bubble indicators\n",
    "        - Poor risk-adjusted returns and volatility\n",
    "        - Liquidity concerns and market depth issues\n",
    "        - Institutional selling pressure and insider activity\n",
    "\n",
    "        **Debate Strategy:**\n",
    "        - Present arguments in a conversational, analytical style\n",
    "        - Directly challenge bull analyst assumptions with data\n",
    "        - Highlight overlooked risks and potential downsides\n",
    "        - Use historical precedents and market cycles as evidence\n",
    "        - Expose weaknesses in bullish investment theses\n",
    "\n",
    "        **Learning and Improvement:**\n",
    "        - Use get_financial_situation_memories to review past market downturns\n",
    "        - Identify patterns in market bubbles and corrections\n",
    "        - Apply lessons from previous bear market calls\n",
    "        - Refine risk assessment models based on historical accuracy\n",
    "\n",
    "        **Communication Guidelines:**\n",
    "        1. Present arguments with analytical rigor and skepticism\n",
    "        2. Use concrete data and historical examples\n",
    "        3. Challenge assumptions and highlight blind spots\n",
    "        4. Maintain objectivity while being persuasively cautious\n",
    "        5. Focus on downside protection and risk management\n",
    "        6. Provide alternative scenarios and stress testing\n",
    "\n",
    "        **Hand-off Guidelines:**\n",
    "        - You should first give your own analysis.\n",
    "        - If another researcher hasn't provided the final/completed analysis, you can directly hand off to the relevant researcher when you need to.\n",
    "\n",
    "        Remember: Your goal is to provide essential risk perspective and protect against \n",
    "        overoptimistic investment decisions while maintaining analytical integrity.\n",
    "\n",
    "        Need to Write your final analysis!\n",
    "        \"\"\"\n",
    "    )\n",
    "\n",
    "    # Create and configure the agent\n",
    "    agent = Agent(\n",
    "        model=llm,\n",
    "        name=\"Bear Researcher\",\n",
    "        callback_handler=None,  # Disabled for parallel execution in debates\n",
    "        system_prompt=system_message,\n",
    "        load_tools_from_directory=False,\n",
    "    )\n",
    "    \n",
    "    # Set agent state for configuration access\n",
    "    agent.state.set(\"config\", config)\n",
    "\n",
    "    return agent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae56b44e-f0c4-4a7d-97f4-abd1be5a105e",
   "metadata": {},
   "source": [
    "### 3.2 Bull Researcher Agent\n",
    "\n",
    "The Bull Researcher agent represents the optimistic, growth-focused perspective in our investment analysis system. This agent is designed to:\n",
    "\n",
    "**Core Responsibilities:**\n",
    "- Identify and analyze investment opportunities and growth potential\n",
    "- Build compelling cases for positive investment positions\n",
    "- Counter pessimistic arguments with solid data and reasoning\n",
    "- Highlight competitive advantages and market opportunities\n",
    "\n",
    "**Analytical Framework:**\n",
    "The Bull Researcher employs a comprehensive growth assessment framework covering:\n",
    "- Growth potential (market expansion, revenue projections, innovation)\n",
    "- Competitive advantages (differentiation, brand strength, market position)\n",
    "- Financial strength (profitability, cash generation, balance sheet health)\n",
    "- Market dynamics (trends, catalysts, positive sentiment)\n",
    "\n",
    "**Debate Strategy:**\n",
    "- Present arguments with data-driven optimism and evidence\n",
    "- Use growth metrics and forward-looking indicators\n",
    "- Counter bearish concerns with strategic advantages\n",
    "- Focus on long-term value creation and market opportunities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cca1bed8-08aa-426b-b95f-4aed0b5d26b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Bull Researcher Agent\n",
    "\"\"\"\n",
    "\n",
    "def create_bull_researcher(llm, config):\n",
    "    \"\"\"\n",
    "    Create a Bull Researcher agent that advocates for positive investment positions.\n",
    "    \n",
    "    Args:\n",
    "        llm: The language model to use for the agent\n",
    "        config (dict): Configuration settings for the agent\n",
    "        \n",
    "    Returns:\n",
    "        Agent: Configured Bull Researcher agent\n",
    "    \"\"\"\n",
    "    \n",
    "    system_message = (\n",
    "        \"\"\"You are a Bull Researcher specializing in building strong investment cases for stocks. \n",
    "        Your role is to advocate for positive investment positions by presenting well-researched, \n",
    "        evidence-based arguments that emphasize growth potential and competitive advantages.\n",
    "\n",
    "        **Key Responsibilities:**\n",
    "        1. Build compelling cases for investment opportunities\n",
    "        2. Counter bearish arguments with solid data and reasoning\n",
    "        3. Engage in constructive debate with bear analysts\n",
    "        4. Learn from past investment decisions and mistakes\n",
    "\n",
    "        **Analysis Framework:**\n",
    "\n",
    "        **Growth Potential Assessment:**\n",
    "        - Market opportunity size and expansion potential\n",
    "        - Revenue growth projections and scalability factors\n",
    "        - New product launches and innovation pipeline\n",
    "        - Geographic expansion opportunities\n",
    "        - Market share growth potential\n",
    "\n",
    "        **Competitive Advantages:**\n",
    "        - Unique products or services with strong differentiation\n",
    "        - Brand strength and customer loyalty\n",
    "        - Dominant market positioning and barriers to entry\n",
    "        - Technological advantages and intellectual property\n",
    "        - Cost advantages and operational efficiency\n",
    "\n",
    "        **Positive Financial Indicators:**\n",
    "        - Strong financial health metrics (revenue, profit margins, cash flow)\n",
    "        - Improving financial trends and performance metrics\n",
    "        - Strong balance sheet and low debt levels\n",
    "        - Efficient capital allocation and return on investment\n",
    "        - Dividend growth and shareholder returns\n",
    "\n",
    "        **Market and Industry Trends:**\n",
    "        - Favorable industry tailwinds and secular trends\n",
    "        - Positive regulatory environment changes\n",
    "        - Increasing demand for company's products/services\n",
    "        - Supply chain advantages and partnerships\n",
    "        - ESG (Environmental, Social, Governance) strengths\n",
    "\n",
    "        **Debate Strategy:**\n",
    "        - Present arguments in a conversational, engaging style\n",
    "        - Directly address and counter bear analyst concerns\n",
    "        - Use specific data and evidence to support positions\n",
    "        - Acknowledge risks while demonstrating why positives outweigh negatives\n",
    "        - Build on previous arguments and strengthen the investment thesis\n",
    "\n",
    "        **Learning and Improvement:**\n",
    "        - Use get_financial_situation_memories to review past investment decisions\n",
    "        - Identify patterns in successful and unsuccessful investment theses\n",
    "        - Apply lessons learned to current analysis and recommendations\n",
    "        - Continuously refine analytical approach based on historical performance\n",
    "\n",
    "        **Communication Guidelines:**\n",
    "        1. Present arguments conversationally and engagingly\n",
    "        2. Use specific data points and concrete evidence\n",
    "        3. Address counterarguments proactively and thoroughly\n",
    "        4. Build momentum in debates by reinforcing strong points\n",
    "        5. Maintain professional tone while being persuasive\n",
    "        6. Focus on actionable insights and clear investment rationale\n",
    "\n",
    "        **Hand-off Guidelines:**\n",
    "        - You should first give your own analysis, and then directly hand off to the relevant researcher when you need to.\n",
    "        - If another researcher hasn't provided the final/completed analysis, you can directly hand off to the relevant researcher when needed. Otherwise, you cannot hand off to them.\n",
    "\n",
    "\n",
    "        Remember: Your goal is to build the strongest possible case for investment while \n",
    "        maintaining intellectual honesty and acknowledging legitimate concerns.\n",
    "\n",
    "        Need to Write your final analysis!\n",
    "        \"\"\"\n",
    "    )\n",
    "\n",
    "    # Create and configure the agent\n",
    "    agent = Agent(\n",
    "        model=llm,\n",
    "        name=\"Bull Researcher\",\n",
    "        callback_handler=None,  # Disabled for parallel execution in debates\n",
    "        system_prompt=system_message,\n",
    "        load_tools_from_directory=False,\n",
    "    )\n",
    "    \n",
    "    # Set agent state for configuration access\n",
    "    agent.state.set(\"config\", config)\n",
    "\n",
    "    return agent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48d48d8d-8e70-43af-9ff9-e17282377ba3",
   "metadata": {},
   "source": [
    "### 3.3 Research Manager Agent\n",
    "\n",
    "The Research Manager agent serves as the senior decision-maker who synthesizes insights from both Bull and Bear researchers to make final investment recommendations. This agent represents the role of a portfolio manager or investment committee chair.\n",
    "\n",
    "**Core Responsibilities:**\n",
    "- Coordinate and facilitate debates between bull and bear analysts\n",
    "- Critically evaluate arguments from multiple perspectives\n",
    "- Synthesize conflicting viewpoints into coherent investment decisions\n",
    "- Provide clear, actionable investment recommendations with rationale\n",
    "\n",
    "**Decision-Making Framework:**\n",
    "- **Argument Evaluation**: Assess the strength and validity of bull vs bear cases\n",
    "- **Risk-Return Analysis**: Balance potential upside against downside risks\n",
    "- **Implementation Strategy**: Define specific actions (Buy/Sell/Hold) with timing\n",
    "- **Risk Management**: Establish position sizing and stop-loss parameters\n",
    "\n",
    "**Synthesis Approach:**\n",
    "- Identify the most compelling evidence from both sides\n",
    "- Resolve contradictions through deeper analysis\n",
    "- Make decisions based on probability-weighted outcomes\n",
    "- Communicate decisions with clear reasoning and confidence levels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7be9b154-c805-4550-af2d-a5c683aa256d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Research Manager Agent\n",
    "\"\"\"\n",
    "\n",
    "def create_research_manager(llm, config):\n",
    "    \"\"\"\n",
    "    Create a Research Manager agent that coordinates debates and makes investment decisions.\n",
    "    \n",
    "    Args:\n",
    "        llm: The language model to use for the agent\n",
    "        config (dict): Configuration settings for the agent\n",
    "        \n",
    "    Returns:\n",
    "        Agent: Configured Research Manager agent\n",
    "    \"\"\"\n",
    "    \n",
    "    system_message = (\n",
    "        \"\"\"You are a Research Manager and Portfolio Manager responsible for coordinating \n",
    "        research team debates and making definitive investment decisions. Your role is to \n",
    "        critically evaluate arguments from both bull and bear analysts and provide clear, \n",
    "        actionable investment recommendations.\n",
    "\n",
    "        **Key Responsibilities:**\n",
    "        1. Facilitate and evaluate research team debates\n",
    "        2. Make definitive investment decisions (Buy, Sell, or Hold)\n",
    "        3. Develop detailed investment plans for the trading team\n",
    "        4. Learn from past investment decisions and outcomes\n",
    "\n",
    "        **Decision-Making Framework:**\n",
    "\n",
    "        **Debate Evaluation Process:**\n",
    "        - Critically assess the strength of bull and bear arguments\n",
    "        - Identify the most compelling evidence and reasoning from each side\n",
    "        - Evaluate the quality of data and analysis presented\n",
    "        - Consider risk-reward ratios and probability-weighted outcomes\n",
    "        - Assess market timing and execution feasibility\n",
    "\n",
    "        **Investment Decision Criteria:**\n",
    "        - **Buy**: Strong bull case with manageable risks and favorable risk-reward\n",
    "        - **Sell**: Significant risks outweigh potential returns or overvaluation concerns\n",
    "        - **Hold**: Only when genuinely balanced arguments justify maintaining position\n",
    "        - Avoid defaulting to Hold - commit to a clear stance based on evidence\n",
    "\n",
    "        **Investment Plan Development:**\n",
    "        Create comprehensive plans including:\n",
    "        - Clear recommendation with supporting rationale\n",
    "        - Risk assessment and mitigation strategies\n",
    "        - Position sizing and entry/exit criteria\n",
    "        - Timeline and milestone monitoring\n",
    "        - Contingency plans for different scenarios\n",
    "\n",
    "        **Risk Management Considerations:**\n",
    "        - Portfolio diversification and concentration limits\n",
    "        - Correlation with existing positions\n",
    "        - Liquidity requirements and market conditions\n",
    "        - Volatility expectations and drawdown limits\n",
    "        - Regulatory and compliance considerations\n",
    "\n",
    "        **Learning and Improvement:**\n",
    "        - Review past investment decisions and their outcomes\n",
    "        - Identify patterns in successful and unsuccessful calls\n",
    "        - Analyze debate quality and decision-making processes\n",
    "        - Refine evaluation criteria based on historical performance\n",
    "        - Update investment frameworks based on market evolution\n",
    "\n",
    "        **Communication Style:**\n",
    "        1. Present analysis conversationally and naturally\n",
    "        2. Avoid excessive formatting or bullet points\n",
    "        3. Provide clear, decisive recommendations\n",
    "        4. Explain reasoning in accessible terms\n",
    "        5. Address both opportunities and risks transparently\n",
    "        6. Focus on actionable insights for the trading team\n",
    "\n",
    "        **Decision Output Requirements:**\n",
    "        - **Investment Recommendation**: Clear Buy/Sell/Hold decision\n",
    "        - **Rationale**: Explanation of why this decision is optimal\n",
    "        - **Strategic Actions**: Concrete implementation steps\n",
    "        - **Risk Factors**: Key risks and mitigation approaches\n",
    "        - **Success Metrics**: How to measure investment performance\n",
    "        - **Review Timeline**: When to reassess the position\n",
    "\n",
    "        **Tools Available:**\n",
    "        - get_financial_situation_memories: Review past investment decisions and lessons\n",
    "        - Note: Do NOT use add_financial_situation_memories during evaluation\n",
    "\n",
    "        **Critical Guidelines:**\n",
    "        - Make decisive recommendations based on the strongest arguments\n",
    "        - Don't default to Hold unless truly justified by balanced evidence\n",
    "        - Consider both short-term and long-term implications\n",
    "        - Account for market conditions and timing factors\n",
    "        - Maintain objectivity while being actionable\n",
    "        - Learn from past mistakes to improve future decisions\n",
    "\n",
    "        Remember: Your role is to synthesize complex debates into clear, actionable \n",
    "        investment strategies that maximize risk-adjusted returns for the portfolio.\n",
    "        \"\"\"\n",
    "    )\n",
    "\n",
    "    # Create and configure the agent\n",
    "    agent = Agent(\n",
    "        model=llm,\n",
    "        name=\"Research Manager\",\n",
    "        system_prompt=system_message,\n",
    "        load_tools_from_directory=False,\n",
    "    )\n",
    "    \n",
    "    # Set agent state for configuration access\n",
    "    agent.state.set(\"config\", config)\n",
    "    \n",
    "    return agent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c92d059a-f640-408d-a012-26332b44a0dd",
   "metadata": {},
   "source": [
    "## 4. Multi-Agent Coordination System\n",
    "\n",
    "### 4.1 Conversation Swarm Implementation\n",
    "\n",
    "The ConversationSwarm class orchestrates sophisticated multi-agent debates and discussions. This system enables our Bull and Bear researchers to engage in structured, productive conversations that lead to well-reasoned investment decisions.\n",
    "\n",
    "**Key Features:**\n",
    "- **Structured Debates**: Manages turn-taking and ensures balanced participation\n",
    "- **Dynamic Handoffs**: Agents can transfer control based on expertise areas\n",
    "- **Timeout Management**: Prevents infinite loops and ensures timely decisions\n",
    "- **Conversation History**: Tracks all interactions for analysis and learning\n",
    "\n",
    "**Execution Phases:**\n",
    "1. **Initial Analysis**: Both agents provide independent perspectives\n",
    "2. **Interactive Debate**: Agents challenge and refine each other's arguments\n",
    "3. **Synthesis**: Research Manager creates final investment recommendation\n",
    "\n",
    "**Configuration Parameters:**\n",
    "- **Max Handoffs**: Limits conversation length (prevents endless debates)\n",
    "- **Execution Timeout**: Overall time limit for the entire conversation\n",
    "- **Node Timeout**: Time limit for individual agent responses\n",
    "- **Repetition Detection**: Prevents circular arguments and ensures progress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "75758ddd-4cd6-4d88-92f5-49c85f116f8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Conversation Swarm\n",
    "\"\"\"\n",
    "\n",
    "import logging\n",
    "from strands.multiagent import Swarm\n",
    "\n",
    "\n",
    "# Enable debug logs and print them to stderr\n",
    "logging.getLogger(\"strands.multiagent\").setLevel(logging.DEBUG)\n",
    "logging.basicConfig(\n",
    "    format=\"%(levelname)s | %(name)s | %(message)s\",\n",
    "    handlers=[logging.StreamHandler()]\n",
    ")\n",
    "\n",
    "\n",
    "class ConversationSwarm:\n",
    "    \"\"\"\n",
    "    A multi-agent conversation system for coordinating debates and discussions.\n",
    "    \n",
    "    This class manages interactions between multiple agents, allowing them to\n",
    "    collaborate, compete, or use hybrid approaches to analyze trading scenarios\n",
    "    and reach consensus decisions.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, agents, summarizer_agent):\n",
    "        \"\"\"\n",
    "        Initialize the ConversationSwarm with agents and collabrative strategy.\n",
    "        \n",
    "        Args:\n",
    "            agents (list): List of agent instances to participate in discussions\n",
    "            summarizer_agent: Agent responsible for synthesizing final decisions\n",
    "        \"\"\"\n",
    "        self.agents = agents\n",
    "        self.summarizer_agent = summarizer_agent\n",
    "        \n",
    "    def run(self, task):\n",
    "        \"\"\"\n",
    "        Execute a multi-phase conversation between agents to analyze a task.\n",
    "        \n",
    "        The conversation follows a structured approach:\n",
    "        1. Initial parallel analysis by all agents\n",
    "        2. Refinement phase where agents respond to each other's insights\n",
    "        3. Final synthesis by the summarizer agent\n",
    "        \n",
    "        Args:\n",
    "            task (str): The trading task or question to analyze\n",
    "            \n",
    "        Returns:\n",
    "            tuple: (final_solution, messages_dict) containing the synthesized\n",
    "                   decision and all conversation messages\n",
    "        \"\"\"\n",
    "        \n",
    "        # Initialize message dictionary to track all agent communications\n",
    "        messages = {}\n",
    "        messages[self.summarizer_agent.name] = []\n",
    "        for agent in self.agents:\n",
    "            messages[agent.name] = []\n",
    "        \n",
    "        print(f\"Starting collabrative conversation with {len(self.agents)} agents...\")\n",
    "        # Create a swarm with these agents\n",
    "        swarm = Swarm(\n",
    "            self.agents,\n",
    "            max_handoffs=10,\n",
    "            max_iterations=10,\n",
    "            execution_timeout=2400.0,  # 15 minutes\n",
    "            node_timeout=600.0,       # 5 minutes per agent\n",
    "            repetitive_handoff_detection_window=8,  # There must be >= 3 unique agents in the last 8 handoffs\n",
    "            repetitive_handoff_min_unique_agents=5\n",
    "        )\n",
    "\n",
    "        # Execute the swarm on a task\n",
    "        print(\"Phase 1: Swarm conversation between bull reseacher and bear reseacher...\")\n",
    "        result = swarm(task)\n",
    "\n",
    "        # Access the final result\n",
    "        print(f\"Status: {result.status}\")\n",
    "        print(f\"Node history: {[node.node_id for node in result.node_history]}\")\n",
    "        save_as_file(\",\".join([node.node_id for node in result.node_history]), working_dir, prefix, \"node_history.txt\")\n",
    "        \n",
    "        bull_history, bear_history = None, None\n",
    "        for message in self.agents[0].messages[::-1]:\n",
    "            if message[\"role\"] != \"assistant\" or len(message[\"content\"]) == 0:\n",
    "                continue\n",
    "            else:\n",
    "                for item in message[\"content\"]:\n",
    "                    if \"text\" in item:\n",
    "                        bull_history = item[\"text\"]\n",
    "                break\n",
    "\n",
    "        for message in self.agents[1].messages[::-1]:\n",
    "            if message[\"role\"] != \"assistant\" or len(message[\"content\"]) == 0:\n",
    "                continue\n",
    "            else:\n",
    "                for item in message[\"content\"]:\n",
    "                    if \"text\" in item:\n",
    "                        bear_history = item[\"text\"]\n",
    "                break\n",
    "        print(\"Phase 2: Final synthesis and decision...\")\n",
    "        \n",
    "        summarizer_prompt = f\"\"\"\n",
    "Original Investment Analysis Task:\n",
    "<query>\n",
    "{task}\n",
    "</query>\n",
    "\n",
    "You have received comprehensive analyses from the research team. Please synthesize \n",
    "these inputs into a final investment decision and strategy:\n",
    "\n",
    "<team_analyses>\n",
    "Bull Reseacher: \n",
    "{bull_history}\n",
    "\n",
    "Bear Reseacher:\n",
    "{bear_history}\n",
    "</team_analyses>\n",
    "\n",
    "Your synthesis should:\n",
    "1. Evaluate the strength of arguments from both bull and bear perspectives\n",
    "2. Identify the most compelling evidence and reasoning\n",
    "3. Make a clear investment recommendation (Buy, Sell, or Hold)\n",
    "4. Provide a detailed rationale for your decision\n",
    "5. Outline specific implementation strategies\n",
    "6. Address key risks and mitigation approaches\n",
    "\n",
    "Create a comprehensive final investment plan that incorporates the best insights \n",
    "from the team while addressing any concerns or contradictions in their analyses.\n",
    "\"\"\"\n",
    "\n",
    "        print(\"Generating final synthesis...\")\n",
    "        final_solution = self.summarizer_agent(summarizer_prompt)\n",
    "        \n",
    "        print(\"Conversation completed successfully!\")\n",
    "        \n",
    "        return final_solution, bull_history, bear_history"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "434bca19-deb1-4cc3-b968-8b8ab0f58547",
   "metadata": {},
   "source": [
    "## 5. System Execution and Analysis\n",
    "\n",
    "### 5.1 Initialize Multi-Agent Investment Analysis\n",
    "\n",
    "This section demonstrates how to set up and execute our multi-agent investment analysis system. We'll create instances of our agents and coordinate their collaboration through the Swarm framework.\n",
    "\n",
    "**Setup Process:**\n",
    "1. **Configuration**: Define analysis parameters (stock ticker, date, output directory)\n",
    "2. **Agent Creation**: Instantiate Bull Researcher, Bear Researcher, and Research Manager\n",
    "3. **Swarm Assembly**: Create ConversationSwarm with proper coordination settings\n",
    "4. **Data Loading**: Import relevant market reports and news for context\n",
    "5. **Execution**: Run the multi-agent analysis and capture results\n",
    "\n",
    "**Key Configuration Variables:**\n",
    "- `company_of_interest`: Stock ticker symbol for analysis (e.g., 'AMZN')\n",
    "- `trade_date`: Analysis date for temporal context\n",
    "- `working_dir`: Output directory for saving analysis results\n",
    "- `prefix`: File naming convention for organized output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "943e5359-40f3-481a-84cc-52899600b60a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from model_utils import get_model, save_as_file, read_file\n",
    "from default_config import DEFAULT_CONFIG\n",
    "# Configuration\n",
    "company_of_interest = \"AMZN\"  # Stock ticker to analyze\n",
    "trade_date = \"2025-08-19\"    # Analysis date\n",
    "working_dir = DEFAULT_CONFIG['results_dir']\n",
    "prefix = f\"{company_of_interest}_{trade_date}\".replace(\" \", \"_\")\n",
    "config = DEFAULT_CONFIG.copy()\n",
    "\n",
    "bull_researcher = create_bull_researcher(llm, config)\n",
    "bear_researcher = create_bear_researcher(llm, config)\n",
    "research_manager = create_research_manager(llm, config)\n",
    "\n",
    "# Create debate swarm with collabrative coordination\n",
    "research_debate = ConversationSwarm(\n",
    "    agents=[bull_researcher, bear_researcher],\n",
    "    summarizer_agent=research_manager\n",
    ")\n",
    "\n",
    "# Load previous reports for context\n",
    "market_report = read_file(working_dir, prefix, \"market_report.txt\")\n",
    "news_report = read_file(working_dir, prefix, \"news_report.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6684c95b-1385-439a-947b-658e3e7f3eeb",
   "metadata": {},
   "source": [
    "### 5.2 Execute Multi-Agent Investment Analysis\n",
    "\n",
    "This section demonstrates the execution of our multi-agent investment analysis system. The process involves:\n",
    "\n",
    "**Execution Flow:**\n",
    "1. **Agent Initialization**: Create Bull Researcher, Bear Researcher, and Research Manager instances\n",
    "2. **Context Loading**: Import market reports and news data for informed analysis\n",
    "3. **Swarm Execution**: Run structured debate between Bull and Bear researchers\n",
    "4. **Synthesis**: Research Manager creates final investment recommendation\n",
    "5. **Output Generation**: Save all analyses and decisions to files\n",
    "\n",
    "**Debug Information:**\n",
    "The debug logs show the detailed execution flow:\n",
    "- Node handoffs between Bull and Bear researchers\n",
    "- Iteration counts and timing information\n",
    "- Completion status and execution metrics\n",
    "\n",
    "**Expected Outcomes:**\n",
    "- Comprehensive bull and bear analyses\n",
    "- Structured debate with multiple rounds of interaction\n",
    "- Final synthesized investment recommendation\n",
    "- Detailed execution logs for analysis and improvement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "88c7d042-c0f1-4403-9cf6-5765189bc552",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG | strands.multiagent.swarm | nodes=<['Bull Researcher', 'Bear Researcher']> | initialized swarm with nodes\n",
      "DEBUG | strands.multiagent.swarm | tool_count=<1>, node_count=<2> | injected coordination tools into agents\n",
      "DEBUG | strands.multiagent.swarm | starting swarm execution\n",
      "DEBUG | strands.multiagent.swarm | current_node=<Bull Researcher> | starting swarm execution with node\n",
      "DEBUG | strands.multiagent.swarm | max_handoffs=<10>, max_iterations=<10>, timeout=<2400.0>s | swarm execution config\n",
      "DEBUG | strands.multiagent.swarm | current_node=<Bull Researcher>, iteration=<1> | executing node\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 3: Running research team debate...\n",
      "Starting collabrative conversation with 2 agents...\n",
      "Phase 1: Swarm conversation between bull reseacher and bear reseacher...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG | strands.multiagent.swarm | from_node=<Bull Researcher>, to_node=<Bear Researcher> | handed off from agent to agent\n",
      "DEBUG | strands.multiagent.swarm | node=<Bull Researcher> | node execution completed\n",
      "DEBUG | strands.multiagent.swarm | current_node=<Bear Researcher>, iteration=<2> | executing node\n",
      "DEBUG | strands.multiagent.swarm | from_node=<Bear Researcher>, to_node=<Bull Researcher> | handed off from agent to agent\n",
      "DEBUG | strands.multiagent.swarm | node=<Bear Researcher> | node execution completed\n",
      "DEBUG | strands.multiagent.swarm | current_node=<Bull Researcher>, iteration=<3> | executing node\n",
      "DEBUG | strands.multiagent.swarm | from_node=<Bull Researcher>, to_node=<Bear Researcher> | handed off from agent to agent\n",
      "DEBUG | strands.multiagent.swarm | node=<Bull Researcher> | node execution completed\n",
      "DEBUG | strands.multiagent.swarm | current_node=<Bear Researcher>, iteration=<4> | executing node\n",
      "DEBUG | strands.multiagent.swarm | from_node=<Bear Researcher>, to_node=<Bull Researcher> | handed off from agent to agent\n",
      "DEBUG | strands.multiagent.swarm | node=<Bear Researcher> | node execution completed\n",
      "DEBUG | strands.multiagent.swarm | current_node=<Bull Researcher>, iteration=<5> | executing node\n",
      "DEBUG | strands.multiagent.swarm | from_node=<Bull Researcher>, to_node=<Bear Researcher> | handed off from agent to agent\n",
      "DEBUG | strands.multiagent.swarm | node=<Bull Researcher> | node execution completed\n",
      "DEBUG | strands.multiagent.swarm | current_node=<Bear Researcher>, iteration=<6> | executing node\n",
      "DEBUG | strands.multiagent.swarm | from_node=<Bear Researcher>, to_node=<Bull Researcher> | handed off from agent to agent\n",
      "DEBUG | strands.multiagent.swarm | node=<Bear Researcher> | node execution completed\n",
      "DEBUG | strands.multiagent.swarm | current_node=<Bull Researcher>, iteration=<7> | executing node\n",
      "DEBUG | strands.multiagent.swarm | from_node=<Bull Researcher>, to_node=<Bear Researcher> | handed off from agent to agent\n",
      "DEBUG | strands.multiagent.swarm | node=<Bull Researcher> | node execution completed\n",
      "DEBUG | strands.multiagent.swarm | current_node=<Bear Researcher>, iteration=<8> | executing node\n",
      "DEBUG | strands.multiagent.swarm | node=<Bear Researcher> | node execution completed\n",
      "DEBUG | strands.multiagent.swarm | node=<Bear Researcher> | no handoff occurred, marking swarm as complete\n",
      "DEBUG | strands.multiagent.swarm | status=<Status.COMPLETED> | swarm execution completed\n",
      "DEBUG | strands.multiagent.swarm | node_history_length=<8>, time=<241.14>s | metrics\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status: Status.COMPLETED\n",
      "Node history: ['Bull Researcher', 'Bear Researcher', 'Bull Researcher', 'Bear Researcher', 'Bull Researcher', 'Bear Researcher', 'Bull Researcher', 'Bear Researcher']\n",
      "Phase 2: Final synthesis and decision...\n",
      "Generating final synthesis...\n",
      "### Final Investment Decision and Strategy for Amazon (AMZN) on 2025-08-19\n",
      "\n",
      "#### **Evaluation of Bull and Bear Arguments**\n",
      "\n",
      "**Bull Perspective:**\n",
      "- **Strong Growth Drivers:** AWS, advertising, and capex continue to drive long-term growth.\n",
      "- **Positive Momentum:** Technical indicators like MACD and VWMA suggest positive momentum and strong buying volume.\n",
      "- **Upside Potential:** Analysts predict a median price target of $264.21, indicating significant upside potential.\n",
      "- **Bullish Sentiment:** Major tech stocks, including AMZN, are forecasted to be bullish.\n",
      "\n",
      "**Bear Perspective:**\n",
      "- **Slower Growth:** Concerns over Amazon's slower revenue growth compared to peers.\n",
      "- **High Debt and Liquidity Concerns:** High capex leading to potential debt and liquidity issues.\n",
      "- **Market Saturation:** The e-commerce market is becoming saturated, limiting growth opportunities.\n",
      "- **Regulatory and Macroeconomic Risks:** Increasing regulatory scrutiny and potential economic slowdowns pose significant threats.\n",
      "\n",
      "#### **Compelling Evidence and Reasoning**\n",
      "\n",
      "- **Positive Momentum:** The MACD and VWMA indicate strong buying volume and positive momentum, supporting the bull case.\n",
      "- **Long-Term Growth Drivers:** AWS, advertising, and capex are robust growth drivers that justify long-term optimism.\n",
      "- **Market Sentiment:** The bullish outlook for major tech stocks adds to the positive sentiment around AMZN.\n",
      "- **Risks:** The bear case highlights significant risks, including slower growth, high debt, market saturation, and regulatory challenges.\n",
      "\n",
      "#### **Investment Recommendation: Hold**\n",
      "\n",
      "Given the balanced but slightly tilted evidence towards the bull case, the recommendation is to **Hold** Amazon (AMZN) stock. This decision is based on the following rationale:\n",
      "\n",
      "1. **Positive Momentum and Technical Indicators:** The stock is in an uptrend with positive momentum, supported by technical indicators.\n",
      "2. **Long-Term Growth Potential:** Strong growth drivers like AWS and advertising justify a long-term optimistic view.\n",
      "3. **Moderate Valuation:** The stock is trading at 32x forward earnings, which is below the historical average, suggesting some room for growth.\n",
      "4. **Risk Mitigation:** The bear case highlights significant risks that need to be monitored, justifying a cautious approach.\n",
      "\n",
      "#### **Detailed Implementation Strategy**\n",
      "\n",
      "1. **Position Sizing:** Maintain the current position size, avoiding significant increases or decreases.\n",
      "2. **Entry/Exit Criteria:** \n",
      "   - **Entry:** Consider buying additional shares if the stock approaches the 50-day SMA with positive MACD and RSI signals.\n",
      "   - **Exit:** Sell if the stock approaches the Bollinger Upper Band or shows significant divergence in the MACD Histogram.\n",
      "3. **Risk Assessment and Mitigation:**\n",
      "   - **Diversification:** Ensure the portfolio is diversified to mitigate concentration risk.\n",
      "   - **Stop-Loss:** Implement a stop-loss order at 10% below the current price to protect against significant downside.\n",
      "   - **Regular Monitoring:** Continuously monitor key risk factors, including revenue growth, debt levels, and regulatory changes.\n",
      "4. **Timeline and Milestone Monitoring:**\n",
      "   - **Short-Term:** Monitor technical indicators and market sentiment over the next quarter.\n",
      "   - **Long-Term:** Review the investment thesis annually to ensure alignment with long-term growth drivers.\n",
      "5. **Contingency Plans:**\n",
      "   - **Economic Downturn:** Reduce position size if economic indicators suggest a potential recession.\n",
      "   - **Regulatory Changes:** Adjust strategy based on new regulatory developments that could impact Amazon’s operations.\n",
      "\n",
      "#### **Key Risks and Mitigation Approaches**\n",
      "\n",
      "1. **Market Competition:** Continuously monitor competitor activities and Amazon’s market share.\n",
      "2. **Regulatory Risks:** Stay updated on regulatory changes and their potential impact on Amazon’s operations.\n",
      "3. **Macroeconomic Factors:** Keep an eye on economic indicators and adjust the investment strategy accordingly.\n",
      "4. **Valuation Concerns:** Regularly reassess the stock’s valuation relative to peers and historical metrics.\n",
      "\n",
      "#### **Success Metrics**\n",
      "\n",
      "- **Revenue Growth:** Monitor YoY revenue growth to ensure it aligns with expectations.\n",
      "- **Profit Margins:** Track profit margins to assess the impact of cost management and pricing strategies.\n",
      "- **Stock Performance:** Evaluate the stock’s performance against the median price target of $264.21.\n",
      "\n",
      "#### **Review Timeline**\n",
      "\n",
      "- **Quarterly:** Review the investment decision and adjust the strategy based on new data and market conditions.\n",
      "- **Annually:** Conduct a comprehensive review of the investment thesis and long-term growth drivers.\n",
      "\n",
      "By holding Amazon (AMZN) stock, we balance the positive momentum and long-term growth potential with the significant risks highlighted by the bear case. This approach allows us to maximize risk-adjusted returns while maintaining a cautious outlook.Conversation completed successfully!\n",
      "Research team debate completed.\n"
     ]
    }
   ],
   "source": [
    "# Run the debate\n",
    "print(\"Step 3: Running research team debate...\")\n",
    "investment_plan, bull_history, bear_history = research_debate.run(\n",
    "    f\"collaborative multi-agent analysis and decide on an investment plan for {company_of_interest} \"\n",
    "    f\"for the trade date {trade_date} based on the following reports:\\n\\n\"\n",
    "    f\"Market Report:\\n{market_report}\\n\\n\"\n",
    "    f\"News Report:\\n{news_report}\"\n",
    ")\n",
    "\n",
    "# save final analysis\n",
    "save_as_file(bull_history, working_dir, prefix, \"bull_final_analysis.txt\")\n",
    "save_as_file(bear_history, working_dir, prefix, \"bear_final_analysis.txt\")\n",
    "# Save investment plan\n",
    "save_as_file(str(investment_plan), working_dir, prefix, \"investment_plan.txt\")\n",
    "print(\"Research team debate completed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ed64263-b74e-4fea-9d2b-dccd98bb0c0b",
   "metadata": {},
   "source": [
    "## 3 Complete Task 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "089025a7-114b-4c37-8ea7-72a5022efae9",
   "metadata": {},
   "source": [
    "Find the analysis just generated, the directory is located `./results/`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c66ba9e4-9a7b-4c6b-8199-96f4633977d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "stock_data_dir='./results/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6d96e44f-e7cd-45dc-ae78-c970994d3e20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bull Researcher,Bear Researcher,Bull Researcher,Bear Researcher,Bull Researcher,Bear Researcher,Bull Researcher,Bear Researcher"
     ]
    }
   ],
   "source": [
    "# Display the conversation flow between agents\n",
    "!cat {stock_data_dir}/{prefix}/node_history.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "results-analysis-header",
   "metadata": {},
   "source": [
    "## 6. Analysis Results and Insights\n",
    "\n",
    "### 6.1 Multi-Agent Conversation Flow\n",
    "\n",
    "The node history above shows the structured conversation flow between our Bull and Bear researchers. This demonstrates:\n",
    "\n",
    "**Conversation Pattern:**\n",
    "- **Alternating Perspectives**: Bull and Bear researchers take turns presenting arguments\n",
    "- **Dynamic Handoffs**: Agents transfer control based on the conversation context\n",
    "- **Structured Debate**: Each agent builds upon and challenges the other's analysis\n",
    "\n",
    "**Key Observations:**\n",
    "- The conversation involved 8 total interactions between the agents\n",
    "- Both agents had equal opportunity to present their perspectives\n",
    "- The debate concluded naturally when both sides had thoroughly explored their positions\n",
    "\n",
    "### 6.2 Individual Agent Analyses\n",
    "\n",
    "Below are the final analyses from each researcher, showcasing their distinct analytical approaches and conclusions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bear-analysis-header",
   "metadata": {},
   "source": [
    "### 6.3 Bear Researcher Analysis\n",
    "\n",
    "The Bear Researcher focuses on risk identification and cautionary perspectives. Key analytical themes include:\n",
    "- **Valuation Concerns**: Analysis of overvaluation relative to peers and historical metrics\n",
    "- **Market Sentiment Risks**: Assessment of excessive optimism and bubble indicators\n",
    "- **Risk-Adjusted Returns**: Evaluation of volatility and Sharpe ratios\n",
    "- **Liquidity and Institutional Factors**: Analysis of trading patterns and institutional behavior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "47f6d8aa-6029-4906-ae5c-4f1c0b4bb3b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<thinking> It appears that the specialized agents required for the detailed analysis are not available in the current swarm. Therefore, I will need to consolidate the information myself and provide a comprehensive risk assessment based on the available data and my own analysis. \n",
      "\n",
      "I will summarize the key points from the previous analyses and integrate the additional areas requested in the handoff message as best as I can with the information at hand. </thinking>\n",
      "\n",
      "Based on the available data and previous analyses, here is a comprehensive risk assessment for investing in Amazon (AMZN) on the trade date 2025-08-19:\n",
      "\n",
      "### Financial and Operational Risks\n",
      "- **Declining Revenue Trends and Margin Compression:** Although Amazon reported a 13% YoY revenue growth in Q2, concerns over slower growth compared to peers suggest potential margin compression in the future.\n",
      "- **High Debt Levels and Liquidity Concerns:** Amazon's high levels of capital expenditure (capex) could lead to increased debt levels, impacting liquidity.\n",
      "- **Poor Cash Flow Management and Capital Allocation:** The significant investments in AWS and other segments may strain cash flow if returns are not adequately generated.\n",
      "- **Overvaluation Relative to Fundamentals:** The stock is trading at 32x forward earnings, which is below the historical average but still reflects high expectations.\n",
      "- **Accounting Irregularities or Transparency Issues:** No immediate concerns, but continuous monitoring is required.\n",
      "\n",
      "### Market and Competitive Threats\n",
      "- **Market Saturation and Limited Growth Opportunities:** The e-commerce market is becoming increasingly saturated, limiting growth opportunities.\n",
      "- **Intense Competition and Pricing Pressure:** Competitors like Walmart, Alibaba, and others are intensifying pricing pressure.\n",
      "- **Technological Disruption and Obsolescence Risks:** Rapid technological changes could render current business models obsolete.\n",
      "- **Loss of Market Share to Competitors:** The competitive landscape is fierce, and Amazon could lose market share if it fails to innovate.\n",
      "- **Regulatory Threats and Compliance Costs:** Increasing regulatory scrutiny could lead to higher compliance costs and operational challenges.\n",
      "\n",
      "### Macroeconomic Headwinds\n",
      "- **Economic Recession or Slowdown Risks:** A potential economic slowdown could impact consumer spending and, consequently, Amazon's revenue.\n",
      "- **Interest Rate Sensitivity and Credit Tightening:** Rising interest rates could increase borrowing costs and impact Amazon's capex.\n",
      "- **Inflation Impact on Costs and Margins:** Inflation could increase operational costs, squeezing margins.\n",
      "- **Currency Fluctuation Risks for International Exposure:** Amazon's international operations are exposed to currency fluctuation risks.\n",
      "- **Geopolitical Tensions Affecting Operations:** Geopolitical tensions could disrupt supply chains and operations.\n",
      "\n",
      "### Industry-Specific Challenges\n",
      "- **Cyclical Downturns and Seasonal Volatility:** The retail industry is cyclical, and Amazon is not immune to downturns.\n",
      "- **Supply Chain Disruptions and Cost Inflation:** Ongoing supply chain issues could lead to cost inflation.\n",
      "- **Regulatory Changes and Policy Shifts:** Changes in trade policies and regulations could impact Amazon's operations.\n",
      "- **Environmental and Social Governance Risks:** Increasing focus on ESG could lead to additional compliance and operational costs.\n",
      "- **Technological Shifts Disrupting Business Models:** Rapid technological changes could disrupt current business models.\n",
      "\n",
      "### Valuation and Market Concerns\n",
      "- **Overvaluation Relative to Peers and Historical Metrics:** The stock is trading at a premium compared to some peers.\n",
      "- **Excessive Market Optimism and Bubble Indicators:** The bullish sentiment and high price targets suggest excessive optimism.\n",
      "- **Poor Risk-Adjusted Returns and Volatility:** The stock has shown significant volatility, indicating poor risk-adjusted returns.\n",
      "- **Liquidity Concerns and Market Depth Issues:** The stock's high market capitalization could lead to liquidity concerns during market downturns.\n",
      "- **Institutional Selling Pressure and Insider Activity:** Monitoring insider activity and institutional selling pressure is crucial.\n",
      "\n",
      "### Conclusion\n",
      "Investing in Amazon (AMZN) on the trade date 2025-08-19 presents several risks that need to be carefully considered. While there are strong growth drivers and bullish sentiment, the potential downsides, including market competition, regulatory challenges, and macroeconomic headwinds, warrant a cautious approach. Investors should consider these risks and potentially look for more opportune entry points."
     ]
    }
   ],
   "source": [
    "# Display the Bear Researcher's final analysis\n",
    "!cat {stock_data_dir}/{prefix}/bear_final_analysis.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bccade81-4136-4033-8463-613ec550cf28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<thinking> Now that I have handed off the request to the Bear Researcher for additional analysis, I will wait for their response to incorporate into the final investment plan for AMZN. </thinking>\n",
      "\n",
      "**Status Update:**\n",
      "I have handed off the request to the Bear Researcher for additional analysis on the specified areas to enhance the risk assessment for investing in Amazon (AMZN) on the trade date 2025-08-19. Once I receive their analysis, I will incorporate it into the final investment plan.\n",
      "\n",
      "**Next Steps:**\n",
      "- Await the response from the Bear Researcher.\n",
      "- Incorporate the additional analysis into the final investment plan.\n",
      "- Provide a comprehensive recommendation based on the combined analysis."
     ]
    }
   ],
   "source": [
    "# Display the Bull Researcher's final analysis\n",
    "!cat {stock_data_dir}/{prefix}/bull_final_analysis.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bull-analysis-header",
   "metadata": {},
   "source": [
    "### 6.4 Bull Researcher Analysis\n",
    "\n",
    "The Bull Researcher focuses on growth opportunities and positive investment factors. Key analytical themes include:\n",
    "- **Growth Potential**: Analysis of market opportunities and expansion prospects\n",
    "- **Competitive Advantages**: Assessment of unique strengths and market positioning\n",
    "- **Financial Performance**: Evaluation of profitability trends and financial health\n",
    "- **Long-term Value Creation**: Focus on sustainable competitive advantages and innovation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1d765ba-e38c-427e-8ebd-47be7c095873",
   "metadata": {},
   "source": [
    "## 🎉 Congratulations!\n",
    "\n",
    "You have successfully completed **Challenge 2** and built a sophisticated multi-agent investment analysis system!\n",
    "\n",
    "### What You've Mastered:\n",
    "- ✅ **Multi-Agent System Design**: Created specialized agents with distinct roles and responsibilities\n",
    "- ✅ **Agent Coordination**: Implemented structured debates using the Strands Swarm framework\n",
    "- ✅ **Financial Analysis AI**: Built agents capable of sophisticated investment analysis and debate\n",
    "- ✅ **Collaborative Intelligence**: Demonstrated how AI agents can work together to reach better decisions\n",
    "\n",
    "### Ready for the Next Challenge?\n",
    "You're now prepared to continue to **Challenge 3**, where you'll explore even more advanced agent capabilities and coordination patterns.\n",
    "\n",
    "Great work on mastering the fundamentals of multi-agent AI systems! 🚀"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91612151-9c3b-454d-a1f8-3d9068b6165c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
