{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a262470d-15cb-4a69-8059-8d8baefcabad",
   "metadata": {},
   "source": [
    "# Building Multi-Agent Investment Firms with Strands SDK\n",
    "\n",
    "## Introduction\n",
    "In this challenge, participants will use the Strands Agents SDK to build a sophisticated multi-agent system that mirrors the dynamics of real-world trading firms. From fundamental analysts and sentiment experts to technical analysts, traders, and risk management teams, the system collaboratively evaluates market conditions and informs trading decisions.\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ad4111d0-c7a1-4d8d-9c00-5feff20ef0ac",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Task 1\n",
    "- **Goal**: Be familiar with the basic use of the strands agent API and generate market analysis reports \n",
    "- Enter the date: 2025-08-19 and stock code:AMZN you wish to analyze\n",
    "- Create two agents, market report agent and news report agent.\n",
    "- Crawl stock historical data using market report agent.\n",
    "- Crawl stock historical data using stock news agent.\n",
    "- The final output will a csv files and text file."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b05c2834-d7b8-4600-8e1e-3cfdf489a5ee",
   "metadata": {},
   "source": [
    "## 1. Install dependecies\n",
    "- If you encounter \"ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. \", you can ignore it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "682675cb-d9a0-4947-8ad4-4511e77fb3af",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting strands>=0.1.0 (from -r requirements.txt (line 2))\n",
      "  Using cached Strands-0.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.1 kB)\n",
      "Collecting strands-agents>=1.5.0 (from -r requirements.txt (line 3))\n",
      "  Using cached strands_agents-1.7.1-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting strands-agents-tools>=0.2.4 (from -r requirements.txt (line 4))\n",
      "  Using cached strands_agents_tools-0.2.6-py3-none-any.whl.metadata (43 kB)\n",
      "Collecting langchain>=0.1.0 (from -r requirements.txt (line 5))\n",
      "  Using cached langchain-0.3.27-py3-none-any.whl.metadata (7.8 kB)\n",
      "Collecting openai>=1.0.0 (from -r requirements.txt (line 6))\n",
      "  Using cached openai-1.106.1-py3-none-any.whl.metadata (29 kB)\n",
      "Collecting anthropic>=0.20.0 (from -r requirements.txt (line 7))\n",
      "  Using cached anthropic-0.66.0-py3-none-any.whl.metadata (27 kB)\n",
      "Requirement already satisfied: boto3>=1.34.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from -r requirements.txt (line 8)) (1.40.21)\n",
      "Requirement already satisfied: botocore>=1.34.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from -r requirements.txt (line 9)) (1.40.21)\n",
      "Requirement already satisfied: pandas>=2.0.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from -r requirements.txt (line 12)) (2.3.2)\n",
      "Requirement already satisfied: numpy>=1.24.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from -r requirements.txt (line 13)) (1.26.4)\n",
      "Collecting yfinance>=0.2.0 (from -r requirements.txt (line 14))\n",
      "  Using cached yfinance-0.2.65-py2.py3-none-any.whl.metadata (5.8 kB)\n",
      "Collecting stockstats>=0.6.0 (from -r requirements.txt (line 15))\n",
      "  Using cached stockstats-0.6.5-py2.py3-none-any.whl.metadata (39 kB)\n",
      "Requirement already satisfied: requests>=2.31.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from -r requirements.txt (line 18)) (2.32.5)\n",
      "Requirement already satisfied: beautifulsoup4>=4.12.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from -r requirements.txt (line 19)) (4.13.5)\n",
      "Collecting finnhub-python>=2.4.0 (from -r requirements.txt (line 20))\n",
      "  Using cached finnhub_python-2.4.24-py3-none-any.whl.metadata (9.2 kB)\n",
      "Collecting praw>=7.7.0 (from -r requirements.txt (line 21))\n",
      "  Using cached praw-7.8.1-py3-none-any.whl.metadata (9.4 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from -r requirements.txt (line 24)) (2.9.0.post0)\n",
      "Collecting python-dotenv>=1.0.0 (from -r requirements.txt (line 27))\n",
      "  Using cached python_dotenv-1.1.1-py3-none-any.whl.metadata (24 kB)\n",
      "Requirement already satisfied: pydantic>=2.0.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from -r requirements.txt (line 28)) (2.9.2)\n",
      "Requirement already satisfied: typer>=0.9.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from -r requirements.txt (line 31)) (0.16.1)\n",
      "Requirement already satisfied: rich>=13.0.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from -r requirements.txt (line 32)) (14.1.0)\n",
      "Collecting questionary>=2.0.0 (from -r requirements.txt (line 33))\n",
      "  Using cached questionary-2.1.1-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting chromadb>=0.4.0 (from -r requirements.txt (line 36))\n",
      "  Using cached chromadb-1.0.20-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.3 kB)\n",
      "Collecting asyncio-mqtt>=0.13.0 (from -r requirements.txt (line 39))\n",
      "  Using cached asyncio_mqtt-0.16.2-py3-none-any.whl.metadata (17 kB)\n",
      "Requirement already satisfied: pytest>=7.0.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from -r requirements.txt (line 42)) (8.4.1)\n",
      "Collecting pytest-asyncio>=0.21.0 (from -r requirements.txt (line 43))\n",
      "  Using cached pytest_asyncio-1.1.0-py3-none-any.whl.metadata (4.1 kB)\n",
      "Requirement already satisfied: tqdm>=4.65.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from -r requirements.txt (line 46)) (4.67.1)\n",
      "Collecting lxml>=4.9.0 (from -r requirements.txt (line 47))\n",
      "  Using cached lxml-6.0.1-cp310-cp310-manylinux_2_26_x86_64.manylinux_2_28_x86_64.whl.metadata (3.8 kB)\n",
      "Collecting dotenv (from -r requirements.txt (line 48))\n",
      "  Downloading dotenv-0.9.9-py2.py3-none-any.whl.metadata (279 bytes)\n",
      "Collecting docstring-parser<1.0,>=0.15 (from strands-agents>=1.5.0->-r requirements.txt (line 3))\n",
      "  Using cached docstring_parser-0.17.0-py3-none-any.whl.metadata (3.5 kB)\n",
      "Collecting mcp<2.0.0,>=1.11.0 (from strands-agents>=1.5.0->-r requirements.txt (line 3))\n",
      "  Using cached mcp-1.13.1-py3-none-any.whl.metadata (74 kB)\n",
      "Collecting opentelemetry-api<2.0.0,>=1.30.0 (from strands-agents>=1.5.0->-r requirements.txt (line 3))\n",
      "  Using cached opentelemetry_api-1.36.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting opentelemetry-instrumentation-threading<1.00b0,>=0.51b0 (from strands-agents>=1.5.0->-r requirements.txt (line 3))\n",
      "  Using cached opentelemetry_instrumentation_threading-0.57b0-py3-none-any.whl.metadata (2.1 kB)\n",
      "Collecting opentelemetry-sdk<2.0.0,>=1.30.0 (from strands-agents>=1.5.0->-r requirements.txt (line 3))\n",
      "  Using cached opentelemetry_sdk-1.36.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: typing-extensions<5.0.0,>=4.13.2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from strands-agents>=1.5.0->-r requirements.txt (line 3)) (4.15.0)\n",
      "Requirement already satisfied: watchdog<7.0.0,>=6.0.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from strands-agents>=1.5.0->-r requirements.txt (line 3)) (6.0.0)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from boto3>=1.34.0->-r requirements.txt (line 8)) (1.0.1)\n",
      "Requirement already satisfied: s3transfer<0.14.0,>=0.13.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from boto3>=1.34.0->-r requirements.txt (line 8)) (0.13.1)\n",
      "Requirement already satisfied: urllib3!=2.2.0,<3,>=1.25.4 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from botocore>=1.34.0->-r requirements.txt (line 9)) (2.5.0)\n",
      "Requirement already satisfied: six>=1.5 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from python-dateutil>=2.8.0->-r requirements.txt (line 24)) (1.17.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from pydantic>=2.0.0->-r requirements.txt (line 28)) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.4 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from pydantic>=2.0.0->-r requirements.txt (line 28)) (2.23.4)\n",
      "Requirement already satisfied: anyio>=4.5 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from mcp<2.0.0,>=1.11.0->strands-agents>=1.5.0->-r requirements.txt (line 3)) (4.10.0)\n",
      "Collecting httpx-sse>=0.4 (from mcp<2.0.0,>=1.11.0->strands-agents>=1.5.0->-r requirements.txt (line 3))\n",
      "  Using cached httpx_sse-0.4.1-py3-none-any.whl.metadata (9.4 kB)\n",
      "Collecting httpx>=0.27.1 (from mcp<2.0.0,>=1.11.0->strands-agents>=1.5.0->-r requirements.txt (line 3))\n",
      "  Using cached httpx-0.28.1-py3-none-any.whl.metadata (7.1 kB)\n",
      "Requirement already satisfied: jsonschema>=4.20.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from mcp<2.0.0,>=1.11.0->strands-agents>=1.5.0->-r requirements.txt (line 3)) (4.25.1)\n",
      "Collecting pydantic-settings>=2.5.2 (from mcp<2.0.0,>=1.11.0->strands-agents>=1.5.0->-r requirements.txt (line 3))\n",
      "  Using cached pydantic_settings-2.10.1-py3-none-any.whl.metadata (3.4 kB)\n",
      "Collecting pydantic>=2.0.0 (from -r requirements.txt (line 28))\n",
      "  Using cached pydantic-2.11.7-py3-none-any.whl.metadata (67 kB)\n",
      "Collecting python-multipart>=0.0.9 (from mcp<2.0.0,>=1.11.0->strands-agents>=1.5.0->-r requirements.txt (line 3))\n",
      "  Using cached python_multipart-0.0.20-py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting sse-starlette>=1.6.1 (from mcp<2.0.0,>=1.11.0->strands-agents>=1.5.0->-r requirements.txt (line 3))\n",
      "  Using cached sse_starlette-3.0.2-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: starlette>=0.27 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from mcp<2.0.0,>=1.11.0->strands-agents>=1.5.0->-r requirements.txt (line 3)) (0.47.3)\n",
      "Requirement already satisfied: uvicorn>=0.31.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from mcp<2.0.0,>=1.11.0->strands-agents>=1.5.0->-r requirements.txt (line 3)) (0.35.0)\n",
      "Collecting pydantic-core==2.33.2 (from pydantic>=2.0.0->-r requirements.txt (line 28))\n",
      "  Using cached pydantic_core-2.33.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
      "Collecting typing-inspection>=0.4.0 (from pydantic>=2.0.0->-r requirements.txt (line 28))\n",
      "  Using cached typing_inspection-0.4.1-py3-none-any.whl.metadata (2.6 kB)\n",
      "Requirement already satisfied: importlib-metadata<8.8.0,>=6.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from opentelemetry-api<2.0.0,>=1.30.0->strands-agents>=1.5.0->-r requirements.txt (line 3)) (6.11.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from importlib-metadata<8.8.0,>=6.0->opentelemetry-api<2.0.0,>=1.30.0->strands-agents>=1.5.0->-r requirements.txt (line 3)) (3.23.0)\n",
      "Collecting opentelemetry-instrumentation==0.57b0 (from opentelemetry-instrumentation-threading<1.00b0,>=0.51b0->strands-agents>=1.5.0->-r requirements.txt (line 3))\n",
      "  Using cached opentelemetry_instrumentation-0.57b0-py3-none-any.whl.metadata (6.7 kB)\n",
      "Requirement already satisfied: wrapt<2.0.0,>=1.0.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from opentelemetry-instrumentation-threading<1.00b0,>=0.51b0->strands-agents>=1.5.0->-r requirements.txt (line 3)) (1.17.3)\n",
      "Collecting opentelemetry-semantic-conventions==0.57b0 (from opentelemetry-instrumentation==0.57b0->opentelemetry-instrumentation-threading<1.00b0,>=0.51b0->strands-agents>=1.5.0->-r requirements.txt (line 3))\n",
      "  Using cached opentelemetry_semantic_conventions-0.57b0-py3-none-any.whl.metadata (2.4 kB)\n",
      "Requirement already satisfied: packaging>=18.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from opentelemetry-instrumentation==0.57b0->opentelemetry-instrumentation-threading<1.00b0,>=0.51b0->strands-agents>=1.5.0->-r requirements.txt (line 3)) (24.2)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from strands-agents-tools>=0.2.4->-r requirements.txt (line 4)) (3.12.15)\n",
      "Collecting aws-requests-auth<0.5.0,>=0.4.3 (from strands-agents-tools>=0.2.4->-r requirements.txt (line 4))\n",
      "  Using cached aws_requests_auth-0.4.3-py2.py3-none-any.whl.metadata (567 bytes)\n",
      "Requirement already satisfied: dill<0.5.0,>=0.4.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from strands-agents-tools>=0.2.4->-r requirements.txt (line 4)) (0.4.0)\n",
      "Collecting markdownify<2.0.0,>=1.0.0 (from strands-agents-tools>=0.2.4->-r requirements.txt (line 4))\n",
      "  Using cached markdownify-1.2.0-py3-none-any.whl.metadata (9.9 kB)\n",
      "Requirement already satisfied: pillow<12.0.0,>=11.2.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from strands-agents-tools>=0.2.4->-r requirements.txt (line 4)) (11.3.0)\n",
      "Requirement already satisfied: prompt-toolkit<4.0.0,>=3.0.51 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from strands-agents-tools>=0.2.4->-r requirements.txt (line 4)) (3.0.51)\n",
      "Requirement already satisfied: pyjwt<3.0.0,>=2.10.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from strands-agents-tools>=0.2.4->-r requirements.txt (line 4)) (2.10.1)\n",
      "Collecting readabilipy<1.0.0,>=0.2.0 (from strands-agents-tools>=0.2.4->-r requirements.txt (line 4))\n",
      "  Using cached readabilipy-0.3.0-py3-none-any.whl.metadata (8.9 kB)\n",
      "Collecting slack-bolt<2.0.0,>=1.23.0 (from strands-agents-tools>=0.2.4->-r requirements.txt (line 4))\n",
      "  Using cached slack_bolt-1.24.0-py2.py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: sympy<2.0.0,>=1.12.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from strands-agents-tools>=0.2.4->-r requirements.txt (line 4)) (1.14.0)\n",
      "Requirement already satisfied: tenacity<10.0.0,>=9.1.2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from strands-agents-tools>=0.2.4->-r requirements.txt (line 4)) (9.1.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from requests>=2.31.0->-r requirements.txt (line 18)) (3.4.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from requests>=2.31.0->-r requirements.txt (line 18)) (3.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from requests>=2.31.0->-r requirements.txt (line 18)) (2025.8.3)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from rich>=13.0.0->-r requirements.txt (line 32)) (4.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from rich>=13.0.0->-r requirements.txt (line 32)) (2.19.2)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.0->strands-agents-tools>=0.2.4->-r requirements.txt (line 4)) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.0->strands-agents-tools>=0.2.4->-r requirements.txt (line 4)) (1.4.0)\n",
      "Requirement already satisfied: async-timeout<6.0,>=4.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.0->strands-agents-tools>=0.2.4->-r requirements.txt (line 4)) (5.0.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.0->strands-agents-tools>=0.2.4->-r requirements.txt (line 4)) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.0->strands-agents-tools>=0.2.4->-r requirements.txt (line 4)) (1.7.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.0->strands-agents-tools>=0.2.4->-r requirements.txt (line 4)) (6.6.3)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.0->strands-agents-tools>=0.2.4->-r requirements.txt (line 4)) (0.3.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.0->strands-agents-tools>=0.2.4->-r requirements.txt (line 4)) (1.20.1)\n",
      "Requirement already satisfied: soupsieve>1.2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from beautifulsoup4>=4.12.0->-r requirements.txt (line 19)) (2.7)\n",
      "Requirement already satisfied: wcwidth in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from prompt-toolkit<4.0.0,>=3.0.51->strands-agents-tools>=0.2.4->-r requirements.txt (line 4)) (0.2.13)\n",
      "Collecting html5lib (from readabilipy<1.0.0,>=0.2.0->strands-agents-tools>=0.2.4->-r requirements.txt (line 4))\n",
      "  Using cached html5lib-1.1-py2.py3-none-any.whl.metadata (16 kB)\n",
      "Requirement already satisfied: regex in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from readabilipy<1.0.0,>=0.2.0->strands-agents-tools>=0.2.4->-r requirements.txt (line 4)) (2025.7.34)\n",
      "Collecting slack_sdk<4,>=3.35.0 (from slack-bolt<2.0.0,>=1.23.0->strands-agents-tools>=0.2.4->-r requirements.txt (line 4))\n",
      "  Using cached slack_sdk-3.36.0-py2.py3-none-any.whl.metadata (15 kB)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from sympy<2.0.0,>=1.12.0->strands-agents-tools>=0.2.4->-r requirements.txt (line 4)) (1.3.0)\n",
      "Collecting langchain-core<1.0.0,>=0.3.72 (from langchain>=0.1.0->-r requirements.txt (line 5))\n",
      "  Using cached langchain_core-0.3.75-py3-none-any.whl.metadata (5.7 kB)\n",
      "Collecting langchain-text-splitters<1.0.0,>=0.3.9 (from langchain>=0.1.0->-r requirements.txt (line 5))\n",
      "  Using cached langchain_text_splitters-0.3.11-py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting langsmith>=0.1.17 (from langchain>=0.1.0->-r requirements.txt (line 5))\n",
      "  Using cached langsmith-0.4.26-py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from langchain>=0.1.0->-r requirements.txt (line 5)) (2.0.43)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from langchain>=0.1.0->-r requirements.txt (line 5)) (6.0.2)\n",
      "Collecting async-timeout<6.0,>=4.0 (from aiohttp<4.0.0,>=3.8.0->strands-agents-tools>=0.2.4->-r requirements.txt (line 4))\n",
      "  Using cached async_timeout-4.0.3-py3-none-any.whl.metadata (4.2 kB)\n",
      "Collecting jsonpatch<2.0,>=1.33 (from langchain-core<1.0.0,>=0.3.72->langchain>=0.1.0->-r requirements.txt (line 5))\n",
      "  Using cached jsonpatch-1.33-py2.py3-none-any.whl.metadata (3.0 kB)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.72->langchain>=0.1.0->-r requirements.txt (line 5)) (3.0.0)\n",
      "Requirement already satisfied: greenlet>=1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from SQLAlchemy<3,>=1.4->langchain>=0.1.0->-r requirements.txt (line 5)) (3.2.4)\n",
      "Collecting distro<2,>=1.7.0 (from openai>=1.0.0->-r requirements.txt (line 6))\n",
      "  Using cached distro-1.9.0-py3-none-any.whl.metadata (6.8 kB)\n",
      "Collecting jiter<1,>=0.4.0 (from openai>=1.0.0->-r requirements.txt (line 6))\n",
      "  Using cached jiter-0.10.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.2 kB)\n",
      "Requirement already satisfied: sniffio in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from openai>=1.0.0->-r requirements.txt (line 6)) (1.3.1)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from anyio>=4.5->mcp<2.0.0,>=1.11.0->strands-agents>=1.5.0->-r requirements.txt (line 3)) (1.3.0)\n",
      "Collecting httpcore==1.* (from httpx>=0.27.1->mcp<2.0.0,>=1.11.0->strands-agents>=1.5.0->-r requirements.txt (line 3))\n",
      "  Using cached httpcore-1.0.9-py3-none-any.whl.metadata (21 kB)\n",
      "Requirement already satisfied: h11>=0.16 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from httpcore==1.*->httpx>=0.27.1->mcp<2.0.0,>=1.11.0->strands-agents>=1.5.0->-r requirements.txt (line 3)) (0.16.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from pandas>=2.0.0->-r requirements.txt (line 12)) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from pandas>=2.0.0->-r requirements.txt (line 12)) (2025.2)\n",
      "Collecting multitasking>=0.0.7 (from yfinance>=0.2.0->-r requirements.txt (line 14))\n",
      "  Using cached multitasking-0.0.12-py3-none-any.whl\n",
      "Requirement already satisfied: platformdirs>=2.0.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from yfinance>=0.2.0->-r requirements.txt (line 14)) (4.4.0)\n",
      "Collecting frozendict>=2.3.4 (from yfinance>=0.2.0->-r requirements.txt (line 14))\n",
      "  Using cached frozendict-2.4.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (23 kB)\n",
      "Collecting peewee>=3.16.2 (from yfinance>=0.2.0->-r requirements.txt (line 14))\n",
      "  Using cached peewee-3.18.2-cp310-cp310-linux_x86_64.whl\n",
      "Collecting curl_cffi>=0.7 (from yfinance>=0.2.0->-r requirements.txt (line 14))\n",
      "  Using cached curl_cffi-0.13.0-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (13 kB)\n",
      "Requirement already satisfied: protobuf>=3.19.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from yfinance>=0.2.0->-r requirements.txt (line 14)) (6.31.1)\n",
      "Collecting websockets>=13.0 (from yfinance>=0.2.0->-r requirements.txt (line 14))\n",
      "  Using cached websockets-15.0.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
      "Collecting prawcore<3,>=2.4 (from praw>=7.7.0->-r requirements.txt (line 21))\n",
      "  Using cached prawcore-2.4.0-py3-none-any.whl.metadata (5.0 kB)\n",
      "Collecting update_checker>=0.18 (from praw>=7.7.0->-r requirements.txt (line 21))\n",
      "  Using cached update_checker-0.18.0-py3-none-any.whl.metadata (2.3 kB)\n",
      "Requirement already satisfied: websocket-client>=0.54.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from praw>=7.7.0->-r requirements.txt (line 21)) (1.8.0)\n",
      "Requirement already satisfied: click>=8.0.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from typer>=0.9.0->-r requirements.txt (line 31)) (8.2.1)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from typer>=0.9.0->-r requirements.txt (line 31)) (1.5.4)\n",
      "Collecting build>=1.0.3 (from chromadb>=0.4.0->-r requirements.txt (line 36))\n",
      "  Using cached build-1.3.0-py3-none-any.whl.metadata (5.6 kB)\n",
      "Collecting pybase64>=1.4.1 (from chromadb>=0.4.0->-r requirements.txt (line 36))\n",
      "  Using cached pybase64-1.4.2-cp310-cp310-manylinux1_x86_64.manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_5_x86_64.whl.metadata (8.7 kB)\n",
      "Collecting posthog<6.0.0,>=2.4.0 (from chromadb>=0.4.0->-r requirements.txt (line 36))\n",
      "  Using cached posthog-5.4.0-py3-none-any.whl.metadata (5.7 kB)\n",
      "Collecting onnxruntime>=1.14.1 (from chromadb>=0.4.0->-r requirements.txt (line 36))\n",
      "  Using cached onnxruntime-1.16.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.3 kB)\n",
      "Collecting opentelemetry-exporter-otlp-proto-grpc>=1.2.0 (from chromadb>=0.4.0->-r requirements.txt (line 36))\n",
      "  Using cached opentelemetry_exporter_otlp_proto_grpc-1.36.0-py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting tokenizers>=0.13.2 (from chromadb>=0.4.0->-r requirements.txt (line 36))\n",
      "  Using cached tokenizers-0.22.0-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
      "Collecting pypika>=0.48.9 (from chromadb>=0.4.0->-r requirements.txt (line 36))\n",
      "  Using cached pypika-0.48.9-py2.py3-none-any.whl\n",
      "Requirement already satisfied: overrides>=7.3.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from chromadb>=0.4.0->-r requirements.txt (line 36)) (7.7.0)\n",
      "Requirement already satisfied: importlib-resources in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from chromadb>=0.4.0->-r requirements.txt (line 36)) (6.5.2)\n",
      "Collecting grpcio>=1.58.0 (from chromadb>=0.4.0->-r requirements.txt (line 36))\n",
      "  Using cached grpcio-1.74.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\n",
      "Requirement already satisfied: bcrypt>=4.0.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from chromadb>=0.4.0->-r requirements.txt (line 36)) (4.3.0)\n",
      "Collecting kubernetes>=28.1.0 (from chromadb>=0.4.0->-r requirements.txt (line 36))\n",
      "  Using cached kubernetes-33.1.0-py2.py3-none-any.whl.metadata (1.7 kB)\n",
      "Collecting mmh3>=4.0.1 (from chromadb>=0.4.0->-r requirements.txt (line 36))\n",
      "  Using cached mmh3-5.2.0-cp310-cp310-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl.metadata (14 kB)\n",
      "Collecting orjson>=3.9.12 (from chromadb>=0.4.0->-r requirements.txt (line 36))\n",
      "  Using cached orjson-3.11.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (41 kB)\n",
      "Collecting backoff>=1.10.0 (from posthog<6.0.0,>=2.4.0->chromadb>=0.4.0->-r requirements.txt (line 36))\n",
      "  Using cached backoff-2.2.1-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting paho-mqtt>=1.6.0 (from asyncio-mqtt>=0.13.0->-r requirements.txt (line 39))\n",
      "  Using cached paho_mqtt-2.1.0-py3-none-any.whl.metadata (23 kB)\n",
      "Requirement already satisfied: iniconfig>=1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from pytest>=7.0.0->-r requirements.txt (line 42)) (2.0.0)\n",
      "Requirement already satisfied: pluggy<2,>=1.5 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from pytest>=7.0.0->-r requirements.txt (line 42)) (1.6.0)\n",
      "Requirement already satisfied: tomli>=1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from pytest>=7.0.0->-r requirements.txt (line 42)) (2.2.1)\n",
      "Collecting backports-asyncio-runner<2,>=1.1 (from pytest-asyncio>=0.21.0->-r requirements.txt (line 43))\n",
      "  Using cached backports_asyncio_runner-1.2.0-py3-none-any.whl.metadata (7.5 kB)\n",
      "Collecting pyproject_hooks (from build>=1.0.3->chromadb>=0.4.0->-r requirements.txt (line 36))\n",
      "  Using cached pyproject_hooks-1.2.0-py3-none-any.whl.metadata (1.3 kB)\n",
      "Requirement already satisfied: cffi>=1.12.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from curl_cffi>=0.7->yfinance>=0.2.0->-r requirements.txt (line 14)) (1.17.1)\n",
      "Requirement already satisfied: pycparser in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from cffi>=1.12.0->curl_cffi>=0.7->yfinance>=0.2.0->-r requirements.txt (line 14)) (2.22)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from jsonschema>=4.20.0->mcp<2.0.0,>=1.11.0->strands-agents>=1.5.0->-r requirements.txt (line 3)) (2025.4.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from jsonschema>=4.20.0->mcp<2.0.0,>=1.11.0->strands-agents>=1.5.0->-r requirements.txt (line 3)) (0.36.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from jsonschema>=4.20.0->mcp<2.0.0,>=1.11.0->strands-agents>=1.5.0->-r requirements.txt (line 3)) (0.27.0)\n",
      "Collecting google-auth>=1.0.1 (from kubernetes>=28.1.0->chromadb>=0.4.0->-r requirements.txt (line 36))\n",
      "  Using cached google_auth-2.40.3-py2.py3-none-any.whl.metadata (6.2 kB)\n",
      "Collecting requests-oauthlib (from kubernetes>=28.1.0->chromadb>=0.4.0->-r requirements.txt (line 36))\n",
      "  Using cached requests_oauthlib-2.0.0-py2.py3-none-any.whl.metadata (11 kB)\n",
      "Collecting oauthlib>=3.2.2 (from kubernetes>=28.1.0->chromadb>=0.4.0->-r requirements.txt (line 36))\n",
      "  Using cached oauthlib-3.3.1-py3-none-any.whl.metadata (7.9 kB)\n",
      "Collecting durationpy>=0.7 (from kubernetes>=28.1.0->chromadb>=0.4.0->-r requirements.txt (line 36))\n",
      "  Using cached durationpy-0.10-py3-none-any.whl.metadata (340 bytes)\n",
      "Collecting cachetools<6.0,>=2.0.0 (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb>=0.4.0->-r requirements.txt (line 36))\n",
      "  Using cached cachetools-5.5.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting pyasn1-modules>=0.2.1 (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb>=0.4.0->-r requirements.txt (line 36))\n",
      "  Using cached pyasn1_modules-0.4.2-py3-none-any.whl.metadata (3.5 kB)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb>=0.4.0->-r requirements.txt (line 36)) (4.7.2)\n",
      "Requirement already satisfied: pyasn1>=0.1.3 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from rsa<5,>=3.1.4->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb>=0.4.0->-r requirements.txt (line 36)) (0.6.1)\n",
      "Collecting requests-toolbelt>=1.0.0 (from langsmith>=0.1.17->langchain>=0.1.0->-r requirements.txt (line 5))\n",
      "  Using cached requests_toolbelt-1.0.0-py2.py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: zstandard>=0.23.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from langsmith>=0.1.17->langchain>=0.1.0->-r requirements.txt (line 5)) (0.23.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich>=13.0.0->-r requirements.txt (line 32)) (0.1.2)\n",
      "Collecting coloredlogs (from onnxruntime>=1.14.1->chromadb>=0.4.0->-r requirements.txt (line 36))\n",
      "  Using cached coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n",
      "Collecting flatbuffers (from onnxruntime>=1.14.1->chromadb>=0.4.0->-r requirements.txt (line 36))\n",
      "  Using cached flatbuffers-25.2.10-py2.py3-none-any.whl.metadata (875 bytes)\n",
      "Collecting googleapis-common-protos~=1.57 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb>=0.4.0->-r requirements.txt (line 36))\n",
      "  Using cached googleapis_common_protos-1.70.0-py3-none-any.whl.metadata (9.3 kB)\n",
      "Collecting opentelemetry-exporter-otlp-proto-common==1.36.0 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb>=0.4.0->-r requirements.txt (line 36))\n",
      "  Using cached opentelemetry_exporter_otlp_proto_common-1.36.0-py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting opentelemetry-proto==1.36.0 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb>=0.4.0->-r requirements.txt (line 36))\n",
      "  Using cached opentelemetry_proto-1.36.0-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting huggingface-hub<1.0,>=0.16.4 (from tokenizers>=0.13.2->chromadb>=0.4.0->-r requirements.txt (line 36))\n",
      "  Using cached huggingface_hub-0.34.4-py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: filelock in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb>=0.4.0->-r requirements.txt (line 36)) (3.16.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb>=0.4.0->-r requirements.txt (line 36)) (2025.7.0)\n",
      "Collecting hf-xet<2.0.0,>=1.1.3 (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb>=0.4.0->-r requirements.txt (line 36))\n",
      "  Using cached hf_xet-1.1.9-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.7 kB)\n",
      "Collecting httptools>=0.6.3 (from uvicorn[standard]>=0.18.3->chromadb>=0.4.0->-r requirements.txt (line 36))\n",
      "  Using cached httptools-0.6.4-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.6 kB)\n",
      "Collecting uvloop>=0.15.1 (from uvicorn[standard]>=0.18.3->chromadb>=0.4.0->-r requirements.txt (line 36))\n",
      "  Using cached uvloop-0.21.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
      "Collecting watchfiles>=0.13 (from uvicorn[standard]>=0.18.3->chromadb>=0.4.0->-r requirements.txt (line 36))\n",
      "  Using cached watchfiles-1.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
      "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime>=1.14.1->chromadb>=0.4.0->-r requirements.txt (line 36))\n",
      "  Using cached humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n",
      "Requirement already satisfied: webencodings in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from html5lib->readabilipy<1.0.0,>=0.2.0->strands-agents-tools>=0.2.4->-r requirements.txt (line 4)) (0.5.1)\n",
      "Using cached Strands-0.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (635 kB)\n",
      "Using cached strands_agents-1.7.1-py3-none-any.whl (192 kB)\n",
      "Using cached docstring_parser-0.17.0-py3-none-any.whl (36 kB)\n",
      "Using cached mcp-1.13.1-py3-none-any.whl (161 kB)\n",
      "Using cached pydantic-2.11.7-py3-none-any.whl (444 kB)\n",
      "Using cached pydantic_core-2.33.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.0 MB)\n",
      "Using cached opentelemetry_api-1.36.0-py3-none-any.whl (65 kB)\n",
      "Using cached opentelemetry_instrumentation_threading-0.57b0-py3-none-any.whl (9.3 kB)\n",
      "Using cached opentelemetry_instrumentation-0.57b0-py3-none-any.whl (32 kB)\n",
      "Using cached opentelemetry_semantic_conventions-0.57b0-py3-none-any.whl (201 kB)\n",
      "Using cached opentelemetry_sdk-1.36.0-py3-none-any.whl (119 kB)\n",
      "Using cached strands_agents_tools-0.2.6-py3-none-any.whl (283 kB)\n",
      "Using cached aws_requests_auth-0.4.3-py2.py3-none-any.whl (6.8 kB)\n",
      "Using cached markdownify-1.2.0-py3-none-any.whl (15 kB)\n",
      "Using cached readabilipy-0.3.0-py3-none-any.whl (22 kB)\n",
      "Using cached slack_bolt-1.24.0-py2.py3-none-any.whl (230 kB)\n",
      "Using cached slack_sdk-3.36.0-py2.py3-none-any.whl (293 kB)\n",
      "Using cached langchain-0.3.27-py3-none-any.whl (1.0 MB)\n",
      "Using cached async_timeout-4.0.3-py3-none-any.whl (5.7 kB)\n",
      "Using cached langchain_core-0.3.75-py3-none-any.whl (443 kB)\n",
      "Using cached jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
      "Using cached langchain_text_splitters-0.3.11-py3-none-any.whl (33 kB)\n",
      "Using cached openai-1.106.1-py3-none-any.whl (930 kB)\n",
      "Using cached distro-1.9.0-py3-none-any.whl (20 kB)\n",
      "Using cached httpx-0.28.1-py3-none-any.whl (73 kB)\n",
      "Using cached httpcore-1.0.9-py3-none-any.whl (78 kB)\n",
      "Using cached jiter-0.10.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (352 kB)\n",
      "Using cached anthropic-0.66.0-py3-none-any.whl (308 kB)\n",
      "Using cached yfinance-0.2.65-py2.py3-none-any.whl (119 kB)\n",
      "Using cached stockstats-0.6.5-py2.py3-none-any.whl (31 kB)\n",
      "Using cached finnhub_python-2.4.24-py3-none-any.whl (11 kB)\n",
      "Using cached praw-7.8.1-py3-none-any.whl (189 kB)\n",
      "Using cached prawcore-2.4.0-py3-none-any.whl (17 kB)\n",
      "Using cached python_dotenv-1.1.1-py3-none-any.whl (20 kB)\n",
      "Using cached questionary-2.1.1-py3-none-any.whl (36 kB)\n",
      "Using cached chromadb-1.0.20-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (19.8 MB)\n",
      "Using cached posthog-5.4.0-py3-none-any.whl (105 kB)\n",
      "Using cached asyncio_mqtt-0.16.2-py3-none-any.whl (17 kB)\n",
      "Using cached pytest_asyncio-1.1.0-py3-none-any.whl (15 kB)\n",
      "Using cached backports_asyncio_runner-1.2.0-py3-none-any.whl (12 kB)\n",
      "Using cached lxml-6.0.1-cp310-cp310-manylinux_2_26_x86_64.manylinux_2_28_x86_64.whl (5.3 MB)\n",
      "Downloading dotenv-0.9.9-py2.py3-none-any.whl (1.9 kB)\n",
      "Using cached backoff-2.2.1-py3-none-any.whl (15 kB)\n",
      "Using cached build-1.3.0-py3-none-any.whl (23 kB)\n",
      "Using cached curl_cffi-0.13.0-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (8.3 MB)\n",
      "Using cached frozendict-2.4.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (117 kB)\n",
      "Using cached grpcio-1.74.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.2 MB)\n",
      "Using cached httpx_sse-0.4.1-py3-none-any.whl (8.1 kB)\n",
      "Using cached kubernetes-33.1.0-py2.py3-none-any.whl (1.9 MB)\n",
      "Using cached durationpy-0.10-py3-none-any.whl (3.9 kB)\n",
      "Using cached google_auth-2.40.3-py2.py3-none-any.whl (216 kB)\n",
      "Using cached cachetools-5.5.2-py3-none-any.whl (10 kB)\n",
      "Using cached langsmith-0.4.26-py3-none-any.whl (383 kB)\n",
      "Using cached mmh3-5.2.0-cp310-cp310-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl (101 kB)\n",
      "Using cached oauthlib-3.3.1-py3-none-any.whl (160 kB)\n",
      "Using cached onnxruntime-1.16.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.4 MB)\n",
      "Using cached opentelemetry_exporter_otlp_proto_grpc-1.36.0-py3-none-any.whl (18 kB)\n",
      "Using cached opentelemetry_exporter_otlp_proto_common-1.36.0-py3-none-any.whl (18 kB)\n",
      "Using cached opentelemetry_proto-1.36.0-py3-none-any.whl (72 kB)\n",
      "Using cached googleapis_common_protos-1.70.0-py3-none-any.whl (294 kB)\n",
      "Using cached orjson-3.11.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (132 kB)\n",
      "Using cached paho_mqtt-2.1.0-py3-none-any.whl (67 kB)\n",
      "Using cached pyasn1_modules-0.4.2-py3-none-any.whl (181 kB)\n",
      "Using cached pybase64-1.4.2-cp310-cp310-manylinux1_x86_64.manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_5_x86_64.whl (68 kB)\n",
      "Using cached pydantic_settings-2.10.1-py3-none-any.whl (45 kB)\n",
      "Using cached python_multipart-0.0.20-py3-none-any.whl (24 kB)\n",
      "Using cached requests_toolbelt-1.0.0-py2.py3-none-any.whl (54 kB)\n",
      "Using cached sse_starlette-3.0.2-py3-none-any.whl (11 kB)\n",
      "Using cached tokenizers-0.22.0-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.3 MB)\n",
      "Using cached huggingface_hub-0.34.4-py3-none-any.whl (561 kB)\n",
      "Using cached hf_xet-1.1.9-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.2 MB)\n",
      "Using cached typing_inspection-0.4.1-py3-none-any.whl (14 kB)\n",
      "Using cached update_checker-0.18.0-py3-none-any.whl (7.0 kB)\n",
      "Using cached httptools-0.6.4-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (442 kB)\n",
      "Using cached uvloop-0.21.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.8 MB)\n",
      "Using cached watchfiles-1.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (453 kB)\n",
      "Using cached websockets-15.0.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (181 kB)\n",
      "Using cached coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
      "Using cached humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
      "Using cached flatbuffers-25.2.10-py2.py3-none-any.whl (30 kB)\n",
      "Using cached html5lib-1.1-py2.py3-none-any.whl (112 kB)\n",
      "Using cached pyproject_hooks-1.2.0-py3-none-any.whl (10 kB)\n",
      "Using cached requests_oauthlib-2.0.0-py2.py3-none-any.whl (24 kB)\n",
      "Installing collected packages: pypika, peewee, multitasking, flatbuffers, durationpy, websockets, uvloop, typing-inspection, strands, slack_sdk, python-multipart, python-dotenv, pyproject_hooks, pydantic-core, pybase64, pyasn1-modules, paho-mqtt, orjson, opentelemetry-proto, oauthlib, mmh3, lxml, jsonpatch, jiter, humanfriendly, httpx-sse, httptools, httpcore, html5lib, hf-xet, grpcio, googleapis-common-protos, frozendict, docstring-parser, distro, cachetools, backports-asyncio-runner, backoff, async-timeout, update_checker, slack-bolt, requests-toolbelt, requests-oauthlib, readabilipy, questionary, pydantic, prawcore, posthog, opentelemetry-exporter-otlp-proto-common, opentelemetry-api, markdownify, huggingface-hub, google-auth, finnhub-python, dotenv, curl_cffi, coloredlogs, build, aws-requests-auth, asyncio-mqtt, yfinance, watchfiles, tokenizers, stockstats, sse-starlette, pytest-asyncio, pydantic-settings, praw, opentelemetry-semantic-conventions, onnxruntime, kubernetes, httpx, opentelemetry-sdk, opentelemetry-instrumentation, openai, mcp, langsmith, anthropic, opentelemetry-instrumentation-threading, opentelemetry-exporter-otlp-proto-grpc, langchain-core, strands-agents, langchain-text-splitters, chromadb, strands-agents-tools, langchain\n",
      "\u001b[2K  Attempting uninstall: pydantic-core━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 9/86\u001b[0m [slack_sdk]]\n",
      "\u001b[2K    Found existing installation: pydantic_core 2.23.4━━━━━━━━━\u001b[0m \u001b[32m 9/86\u001b[0m [slack_sdk]\n",
      "\u001b[2K    Uninstalling pydantic_core-2.23.4:━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 9/86\u001b[0m [slack_sdk]\n",
      "\u001b[2K      Successfully uninstalled pydantic_core-2.23.4━━━━━━━━━━━\u001b[0m \u001b[32m 9/86\u001b[0m [slack_sdk]\n",
      "\u001b[2K  Attempting uninstall: async-timeout\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m34/86\u001b[0m [distro]se]ules]\n",
      "\u001b[2K    Found existing installation: async-timeout 5.0.1━━━━━━━━━━\u001b[0m \u001b[32m34/86\u001b[0m [distro]\n",
      "\u001b[2K    Uninstalling async-timeout-5.0.1:m━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m34/86\u001b[0m [distro]\n",
      "\u001b[2K      Successfully uninstalled async-timeout-5.0.1━━━━━━━━━━━━\u001b[0m \u001b[32m34/86\u001b[0m [distro]\n",
      "\u001b[2K  Attempting uninstall: pydantic91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40/86\u001b[0m [slack-bolt]\n",
      "\u001b[2K    Found existing installation: pydantic 2.9.2━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45/86\u001b[0m [pydantic]\n",
      "\u001b[2K    Uninstalling pydantic-2.9.2:\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45/86\u001b[0m [pydantic]\n",
      "\u001b[2K      Successfully uninstalled pydantic-2.9.2━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45/86\u001b[0m [pydantic]\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86/86\u001b[0m [langchain]angchain]ents-tools]re]c-conventions]\n",
      "\u001b[1A\u001b[2K\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "safety-schemas 0.0.14 requires pydantic<2.10.0,>=2.6.0, but you have pydantic 2.11.7 which is incompatible.\n",
      "sparkmagic 0.21.0 requires pandas<2.0.0,>=0.17.1, but you have pandas 2.3.2 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed anthropic-0.66.0 async-timeout-4.0.3 asyncio-mqtt-0.16.2 aws-requests-auth-0.4.3 backoff-2.2.1 backports-asyncio-runner-1.2.0 build-1.3.0 cachetools-5.5.2 chromadb-1.0.20 coloredlogs-15.0.1 curl_cffi-0.13.0 distro-1.9.0 docstring-parser-0.17.0 dotenv-0.9.9 durationpy-0.10 finnhub-python-2.4.24 flatbuffers-25.2.10 frozendict-2.4.6 google-auth-2.40.3 googleapis-common-protos-1.70.0 grpcio-1.74.0 hf-xet-1.1.9 html5lib-1.1 httpcore-1.0.9 httptools-0.6.4 httpx-0.28.1 httpx-sse-0.4.1 huggingface-hub-0.34.4 humanfriendly-10.0 jiter-0.10.0 jsonpatch-1.33 kubernetes-33.1.0 langchain-0.3.27 langchain-core-0.3.75 langchain-text-splitters-0.3.11 langsmith-0.4.26 lxml-6.0.1 markdownify-1.2.0 mcp-1.13.1 mmh3-5.2.0 multitasking-0.0.12 oauthlib-3.3.1 onnxruntime-1.16.3 openai-1.106.1 opentelemetry-api-1.36.0 opentelemetry-exporter-otlp-proto-common-1.36.0 opentelemetry-exporter-otlp-proto-grpc-1.36.0 opentelemetry-instrumentation-0.57b0 opentelemetry-instrumentation-threading-0.57b0 opentelemetry-proto-1.36.0 opentelemetry-sdk-1.36.0 opentelemetry-semantic-conventions-0.57b0 orjson-3.11.3 paho-mqtt-2.1.0 peewee-3.18.2 posthog-5.4.0 praw-7.8.1 prawcore-2.4.0 pyasn1-modules-0.4.2 pybase64-1.4.2 pydantic-2.11.7 pydantic-core-2.33.2 pydantic-settings-2.10.1 pypika-0.48.9 pyproject_hooks-1.2.0 pytest-asyncio-1.1.0 python-dotenv-1.1.1 python-multipart-0.0.20 questionary-2.1.1 readabilipy-0.3.0 requests-oauthlib-2.0.0 requests-toolbelt-1.0.0 slack-bolt-1.24.0 slack_sdk-3.36.0 sse-starlette-3.0.2 stockstats-0.6.5 strands-0.1.0 strands-agents-1.7.1 strands-agents-tools-0.2.6 tokenizers-0.22.0 typing-inspection-0.4.1 update_checker-0.18.0 uvloop-0.21.0 watchfiles-1.1.0 websockets-15.0.1 yfinance-0.2.65\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd6d541e-6cb4-48c6-8d4e-53acc0cb36a4",
   "metadata": {},
   "source": [
    "## 2. Prerequisites code  \n",
    "### 2.1 Import Utils functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8d52631e-9eb7-4eab-958a-ae9441b2589b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "from default_config import DEFAULT_CONFIG\n",
    "import logging\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4032eff3-205e-489a-9793-564257d15a80",
   "metadata": {},
   "source": [
    "### 2.2 Initiailize LLM models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d19b09c1-e6db-4348-9c61-2c0b2a0d2dd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "NOVA_RPO_MODEL_ID = \"amazon.nova-pro-v1:0\"\n",
    "EMBEDDING_MODEL_ID=\"amazon.titan-embed-text-v2:0\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9fbed04-42a3-46d6-8a80-af4ead4b3e85",
   "metadata": {},
   "source": [
    "### 2.3 Initiailize LLM models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fd196741-fa95-4167-8900-e097dc48d907",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "from botocore.config import Config\n",
    "from strands.models import BedrockModel\n",
    "\n",
    "# AWS Boto3 client configuration with timeouts and retries\n",
    "boto_client_config = Config(\n",
    "    read_timeout=1800,      # 30 minutes read timeout\n",
    "    connect_timeout=900,    # 15 minutes connect timeout\n",
    "    retries=dict(max_attempts=3, mode=\"adaptive\"),\n",
    ")\n",
    "\n",
    "\n",
    "def get_model(model_id=NOVA_RPO_MODEL_ID, thinking=False,\n",
    "              temperature=0.7, max_tokens=10000):\n",
    "    \"\"\"\n",
    "    Create and return a Bedrock model instance.\n",
    "\n",
    "    Args:\n",
    "        model_id (str): The specific model ID to use\n",
    "        thinking (bool): Whether to enable thinking mode for supported models\n",
    "        temperature (float): Sampling temperature for response generation\n",
    "        max_tokens (int): Maximum tokens in the response\n",
    "\n",
    "    Returns:\n",
    "        BedrockModel instance\n",
    "    \"\"\"\n",
    "    session = boto3.Session()\n",
    "\n",
    "    # Configure thinking mode for supported models\n",
    "    additional_request_fields = {}\n",
    "    if thinking:\n",
    "        additional_request_fields = {\n",
    "            \"thinking\": {\n",
    "                \"type\": \"enabled\",\n",
    "                \"budget_tokens\": 4096,\n",
    "            }\n",
    "        }\n",
    "\n",
    "    return BedrockModel(\n",
    "        model_id=model_id,\n",
    "        boto_session=session,\n",
    "        max_tokens=max_tokens,\n",
    "        temperature=temperature,\n",
    "        boto_client_config=boto_client_config,\n",
    "        additional_request_fields=additional_request_fields,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "15ed67dc-8420-4655-b596-9a117a84749e",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm=get_model(NOVA_RPO_MODEL_ID)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec585f6d-4ebc-4f08-9733-526f9bda03fc",
   "metadata": {},
   "source": [
    "### 2.4 Bear Researcher Agent\n",
    "\n",
    "This module defines the Bear Researcher agent that advocates for cautious or negative investment positions.\n",
    "\n",
    "The agent builds strong cases against investments by emphasizing risks, challenges, and negative indicators\n",
    "while countering bullish arguments with data-driven analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aa5ce16b-f704-49f5-a74e-5691a69533be",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Bear Researcher Agent\n",
    "\"\"\"\n",
    "\n",
    "from strands import Agent\n",
    "\n",
    "def create_bear_researcher(llm, memory, config):\n",
    "    \"\"\"\n",
    "    Create a Bear Researcher agent that advocates for cautious investment positions.\n",
    "    \n",
    "    Args:\n",
    "        llm: The language model to use for the agent\n",
    "        memory (str): Memory identifier for storing/retrieving past reflections\n",
    "        config (dict): Configuration settings for the agent\n",
    "        \n",
    "    Returns:\n",
    "        Agent: Configured Bear Researcher agent\n",
    "    \"\"\"\n",
    "    \n",
    "    system_message = (\n",
    "        \"\"\"You are a Bear Researcher specializing in risk analysis and investment caution. \n",
    "        Your role is to advocate against risky investments by presenting well-researched, \n",
    "        evidence-based arguments that emphasize potential downsides and market risks.\n",
    "\n",
    "        **Key Responsibilities:**\n",
    "        1. Build compelling cases against overvalued or risky investments\n",
    "        2. Counter bullish arguments with solid risk analysis and data\n",
    "        3. Engage in constructive debate with bull analysts\n",
    "        4. Learn from past investment decisions and market downturns\n",
    "\n",
    "        **Risk Assessment Framework:**\n",
    "\n",
    "        **Financial and Operational Risks:**\n",
    "        - Declining revenue trends and margin compression\n",
    "        - High debt levels and liquidity concerns\n",
    "        - Poor cash flow management and capital allocation\n",
    "        - Overvaluation relative to fundamentals\n",
    "        - Accounting irregularities or transparency issues\n",
    "\n",
    "        **Market and Competitive Threats:**\n",
    "        - Market saturation and limited growth opportunities\n",
    "        - Intense competition and pricing pressure\n",
    "        - Technological disruption and obsolescence risks\n",
    "        - Loss of market share to competitors\n",
    "        - Regulatory threats and compliance costs\n",
    "\n",
    "        **Macroeconomic Headwinds:**\n",
    "        - Economic recession or slowdown risks\n",
    "        - Interest rate sensitivity and credit tightening\n",
    "        - Inflation impact on costs and margins\n",
    "        - Currency fluctuation risks for international exposure\n",
    "        - Geopolitical tensions affecting operations\n",
    "\n",
    "        **Industry-Specific Challenges:**\n",
    "        - Cyclical downturns and seasonal volatility\n",
    "        - Supply chain disruptions and cost inflation\n",
    "        - Regulatory changes and policy shifts\n",
    "        - Environmental and social governance risks\n",
    "        - Technological shifts disrupting business models\n",
    "\n",
    "        **Valuation and Market Concerns:**\n",
    "        - Overvaluation relative to peers and historical metrics\n",
    "        - Excessive market optimism and bubble indicators\n",
    "        - Poor risk-adjusted returns and volatility\n",
    "        - Liquidity concerns and market depth issues\n",
    "        - Institutional selling pressure and insider activity\n",
    "\n",
    "        **Debate Strategy:**\n",
    "        - Present arguments in a conversational, analytical style\n",
    "        - Directly challenge bull analyst assumptions with data\n",
    "        - Highlight overlooked risks and potential downsides\n",
    "        - Use historical precedents and market cycles as evidence\n",
    "        - Expose weaknesses in bullish investment theses\n",
    "\n",
    "        **Learning and Improvement:**\n",
    "        - Use get_financial_situation_memories to review past market downturns\n",
    "        - Identify patterns in market bubbles and corrections\n",
    "        - Apply lessons from previous bear market calls\n",
    "        - Refine risk assessment models based on historical accuracy\n",
    "\n",
    "        **Communication Guidelines:**\n",
    "        1. Present arguments with analytical rigor and skepticism\n",
    "        2. Use concrete data and historical examples\n",
    "        3. Challenge assumptions and highlight blind spots\n",
    "        4. Maintain objectivity while being persuasively cautious\n",
    "        5. Focus on downside protection and risk management\n",
    "        6. Provide alternative scenarios and stress testing\n",
    "\n",
    "        **Hand-off Guidelines:**\n",
    "        - You should first give your own analysis.\n",
    "        - If another researcher hasn't provided the final/completed analysis, you can directly hand off to the relevant researcher when you need to.\n",
    "\n",
    "        Remember: Your goal is to provide essential risk perspective and protect against \n",
    "        overoptimistic investment decisions while maintaining analytical integrity.\n",
    "\n",
    "        Need to Write your final analysis!\n",
    "        \"\"\"\n",
    "    )\n",
    "\n",
    "    # Create and configure the agent\n",
    "    agent = Agent(\n",
    "        model=llm,\n",
    "        name=\"Bear Researcher\",\n",
    "        callback_handler=None,  # Disabled for parallel execution in debates\n",
    "        system_prompt=system_message,\n",
    "        load_tools_from_directory=False,\n",
    "    )\n",
    "    \n",
    "    # Set agent state for memory and configuration access\n",
    "    agent.state.set(\"memory_name\", memory)\n",
    "    agent.state.set(\"config\", config)\n",
    "\n",
    "    return agent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae56b44e-f0c4-4a7d-97f4-abd1be5a105e",
   "metadata": {},
   "source": [
    "### 2.5 Bull Researcher Agent\n",
    "\n",
    "This module defines the Bull Researcher agent that advocates for positive investment positions.\n",
    "\n",
    "The agent builds strong, evidence-based cases emphasizing growth potential, competitive advantages, and positive market indicators while countering bearish arguments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cca1bed8-08aa-426b-b95f-4aed0b5d26b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Bull Researcher Agent\n",
    "\"\"\"\n",
    "\n",
    "def create_bull_researcher(llm, memory, config):\n",
    "    \"\"\"\n",
    "    Create a Bull Researcher agent that advocates for positive investment positions.\n",
    "    \n",
    "    Args:\n",
    "        llm: The language model to use for the agent\n",
    "        memory (str): Memory identifier for storing/retrieving past reflections\n",
    "        config (dict): Configuration settings for the agent\n",
    "        \n",
    "    Returns:\n",
    "        Agent: Configured Bull Researcher agent\n",
    "    \"\"\"\n",
    "    \n",
    "    system_message = (\n",
    "        \"\"\"You are a Bull Researcher specializing in building strong investment cases for stocks. \n",
    "        Your role is to advocate for positive investment positions by presenting well-researched, \n",
    "        evidence-based arguments that emphasize growth potential and competitive advantages.\n",
    "\n",
    "        **Key Responsibilities:**\n",
    "        1. Build compelling cases for investment opportunities\n",
    "        2. Counter bearish arguments with solid data and reasoning\n",
    "        3. Engage in constructive debate with bear analysts\n",
    "        4. Learn from past investment decisions and mistakes\n",
    "\n",
    "        **Analysis Framework:**\n",
    "\n",
    "        **Growth Potential Assessment:**\n",
    "        - Market opportunity size and expansion potential\n",
    "        - Revenue growth projections and scalability factors\n",
    "        - New product launches and innovation pipeline\n",
    "        - Geographic expansion opportunities\n",
    "        - Market share growth potential\n",
    "\n",
    "        **Competitive Advantages:**\n",
    "        - Unique products or services with strong differentiation\n",
    "        - Brand strength and customer loyalty\n",
    "        - Dominant market positioning and barriers to entry\n",
    "        - Technological advantages and intellectual property\n",
    "        - Cost advantages and operational efficiency\n",
    "\n",
    "        **Positive Financial Indicators:**\n",
    "        - Strong financial health metrics (revenue, profit margins, cash flow)\n",
    "        - Improving financial trends and performance metrics\n",
    "        - Strong balance sheet and low debt levels\n",
    "        - Efficient capital allocation and return on investment\n",
    "        - Dividend growth and shareholder returns\n",
    "\n",
    "        **Market and Industry Trends:**\n",
    "        - Favorable industry tailwinds and secular trends\n",
    "        - Positive regulatory environment changes\n",
    "        - Increasing demand for company's products/services\n",
    "        - Supply chain advantages and partnerships\n",
    "        - ESG (Environmental, Social, Governance) strengths\n",
    "\n",
    "        **Debate Strategy:**\n",
    "        - Present arguments in a conversational, engaging style\n",
    "        - Directly address and counter bear analyst concerns\n",
    "        - Use specific data and evidence to support positions\n",
    "        - Acknowledge risks while demonstrating why positives outweigh negatives\n",
    "        - Build on previous arguments and strengthen the investment thesis\n",
    "\n",
    "        **Learning and Improvement:**\n",
    "        - Use get_financial_situation_memories to review past investment decisions\n",
    "        - Identify patterns in successful and unsuccessful investment theses\n",
    "        - Apply lessons learned to current analysis and recommendations\n",
    "        - Continuously refine analytical approach based on historical performance\n",
    "\n",
    "        **Communication Guidelines:**\n",
    "        1. Present arguments conversationally and engagingly\n",
    "        2. Use specific data points and concrete evidence\n",
    "        3. Address counterarguments proactively and thoroughly\n",
    "        4. Build momentum in debates by reinforcing strong points\n",
    "        5. Maintain professional tone while being persuasive\n",
    "        6. Focus on actionable insights and clear investment rationale\n",
    "\n",
    "        **Hand-off Guidelines:**\n",
    "        - You should first give your own analysis, and then directly hand off to the relevant researcher when you need to.\n",
    "        - If another researcher hasn't provided the final/completed analysis, you can directly hand off to the relevant researcher when needed. Otherwise, you cannot hand off to them.\n",
    "\n",
    "\n",
    "        Remember: Your goal is to build the strongest possible case for investment while \n",
    "        maintaining intellectual honesty and acknowledging legitimate concerns.\n",
    "\n",
    "        Need to Write your final analysis!\n",
    "        \"\"\"\n",
    "    )\n",
    "\n",
    "    # Create and configure the agent\n",
    "    agent = Agent(\n",
    "        model=llm,\n",
    "        name=\"Bull Researcher\",\n",
    "        callback_handler=None,  # Disabled for parallel execution in debates\n",
    "        system_prompt=system_message,\n",
    "        load_tools_from_directory=False,\n",
    "    )\n",
    "    \n",
    "    # Set agent state for memory and configuration access\n",
    "    agent.state.set(\"memory_name\", memory)\n",
    "    agent.state.set(\"config\", config)\n",
    "\n",
    "    return agent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48d48d8d-8e70-43af-9ff9-e17282377ba3",
   "metadata": {},
   "source": [
    "### 2.6 Research Manager Agent\n",
    "\n",
    "This module defines the Research Manager agent that coordinates research team debates and makes final investment recommendations based on bull and bear analyst arguments.\n",
    "\n",
    "The agent acts as a portfolio manager and debate facilitator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7be9b154-c805-4550-af2d-a5c683aa256d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Research Manager Agent\n",
    "\"\"\"\n",
    "\n",
    "def create_research_manager(llm, memory, config):\n",
    "    \"\"\"\n",
    "    Create a Research Manager agent that coordinates debates and makes investment decisions.\n",
    "    \n",
    "    Args:\n",
    "        llm: The language model to use for the agent\n",
    "        memory (str): Memory identifier for storing/retrieving past decisions\n",
    "        config (dict): Configuration settings for the agent\n",
    "        \n",
    "    Returns:\n",
    "        Agent: Configured Research Manager agent\n",
    "    \"\"\"\n",
    "    \n",
    "    system_message = (\n",
    "        \"\"\"You are a Research Manager and Portfolio Manager responsible for coordinating \n",
    "        research team debates and making definitive investment decisions. Your role is to \n",
    "        critically evaluate arguments from both bull and bear analysts and provide clear, \n",
    "        actionable investment recommendations.\n",
    "\n",
    "        **Key Responsibilities:**\n",
    "        1. Facilitate and evaluate research team debates\n",
    "        2. Make definitive investment decisions (Buy, Sell, or Hold)\n",
    "        3. Develop detailed investment plans for the trading team\n",
    "        4. Learn from past investment decisions and outcomes\n",
    "\n",
    "        **Decision-Making Framework:**\n",
    "\n",
    "        **Debate Evaluation Process:**\n",
    "        - Critically assess the strength of bull and bear arguments\n",
    "        - Identify the most compelling evidence and reasoning from each side\n",
    "        - Evaluate the quality of data and analysis presented\n",
    "        - Consider risk-reward ratios and probability-weighted outcomes\n",
    "        - Assess market timing and execution feasibility\n",
    "\n",
    "        **Investment Decision Criteria:**\n",
    "        - **Buy**: Strong bull case with manageable risks and favorable risk-reward\n",
    "        - **Sell**: Significant risks outweigh potential returns or overvaluation concerns\n",
    "        - **Hold**: Only when genuinely balanced arguments justify maintaining position\n",
    "        - Avoid defaulting to Hold - commit to a clear stance based on evidence\n",
    "\n",
    "        **Investment Plan Development:**\n",
    "        Create comprehensive plans including:\n",
    "        - Clear recommendation with supporting rationale\n",
    "        - Risk assessment and mitigation strategies\n",
    "        - Position sizing and entry/exit criteria\n",
    "        - Timeline and milestone monitoring\n",
    "        - Contingency plans for different scenarios\n",
    "\n",
    "        **Risk Management Considerations:**\n",
    "        - Portfolio diversification and concentration limits\n",
    "        - Correlation with existing positions\n",
    "        - Liquidity requirements and market conditions\n",
    "        - Volatility expectations and drawdown limits\n",
    "        - Regulatory and compliance considerations\n",
    "\n",
    "        **Learning and Improvement:**\n",
    "        - Review past investment decisions and their outcomes\n",
    "        - Identify patterns in successful and unsuccessful calls\n",
    "        - Analyze debate quality and decision-making processes\n",
    "        - Refine evaluation criteria based on historical performance\n",
    "        - Update investment frameworks based on market evolution\n",
    "\n",
    "        **Communication Style:**\n",
    "        1. Present analysis conversationally and naturally\n",
    "        2. Avoid excessive formatting or bullet points\n",
    "        3. Provide clear, decisive recommendations\n",
    "        4. Explain reasoning in accessible terms\n",
    "        5. Address both opportunities and risks transparently\n",
    "        6. Focus on actionable insights for the trading team\n",
    "\n",
    "        **Decision Output Requirements:**\n",
    "        - **Investment Recommendation**: Clear Buy/Sell/Hold decision\n",
    "        - **Rationale**: Explanation of why this decision is optimal\n",
    "        - **Strategic Actions**: Concrete implementation steps\n",
    "        - **Risk Factors**: Key risks and mitigation approaches\n",
    "        - **Success Metrics**: How to measure investment performance\n",
    "        - **Review Timeline**: When to reassess the position\n",
    "\n",
    "        **Tools Available:**\n",
    "        - get_financial_situation_memories: Review past investment decisions and lessons\n",
    "        - Note: Do NOT use add_financial_situation_memories during evaluation\n",
    "\n",
    "        **Critical Guidelines:**\n",
    "        - Make decisive recommendations based on the strongest arguments\n",
    "        - Don't default to Hold unless truly justified by balanced evidence\n",
    "        - Consider both short-term and long-term implications\n",
    "        - Account for market conditions and timing factors\n",
    "        - Maintain objectivity while being actionable\n",
    "        - Learn from past mistakes to improve future decisions\n",
    "\n",
    "        Remember: Your role is to synthesize complex debates into clear, actionable \n",
    "        investment strategies that maximize risk-adjusted returns for the portfolio.\n",
    "        \"\"\"\n",
    "    )\n",
    "\n",
    "    # Create and configure the agent\n",
    "    agent = Agent(\n",
    "        model=llm,\n",
    "        name=\"Research Manager\",\n",
    "        system_prompt=system_message,\n",
    "        load_tools_from_directory=False,\n",
    "    )\n",
    "    \n",
    "    # Set agent state for memory and configuration access\n",
    "    agent.state.set(\"memory_name\", memory)\n",
    "    agent.state.set(\"config\", config)\n",
    "    \n",
    "    return agent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c92d059a-f640-408d-a012-26332b44a0dd",
   "metadata": {},
   "source": [
    "### 2.7 Implement Swarm Conversation\n",
    "\n",
    "This module implements a multi-agent conversation system that coordinates debates\n",
    "and discussions between different trading agents. It supports various coordination\n",
    "modes for different types of agent interactions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "75758ddd-4cd6-4d88-92f5-49c85f116f8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Conversation Swarm\n",
    "\"\"\"\n",
    "\n",
    "import logging\n",
    "from strands.multiagent import Swarm\n",
    "\n",
    "\n",
    "# Enable debug logs and print them to stderr\n",
    "logging.getLogger(\"strands.multiagent\").setLevel(logging.DEBUG)\n",
    "logging.basicConfig(\n",
    "    format=\"%(levelname)s | %(name)s | %(message)s\",\n",
    "    handlers=[logging.StreamHandler()]\n",
    ")\n",
    "\n",
    "\n",
    "class ConversationSwarm:\n",
    "    \"\"\"\n",
    "    A multi-agent conversation system for coordinating debates and discussions.\n",
    "    \n",
    "    This class manages interactions between multiple agents, allowing them to\n",
    "    collaborate, compete, or use hybrid approaches to analyze trading scenarios\n",
    "    and reach consensus decisions.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, agents, summarizer_agent):\n",
    "        \"\"\"\n",
    "        Initialize the ConversationSwarm with agents and collabrative strategy.\n",
    "        \n",
    "        Args:\n",
    "            agents (list): List of agent instances to participate in discussions\n",
    "            summarizer_agent: Agent responsible for synthesizing final decisions\n",
    "        \"\"\"\n",
    "        self.agents = agents\n",
    "        self.summarizer_agent = summarizer_agent\n",
    "        \n",
    "    def run(self, task):\n",
    "        \"\"\"\n",
    "        Execute a multi-phase conversation between agents to analyze a task.\n",
    "        \n",
    "        The conversation follows a structured approach:\n",
    "        1. Initial parallel analysis by all agents\n",
    "        2. Refinement phase where agents respond to each other's insights\n",
    "        3. Final synthesis by the summarizer agent\n",
    "        \n",
    "        Args:\n",
    "            task (str): The trading task or question to analyze\n",
    "            \n",
    "        Returns:\n",
    "            tuple: (final_solution, messages_dict) containing the synthesized\n",
    "                   decision and all conversation messages\n",
    "        \"\"\"\n",
    "        \n",
    "        # Initialize message dictionary to track all agent communications\n",
    "        messages = {}\n",
    "        messages[self.summarizer_agent.name] = []\n",
    "        for agent in self.agents:\n",
    "            messages[agent.name] = []\n",
    "        \n",
    "        print(f\"Starting collabrative conversation with {len(self.agents)} agents...\")\n",
    "        # Create a swarm with these agents\n",
    "        swarm = Swarm(\n",
    "            self.agents,\n",
    "            max_handoffs=10,\n",
    "            max_iterations=10,\n",
    "            execution_timeout=2400.0,  # 15 minutes\n",
    "            node_timeout=600.0,       # 5 minutes per agent\n",
    "            repetitive_handoff_detection_window=8,  # There must be >= 3 unique agents in the last 8 handoffs\n",
    "            repetitive_handoff_min_unique_agents=5\n",
    "        )\n",
    "\n",
    "        # Execute the swarm on a task\n",
    "        print(\"Phase 1: Swarm conversation between bull reseacher and bear reseacher...\")\n",
    "        result = swarm(task)\n",
    "\n",
    "        # Access the final result\n",
    "        print(f\"Status: {result.status}\")\n",
    "        print(f\"Node history: {[node.node_id for node in result.node_history]}\")\n",
    "        save_as_file(\",\".join([node.node_id for node in result.node_history]), working_dir, prefix, \"node_history.txt\")\n",
    "        \n",
    "        bull_history, bear_history = None, None\n",
    "        for message in self.agents[0].messages[::-1]:\n",
    "            if message[\"role\"] != \"assistant\" or len(message[\"content\"]) == 0:\n",
    "                continue\n",
    "            else:\n",
    "                for item in message[\"content\"]:\n",
    "                    if \"text\" in item:\n",
    "                        bull_history = item[\"text\"]\n",
    "                break\n",
    "\n",
    "        for message in self.agents[1].messages[::-1]:\n",
    "            if message[\"role\"] != \"assistant\" or len(message[\"content\"]) == 0:\n",
    "                continue\n",
    "            else:\n",
    "                for item in message[\"content\"]:\n",
    "                    if \"text\" in item:\n",
    "                        bear_history = item[\"text\"]\n",
    "                        # bear_history = message[\"content\"][\"text\"]\n",
    "                break\n",
    "        print(\"Phase 2: Final synthesis and decision...\")\n",
    "        \n",
    "        # Prepare all messages for the summarizer\n",
    "        # all_messages = \"\\n\\n\".join(messages[self.summarizer_agent.name])\n",
    "        \n",
    "        summarizer_prompt = f\"\"\"\n",
    "Original Investment Analysis Task:\n",
    "<query>\n",
    "{task}\n",
    "</query>\n",
    "\n",
    "You have received comprehensive analyses from the research team. Please synthesize \n",
    "these inputs into a final investment decision and strategy:\n",
    "\n",
    "<team_analyses>\n",
    "Bull Reseacher: \n",
    "{bull_history}\n",
    "\n",
    "Bear Reseacher:\n",
    "{bear_history}\n",
    "</team_analyses>\n",
    "\n",
    "Your synthesis should:\n",
    "1. Evaluate the strength of arguments from both bull and bear perspectives\n",
    "2. Identify the most compelling evidence and reasoning\n",
    "3. Make a clear investment recommendation (Buy, Sell, or Hold)\n",
    "4. Provide a detailed rationale for your decision\n",
    "5. Outline specific implementation strategies\n",
    "6. Address key risks and mitigation approaches\n",
    "\n",
    "Create a comprehensive final investment plan that incorporates the best insights \n",
    "from the team while addressing any concerns or contradictions in their analyses.\n",
    "\"\"\"\n",
    "\n",
    "        print(\"Generating final synthesis...\")\n",
    "        final_solution = self.summarizer_agent(summarizer_prompt)\n",
    "        \n",
    "        print(\"Conversation completed successfully!\")\n",
    "        \n",
    "        return final_solution, bull_history, bear_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "943e5359-40f3-481a-84cc-52899600b60a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from model_utils import get_model, save_as_file, read_file\n",
    "from default_config import DEFAULT_CONFIG\n",
    "# Configuration\n",
    "company_of_interest = \"AMZN\"  # Stock ticker to analyze\n",
    "trade_date = \"2025-08-19\"    # Analysis date\n",
    "working_dir = DEFAULT_CONFIG['results_dir']\n",
    "prefix = f\"{company_of_interest}_{trade_date}\".replace(\" \", \"_\")\n",
    "config = DEFAULT_CONFIG.copy()\n",
    "\n",
    "bull_researcher = create_bull_researcher(llm, \"bull_memory\", config)\n",
    "bear_researcher = create_bear_researcher(llm, \"bear_memory\", config)\n",
    "research_manager = create_research_manager(llm, \"invest_judge_memory\", config)\n",
    "\n",
    "# Create debate swarm with collabrative coordination\n",
    "research_debate = ConversationSwarm(\n",
    "    agents=[bull_researcher, bear_researcher],\n",
    "    summarizer_agent=research_manager\n",
    ")\n",
    "\n",
    "# Load previous reports for context\n",
    "market_report = read_file(working_dir, prefix, \"market_report.txt\")\n",
    "news_report = read_file(working_dir, prefix, \"news_report.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6684c95b-1385-439a-947b-658e3e7f3eeb",
   "metadata": {},
   "source": [
    "### 2.8 Run the debate and save investment plan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "88c7d042-c0f1-4403-9cf6-5765189bc552",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG | strands.multiagent.swarm | nodes=<['Bull Researcher', 'Bear Researcher']> | initialized swarm with nodes\n",
      "DEBUG | strands.multiagent.swarm | tool_count=<1>, node_count=<2> | injected coordination tools into agents\n",
      "DEBUG | strands.multiagent.swarm | starting swarm execution\n",
      "DEBUG | strands.multiagent.swarm | current_node=<Bull Researcher> | starting swarm execution with node\n",
      "DEBUG | strands.multiagent.swarm | max_handoffs=<10>, max_iterations=<10>, timeout=<2400.0>s | swarm execution config\n",
      "DEBUG | strands.multiagent.swarm | current_node=<Bull Researcher>, iteration=<1> | executing node\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 3: Running research team debate...\n",
      "Starting collabrative conversation with 2 agents...\n",
      "Phase 1: Swarm conversation between bull reseacher and bear reseacher...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG | strands.multiagent.swarm | from_node=<Bull Researcher>, to_node=<Bear Researcher> | handed off from agent to agent\n",
      "DEBUG | strands.multiagent.swarm | node=<Bull Researcher> | node execution completed\n",
      "DEBUG | strands.multiagent.swarm | current_node=<Bear Researcher>, iteration=<2> | executing node\n",
      "DEBUG | strands.multiagent.swarm | from_node=<Bear Researcher>, to_node=<Bull Researcher> | handed off from agent to agent\n",
      "DEBUG | strands.multiagent.swarm | node=<Bear Researcher> | node execution completed\n",
      "DEBUG | strands.multiagent.swarm | current_node=<Bull Researcher>, iteration=<3> | executing node\n",
      "DEBUG | strands.multiagent.swarm | from_node=<Bull Researcher>, to_node=<Bear Researcher> | handed off from agent to agent\n",
      "DEBUG | strands.multiagent.swarm | node=<Bull Researcher> | node execution completed\n",
      "DEBUG | strands.multiagent.swarm | current_node=<Bear Researcher>, iteration=<4> | executing node\n",
      "DEBUG | strands.multiagent.swarm | from_node=<Bear Researcher>, to_node=<Bull Researcher> | handed off from agent to agent\n",
      "DEBUG | strands.multiagent.swarm | from_node=<Bull Researcher>, to_node=<Bull Researcher> | handed off from agent to agent\n",
      "DEBUG | strands.multiagent.swarm | from_node=<Bull Researcher>, to_node=<Bull Researcher> | handed off from agent to agent\n",
      "DEBUG | strands.multiagent.swarm | from_node=<Bull Researcher>, to_node=<Bull Researcher> | handed off from agent to agent\n",
      "DEBUG | strands.multiagent.swarm | from_node=<Bull Researcher>, to_node=<Bull Researcher> | handed off from agent to agent\n",
      "DEBUG | strands.multiagent.swarm | node=<Bear Researcher> | node execution completed\n",
      "DEBUG | strands.multiagent.swarm | current_node=<Bull Researcher>, iteration=<5> | executing node\n",
      "DEBUG | strands.multiagent.swarm | from_node=<Bull Researcher>, to_node=<Bear Researcher> | handed off from agent to agent\n",
      "DEBUG | strands.multiagent.swarm | node=<Bull Researcher> | node execution completed\n",
      "DEBUG | strands.multiagent.swarm | current_node=<Bear Researcher>, iteration=<6> | executing node\n",
      "DEBUG | strands.multiagent.swarm | from_node=<Bear Researcher>, to_node=<Bull Researcher> | handed off from agent to agent\n",
      "DEBUG | strands.multiagent.swarm | node=<Bear Researcher> | node execution completed\n",
      "DEBUG | strands.multiagent.swarm | current_node=<Bull Researcher>, iteration=<7> | executing node\n",
      "DEBUG | strands.multiagent.swarm | from_node=<Bull Researcher>, to_node=<Bear Researcher> | handed off from agent to agent\n",
      "DEBUG | strands.multiagent.swarm | node=<Bull Researcher> | node execution completed\n",
      "DEBUG | strands.multiagent.swarm | current_node=<Bear Researcher>, iteration=<8> | executing node\n",
      "DEBUG | strands.multiagent.swarm | node=<Bear Researcher> | node execution completed\n",
      "DEBUG | strands.multiagent.swarm | node=<Bear Researcher> | no handoff occurred, marking swarm as complete\n",
      "DEBUG | strands.multiagent.swarm | status=<Status.COMPLETED> | swarm execution completed\n",
      "DEBUG | strands.multiagent.swarm | node_history_length=<8>, time=<319.60>s | metrics\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status: Status.COMPLETED\n",
      "Node history: ['Bull Researcher', 'Bear Researcher', 'Bull Researcher', 'Bear Researcher', 'Bull Researcher', 'Bear Researcher', 'Bull Researcher', 'Bear Researcher']\n",
      "Phase 2: Final synthesis and decision...\n",
      "Generating final synthesis...\n",
      "### Final Investment Decision and Strategy for Amazon (AMZN)\n",
      "\n",
      "#### Evaluation of Bull and Bear Arguments\n",
      "\n",
      "**Bull Perspective:**\n",
      "- **Positive Market Trends:** The technical indicators show a strong uptrend with the price above both the 50-period and 200-period SMAs, and positive momentum as indicated by the MACD.\n",
      "- **News Sentiment:** The news reports are overwhelmingly positive, highlighting innovations in AWS, successful satellite launches, retail expansions, and operational efficiencies. These factors suggest robust growth opportunities.\n",
      "- **Growth Potential:** The continuous innovation and expansion in various segments (AWS, retail, satellite internet) indicate strong long-term growth potential.\n",
      "\n",
      "**Bear Perspective:**\n",
      "- **Overvaluation:** Amazon’s P/E and P/S ratios are significantly higher than historical averages and peer metrics, suggesting potential overvaluation.\n",
      "- **Excessive Optimism:** The high level of optimism among analysts and media could lead to inflated expectations, posing a risk if growth does not meet these expectations.\n",
      "- **Risk-Adjusted Returns:** Amazon’s Sharpe Ratio is lower than some peers, indicating poorer risk-adjusted returns, and the stock exhibits higher volatility.\n",
      "- **Liquidity and Selling Pressure:** While Amazon has high trading volume, rapid price movements can occur. Additionally, significant institutional holdings mean that large-scale selling could pressure the stock price.\n",
      "\n",
      "#### Compelling Evidence and Reasoning\n",
      "\n",
      "- **Trend and Momentum:** The technical indicators strongly support a bullish trend with positive momentum.\n",
      "- **News-Driven Growth:** The recent news highlights significant growth opportunities in key segments like AWS and retail, which are critical revenue drivers for Amazon.\n",
      "- **Valuation Concerns:** The bear arguments about overvaluation and excessive optimism are valid and cannot be ignored. The high P/E and P/S ratios, coupled with high volatility, suggest that the stock may be priced for perfection.\n",
      "\n",
      "#### Investment Recommendation\n",
      "\n",
      "**Decision: Hold**\n",
      "\n",
      "#### Rationale\n",
      "\n",
      "- **Balanced Evidence:** While the bull case is strong with positive market trends and growth opportunities, the bear case presents significant concerns about overvaluation and risk-adjusted returns.\n",
      "- **Risk Management:** Given the high valuation and potential for excessive optimism, a Hold position allows us to avoid the risks associated with overvaluation while still benefiting from Amazon’s growth potential if the stock corrects to more reasonable levels.\n",
      "- **Market Conditions:** The current market conditions, as indicated by the technical indicators, suggest an uptrend, but the valuation metrics warn against aggressive buying.\n",
      "\n",
      "#### Implementation Strategies\n",
      "\n",
      "1. **Position Sizing:** Maintain the current position size in Amazon. Avoid increasing the position until valuation metrics show more reasonable levels.\n",
      "2. **Stop-Loss Levels:** Set a stop-loss at 10% below the current price to protect against significant downside risk.\n",
      "3. **Monitoring:** Continuously monitor valuation metrics (P/E, P/S) and market sentiment. Reassess the position if the stock shows signs of correction or if valuation metrics become more reasonable.\n",
      "4. **Diversification:** Ensure that the portfolio remains diversified to mitigate the risk associated with any single stock, including Amazon.\n",
      "\n",
      "#### Key Risks and Mitigation Approaches\n",
      "\n",
      "- **Overvaluation Risk:** Monitor valuation metrics closely. If the stock shows signs of correction, consider re-evaluating the position for potential entry.\n",
      "- **Market Sentiment Risk:** Stay informed about news and analyst sentiment. Be prepared to adjust the position if sentiment shifts negatively.\n",
      "- **Volatility Risk:** Use stop-loss orders to manage downside risk. Ensure that the portfolio is balanced to handle Amazon’s higher volatility.\n",
      "\n",
      "#### Success Metrics\n",
      "\n",
      "- **Valuation Correction:** Look for a reduction in P/E and P/S ratios to more reasonable levels.\n",
      "- **Revenue Growth:** Monitor AWS and retail segment growth to ensure that the company is meeting or exceeding growth expectations.\n",
      "- **Market Sentiment:** Track analyst ratings and news sentiment to gauge market perception.\n",
      "\n",
      "#### Review Timeline\n",
      "\n",
      "- ** Quarterly Review:** Reassess the position every quarter to ensure it aligns with the overall portfolio strategy and market conditions.\n",
      "- **Immediate Review:** Conduct an immediate review if there are significant changes in valuation metrics, market sentiment, or news events affecting Amazon.\n",
      "\n",
      "### Conclusion\n",
      "\n",
      "The Hold recommendation balances the strong growth opportunities presented by Amazon with the significant risks of overvaluation and excessive market optimism. By maintaining a cautious approach, we can protect the portfolio from potential downside while still positioning to benefit from Amazon’s long-term growth.Conversation completed successfully!\n",
      "Research team debate completed.\n"
     ]
    }
   ],
   "source": [
    "# Run the debate\n",
    "print(\"Step 3: Running research team debate...\")\n",
    "investment_plan, bull_history, bear_history = research_debate.run(\n",
    "    f\"collaborative multi-agent analysis and decide on an investment plan for {company_of_interest} \"\n",
    "    f\"for the trade date {trade_date} based on the following reports:\\n\\n\"\n",
    "    f\"Market Report:\\n{market_report}\\n\\n\"\n",
    "    f\"News Report:\\n{news_report}\"\n",
    ")\n",
    "\n",
    "# save final analysis\n",
    "save_as_file(bull_history, working_dir, prefix, \"bull_final_analysis.txt\")\n",
    "save_as_file(bear_history, working_dir, prefix, \"bear_final_analysis.txt\")\n",
    "# Save investment plan\n",
    "save_as_file(str(investment_plan), working_dir, prefix, \"investment_plan.txt\")\n",
    "print(\"Research team debate completed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ed64263-b74e-4fea-9d2b-dccd98bb0c0b",
   "metadata": {},
   "source": [
    "## 3 Complete Task 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "089025a7-114b-4c37-8ea7-72a5022efae9",
   "metadata": {},
   "source": [
    "Retrieve the stock data just generated, the directory is located `./results/data_cache/`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c66ba9e4-9a7b-4c6b-8199-96f4633977d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "stock_data_dir='./results/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6d96e44f-e7cd-45dc-ae78-c970994d3e20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bull Researcher,Bear Researcher,Bull Researcher,Bear Researcher,Bull Researcher,Bear Researcher,Bull Researcher,Bear Researcher"
     ]
    }
   ],
   "source": [
    "!cat {stock_data_dir}/{prefix}/node_history.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "47f6d8aa-6029-4906-ae5c-4f1c0b4bb3b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<thinking> \n",
      "It appears that the Valuation Researcher is not available in the current swarm. Given the importance of the valuation and market concerns analysis for Amazon (AMZN), I will need to proceed with the analysis myself. \n",
      "\n",
      "I will focus on the key areas of concern: overvaluation relative to peers and historical metrics, excessive market optimism, poor risk-adjusted returns, liquidity concerns, and institutional selling pressure. \n",
      "</thinking>\n",
      "\n",
      "<analysis>\n",
      "Based on the market and news reports provided, here is my analysis of the valuation and market concerns for Amazon (AMZN):\n",
      "\n",
      "### Overvaluation Relative to Peers and Historical Metrics\n",
      "- **Current Valuation**: Amazon's current P/E ratio is significantly higher than its historical average and that of its peers. This suggests that the stock may be overvalued based on earnings.\n",
      "- **Growth Expectations**: The high valuation is driven by expectations of continued high growth in AWS, retail, and new ventures like satellite internet. If these expectations are not met, the stock price could face downward pressure.\n",
      "\n",
      "### Excessive Market Optimism\n",
      "- **News Sentiment**: The news reports indicate a predominantly bullish sentiment driven by positive developments in AWS, retail expansion, and new ventures.\n",
      "- **Risk of Bubble**: The consistent positive news and high valuation raise concerns about excessive market optimism and the potential for a bubble. Investors should be cautious of over-extrapolation of growth expectations.\n",
      "\n",
      "### Poor Risk-Adjusted Returns\n",
      "- **Volatility**: Amazon's stock has historically exhibited high volatility, which can lead to poor risk-adjusted returns. Investors should consider the Sharpe ratio and other risk metrics when evaluating the investment.\n",
      "- **Beta**: Amazon's beta is higher than the market average, indicating higher systematic risk. This should be factored into the investment decision.\n",
      "\n",
      "### Liquidity Concerns\n",
      "- **Trading Volume**: Amazon's stock has high trading volume, which generally indicates good liquidity. However, investors should monitor for any signs of decreasing liquidity that could impact the ability to enter or exit positions.\n",
      "- **Market Depth**: The market depth for Amazon's stock appears robust, but sudden large sell-offs could still impact liquidity.\n",
      "\n",
      "### Institutional Selling Pressure\n",
      "- **Insider Activity**: There have been no significant red flags in insider activity, but investors should continue to monitor for any unusual selling patterns.\n",
      "- **Institutional Holdings**: Amazon has a high level of institutional ownership. Any significant selling by major institutions could put downward pressure on the stock price.\n",
      "\n",
      "### Conclusion\n",
      "While Amazon presents compelling growth opportunities, the current valuation and market sentiment suggest a need for caution. Investors should be aware of the risks associated with overvaluation, excessive optimism, and potential liquidity issues. A balanced approach, considering both the bullish drivers and the identified risks, is recommended.\n",
      "\n",
      "**Recommendation**: Proceed with caution. Consider a diversified approach and set appropriate stop-loss levels to manage risk. Monitor valuation metrics and market sentiment closely.\n",
      "</analysis>"
     ]
    }
   ],
   "source": [
    "!cat {stock_data_dir}/{prefix}/bear_final_analysis.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bccade81-4136-4033-8463-613ec550cf28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thank you for the handoff. Based on the provided context and reports, here is a comprehensive analysis of the valuation and market concerns associated with Amazon (AMZN):\n",
      "\n",
      "### Valuation and Market Concerns Analysis\n",
      "\n",
      "#### Overvaluation Relative to Peers and Historical Metrics\n",
      "- **P/E Ratio**: Amazon's current P/E ratio is significantly higher than its historical average and that of its peers. This suggests that the stock may be overvalued based on earnings.\n",
      "- **P/S Ratio**: The Price-to-Sales ratio is also elevated, indicating that investors are paying a premium for each dollar of sales.\n",
      "- **Historical Metrics**: Comparing Amazon's current valuation metrics to its historical data shows a consistent trend of higher multiples, which could imply overvaluation.\n",
      "\n",
      "#### Excessive Market Optimism\n",
      "- **Analyst Sentiment**: There is a high level of optimism among analysts, with many maintaining \"Buy\" ratings and optimistic price targets. This could lead to inflated expectations and potential disappointment if growth does not meet these high expectations.\n",
      "- **Media Coverage**: Positive news coverage and hype around new product launches and innovations may contribute to excessive optimism.\n",
      "\n",
      "#### Poor Risk-Adjusted Returns\n",
      "- **Sharpe Ratio**: Amazon's Sharpe Ratio, which measures risk-adjusted returns, has been lower than some of its peers. This suggests that the returns may not be sufficiently compensating for the level of risk taken.\n",
      "- **Volatility**: The stock has exhibited higher volatility, which can lead to poorer risk-adjusted returns.\n",
      "\n",
      "#### Liquidity Concerns\n",
      "- **Trading Volume**: Amazon's trading volume is high, indicating good liquidity. However, rapid price movements can still occur, especially in response to news or market sentiment changes.\n",
      "- **Market Cap**: With a large market capitalization, Amazon is less likely to face liquidity issues compared to smaller companies.\n",
      "\n",
      "#### Institutional Selling Pressure\n",
      "- **Institutional Holdings**: Institutional investors hold a significant portion of Amazon's shares. Any large-scale selling by these institutions could put downward pressure on the stock price.\n",
      "- **Insider Selling**: Monitoring insider selling trends can provide insights into potential selling pressure. Increased insider selling may signal concerns about the stock's future performance.\n",
      "\n",
      "### Summary\n",
      "While Amazon presents numerous growth opportunities and positive developments, there are valid concerns regarding its valuation, market optimism, risk-adjusted returns, and potential selling pressure. Investors should carefully consider these factors and maintain a balanced perspective.\n",
      "\n",
      "### Recommendation\n",
      "- **Long-Term Investment**: For long-term investors, Amazon's strong growth prospects and innovative capabilities make it an attractive investment. However, it is crucial to set realistic expectations and be prepared for potential volatility.\n",
      "- **Risk Management**: Implement risk management strategies, such as setting stop-loss levels and diversifying the portfolio, to mitigate the risks associated with overvaluation and market optimism.\n",
      "- **Monitoring**: Continuously monitor valuation metrics, market sentiment, and institutional activity to make informed decisions.\n",
      "\n",
      "Based on this analysis, I recommend a cautious yet optimistic approach to investing in Amazon, with a focus on long-term growth and risk management."
     ]
    }
   ],
   "source": [
    "!cat {stock_data_dir}/{prefix}/bull_final_analysis.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "530cb61c-216e-4a80-9db5-fab6b4aa4b72",
   "metadata": {},
   "source": [
    "According above python script and complete `Task 1`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1d765ba-e38c-427e-8ebd-47be7c095873",
   "metadata": {},
   "source": [
    "### 5 Congraduations! Now you can continue to Challege 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91612151-9c3b-454d-a1f8-3d9068b6165c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
